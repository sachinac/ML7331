{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6> <b> SMU Lab Two - MSDS7331 - Machine Learning-1 </b> </font>\n",
    "\n",
    "<font size=5> <b> Summer 2020 Group - Sachin, Ikenna, Edgar, Dustin </b></font> \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/sachinac/ML7331/blob/master/data/data_mining.jpg?raw=true\"> \n",
    "\n",
    "<p align=\"center\"><font size=5> <b> Health Care Fraud Detection  </b></font> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-1\">Import Libraries</a></span></li><li><span><a href=\"#Data-Preparation-Part-1\" data-toc-modified-id=\"Data-Preparation-Part-1-2\">Data Preparation Part 1</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-2.1\">Load Data</a></span></li><li><span><a href=\"#Set-Categorical-Variables\" data-toc-modified-id=\"Set-Categorical-Variables-2.2\">Set Categorical Variables</a></span></li><li><span><a href=\"#Set-Float-Variables\" data-toc-modified-id=\"Set-Float-Variables-2.3\">Set Float Variables</a></span></li><li><span><a href=\"#Set-Integer-Variables\" data-toc-modified-id=\"Set-Integer-Variables-2.4\">Set Integer Variables</a></span></li><li><span><a href=\"#Set-Date-Variables\" data-toc-modified-id=\"Set-Date-Variables-2.5\">Set Date Variables</a></span></li><li><span><a href=\"#Recoding-Binary-and-Categorical-Features\" data-toc-modified-id=\"Recoding-Binary-and-Categorical-Features-2.6\">Recoding Binary and Categorical Features</a></span></li><li><span><a href=\"#Final-Dataframe---All-Features\" data-toc-modified-id=\"Final-Dataframe---All-Features-2.7\">Final Dataframe - All Features</a></span></li><li><span><a href=\"#Set-Target-Variable\" data-toc-modified-id=\"Set-Target-Variable-2.8\">Set Target Variable</a></span></li><li><span><a href=\"#One-Hot-Encoding-using-SciKit-Learn-Multi-Label-Binarizer\" data-toc-modified-id=\"One-Hot-Encoding-using-SciKit-Learn-Multi-Label-Binarizer-2.9\">One Hot Encoding using SciKit Learn Multi Label Binarizer</a></span></li><li><span><a href=\"#One-Hot-Encoding-using-Pandas\" data-toc-modified-id=\"One-Hot-Encoding-using-Pandas-2.10\">One Hot Encoding using Pandas</a></span></li><li><span><a href=\"#Post-processing-Encoded-Features\" data-toc-modified-id=\"Post-processing-Encoded-Features-2.11\">Post-processing Encoded Features</a></span></li><li><span><a href=\"#Remove-'None'-columns\" data-toc-modified-id=\"Remove-'None'-columns-2.12\">Remove 'None' columns</a></span><ul class=\"toc-item\"><li><span><a href=\"#Regression-DataSet\" data-toc-modified-id=\"Regression-DataSet-2.12.1\">Regression DataSet</a></span></li></ul></li><li><span><a href=\"#MinMaxScaler\" data-toc-modified-id=\"MinMaxScaler-2.13\">MinMaxScaler</a></span><ul class=\"toc-item\"><li><span><a href=\"#Classification-Setting\" data-toc-modified-id=\"Classification-Setting-2.13.1\">Classification Setting</a></span></li><li><span><a href=\"#Regression-Setting\" data-toc-modified-id=\"Regression-Setting-2.13.2\">Regression Setting</a></span></li></ul></li></ul></li><li><span><a href=\"#Data-Preparation-Part-2\" data-toc-modified-id=\"Data-Preparation-Part-2-3\">Data Preparation Part 2</a></span><ul class=\"toc-item\"><li><span><a href=\"#Classification-Final-DataSet\" data-toc-modified-id=\"Classification-Final-DataSet-3.1\">Classification Final DataSet</a></span></li><li><span><a href=\"#Classifcation-Target-Variable\" data-toc-modified-id=\"Classifcation-Target-Variable-3.2\">Classifcation Target Variable</a></span></li><li><span><a href=\"#Regression-Final-Dataset\" data-toc-modified-id=\"Regression-Final-Dataset-3.3\">Regression Final Dataset</a></span></li><li><span><a href=\"#Regression-Target-Variable\" data-toc-modified-id=\"Regression-Target-Variable-3.4\">Regression Target Variable</a></span></li></ul></li><li><span><a href=\"#Modeling-and-Evaluation-1\" data-toc-modified-id=\"Modeling-and-Evaluation-1-4\">Modeling and Evaluation 1</a></span><ul class=\"toc-item\"><li><span><a href=\"#Task-1:-Classification---Provider-Fraud\" data-toc-modified-id=\"Task-1:-Classification---Provider-Fraud-4.1\">Task 1: Classification - Provider Fraud</a></span></li><li><span><a href=\"#Task-2:-Regression\" data-toc-modified-id=\"Task-2:-Regression-4.2\">Task 2: Regression</a></span></li></ul></li><li><span><a href=\"#Modeling-and-Evaluation-2\" data-toc-modified-id=\"Modeling-and-Evaluation-2-5\">Modeling and Evaluation 2</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sparse-Matrix-Conversion-and-Test/Train-Split\" data-toc-modified-id=\"Sparse-Matrix-Conversion-and-Test/Train-Split-5.1\">Sparse Matrix Conversion and Test/Train Split</a></span></li><li><span><a href=\"#Cross-Validation-Method\" data-toc-modified-id=\"Cross-Validation-Method-5.2\">Cross Validation Method</a></span></li></ul></li><li><span><a href=\"#Modeling-and-Evaluations-3\" data-toc-modified-id=\"Modeling-and-Evaluations-3-6\">Modeling and Evaluations 3</a></span><ul class=\"toc-item\"><li><span><a href=\"#function-Defnitions\" data-toc-modified-id=\"function-Defnitions-6.1\">function Defnitions</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.0-testPerformance\" data-toc-modified-id=\"1.0-testPerformance-6.1.1\">1.0 testPerformance</a></span></li><li><span><a href=\"#2.0-Display-Weights\" data-toc-modified-id=\"2.0-Display-Weights-6.1.2\">2.0 Display Weights</a></span></li><li><span><a href=\"#3.0-lab2_grid_search\" data-toc-modified-id=\"3.0-lab2_grid_search-6.1.3\">3.0 lab2_grid_search</a></span></li></ul></li><li><span><a href=\"#Classification-Models\" data-toc-modified-id=\"Classification-Models-6.2\">Classification Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-6.2.1\">Logistic Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Parameters\" data-toc-modified-id=\"Logistic-Parameters-6.2.1.1\">Logistic Parameters</a></span></li><li><span><a href=\"#Parameter-Grid\" data-toc-modified-id=\"Parameter-Grid-6.2.1.2\">Parameter Grid</a></span></li><li><span><a href=\"#GridSearch\" data-toc-modified-id=\"GridSearch-6.2.1.3\">GridSearch</a></span></li><li><span><a href=\"#Logistic-weights\" data-toc-modified-id=\"Logistic-weights-6.2.1.4\">Logistic weights</a></span></li></ul></li><li><span><a href=\"#Random-forest\" data-toc-modified-id=\"Random-forest-6.2.2\">Random forest</a></span><ul class=\"toc-item\"><li><span><a href=\"#Random-Forest-Parameters\" data-toc-modified-id=\"Random-Forest-Parameters-6.2.2.1\">Random Forest Parameters</a></span></li><li><span><a href=\"#Parameter-Grid\" data-toc-modified-id=\"Parameter-Grid-6.2.2.2\">Parameter Grid</a></span></li><li><span><a href=\"#GridSearch\" data-toc-modified-id=\"GridSearch-6.2.2.3\">GridSearch</a></span></li><li><span><a href=\"#Random-Forest-Weights\" data-toc-modified-id=\"Random-Forest-Weights-6.2.2.4\">Random Forest Weights</a></span></li></ul></li><li><span><a href=\"#Naive-Bayes\" data-toc-modified-id=\"Naive-Bayes-6.2.3\">Naive Bayes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Naive-Bayes-Parameters\" data-toc-modified-id=\"Naive-Bayes-Parameters-6.2.3.1\">Naive Bayes Parameters</a></span></li><li><span><a href=\"#Parameter-Grid\" data-toc-modified-id=\"Parameter-Grid-6.2.3.2\">Parameter Grid</a></span></li><li><span><a href=\"#Grid-Search\" data-toc-modified-id=\"Grid-Search-6.2.3.3\">Grid Search</a></span></li><li><span><a href=\"#Naive-Bayes-Weights\" data-toc-modified-id=\"Naive-Bayes-Weights-6.2.3.4\">Naive Bayes Weights</a></span></li></ul></li></ul></li><li><span><a href=\"#Regression-Models\" data-toc-modified-id=\"Regression-Models-6.3\">Regression Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Split-Train/Test\" data-toc-modified-id=\"Split-Train/Test-6.3.1\">Split Train/Test</a></span></li><li><span><a href=\"#Multiple-Linear-Regression\" data-toc-modified-id=\"Multiple-Linear-Regression-6.3.2\">Multiple Linear Regression</a></span></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-6.3.3\">Random Forest</a></span></li><li><span><a href=\"#kNN\" data-toc-modified-id=\"kNN-6.3.4\">kNN</a></span></li></ul></li></ul></li><li><span><a href=\"#Modeling-and-Evaluations-4\" data-toc-modified-id=\"Modeling-and-Evaluations-4-7\">Modeling and Evaluations 4</a></span></li><li><span><a href=\"#Modeling-and-Evaluations-5\" data-toc-modified-id=\"Modeling-and-Evaluations-5-8\">Modeling and Evaluations 5</a></span></li><li><span><a href=\"#Modeling-and-Evaluations-6\" data-toc-modified-id=\"Modeling-and-Evaluations-6-9\">Modeling and Evaluations 6</a></span></li><li><span><a href=\"#Deployment\" data-toc-modified-id=\"Deployment-10\">Deployment</a></span></li><li><span><a href=\"#Exceptional-Work\" data-toc-modified-id=\"Exceptional-Work-11\">Exceptional Work</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Preprocessing:\" data-toc-modified-id=\"Preprocessing:-11.0.1\">Preprocessing:</a></span></li><li><span><a href=\"#Pipelines-and-Grid-Search:\" data-toc-modified-id=\"Pipelines-and-Grid-Search:-11.0.2\">Pipelines and Grid Search:</a></span></li></ul></li></ul></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-12\">References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:15:45.813003Z",
     "start_time": "2020-07-05T05:15:44.894500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import timeit\n",
    "\n",
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from scipy.sparse import csc_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor \n",
    "\n",
    "lab2_random_state  = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data into memory. EDA was already performed on this data. We had originally received Beneficiary, Encounters and target variable datasets in three different spreadsheets and EDA combined that into single spreadsheet using keys of the tables. We still need to perform some additional operations before we actually start with modeling. So in first we prepare our data for modeling as follows :\n",
    "* Prepare variables. Setup data type correctly.\n",
    "* Remove unnecessary variables\n",
    "* Transform categorical features into dummy variables \n",
    "* Feature selection.\n",
    "\n",
    "Lets first print the information of this dataframe. As we can see from below dataframe info this data has total of 79 features. We definately dont need all features. This step will process some of the features before we actually use this data for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:15:48.623475Z",
     "start_time": "2020-07-05T05:15:48.092861Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lab2_df = pd.read_csv('data/final_fraud_dataset.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T08:51:44.322459Z",
     "start_time": "2020-06-30T08:51:44.318865Z"
    }
   },
   "source": [
    "Following are nominal categorical attributes. Pandas requires these to be datatype of 'object' or 'category'. We are setting nominal categorical variables as 'object'. Here is the list of categorical variables :\n",
    "\n",
    "* Race\n",
    "* Gender\n",
    "* RenalDiseaseIndicator\n",
    "* State\n",
    "* County\n",
    "* AttendingPhysicianPresent\n",
    "* OtherPhysicianPresent\n",
    "* OperatingPhysicianPresent\n",
    "* 11 Chronic Conditions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:15:50.215296Z",
     "start_time": "2020-07-05T05:15:50.124803Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_preds = ['Gender','Race','RenalDiseaseIndicator','State','County',\n",
    "             'NoOfMonths_PartACov','NoOfMonths_PartBCov',\n",
    "             'ChronicCond_Alzheimer','ChronicCond_Heartfailure',\n",
    "             'ChronicCond_KidneyDisease','ChronicCond_Cancer','ChronicCond_ObstrPulmonary',\n",
    "             'ChronicCond_Depression','ChronicCond_Diabetes','ChronicCond_IschemicHeart',\n",
    "             'ChronicCond_Osteoporasis','ChronicCond_rheumatoidarthritis','ChronicCond_stroke',\n",
    "             'Alive','ClmAdmitDiagnosisCode','DiagnosisGroupCode',\n",
    "             'ClmDiagnosisCode_1','ClmDiagnosisCode_2','ClmDiagnosisCode_3',\n",
    "             'ClmDiagnosisCode_4','ClmDiagnosisCode_5','ClmDiagnosisCode_6',\n",
    "             'ClmDiagnosisCode_7','ClmDiagnosisCode_8','ClmDiagnosisCode_9',\n",
    "             'ClmDiagnosisCode_10','ClmProcedureCode_1','ClmProcedureCode_2',\n",
    "             'ClmProcedureCode_3','ClmProcedureCode_4','ClmProcedureCode_5',\n",
    "             'AttendingPhysicianPresent','OtherPhysicianPresent','OperatingPhysicianPresent']\n",
    "\n",
    "lab2_df[cat_preds]   = lab2_df[cat_preds].astype('object')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Float Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following varibles are required to be datatype of floating point. These are amounts and hence it makes sense to changt it's type to float\n",
    "\n",
    "* InscClaimAmtReimbursed\n",
    "* IPAnnualReimbursementAmt\n",
    "* IPAnnualDeductibleAmt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:15:55.547692Z",
     "start_time": "2020-07-05T05:15:55.487968Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "float_preds = ['InscClaimAmtReimbursed','IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt']\n",
    "\n",
    "lab2_df[float_preds]   = lab2_df[float_preds].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Integer Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These variables contains all numbers but they are actually nominal categorical attributes. They are all binary in nature. So we can keep them as integer as we will be converting this dataset into sparse matrix for model building exercise. \n",
    "\n",
    "Following variables will be set as integer data type :\n",
    "* NoOfMonths_PartACov - Number of months of Medicare part A coverage\n",
    "* NoOfMonths_PartBCov - Number of months of Medicare part B coverage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:15:59.397332Z",
     "start_time": "2020-07-05T05:15:59.352100Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "int_preds = ['NoOfMonths_PartACov', \n",
    "             'NoOfMonths_PartBCov']\n",
    "\n",
    "lab2_df[int_preds] = lab2_df[int_preds].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Date Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are new attributes are derived from existing attritbutes of type dates. All date attributes are converted to the proleptic Gregorian ordinal of a date.In simple terms datetime.toordinal() returns the day count from the date 01/01/01\n",
    "\n",
    "\n",
    "* ORD_DOD - Set ORD_DOD to open end date where date is not available to indicate that Beneficiary is alive\n",
    "* ORD_DOB \n",
    "* ORD_ClaimStartDt\n",
    "* ORD_ClaimEndDt\n",
    "* ORD_AdmissionDt\n",
    "* ORD_DischargeDt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:16:03.017497Z",
     "start_time": "2020-07-05T05:16:01.785657Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dte_preds = ['ClaimStartDt', 'ClaimEndDt','AdmissionDt', 'DischargeDt', 'DOB','DOD']\n",
    "\n",
    "# Regex to normalize integer DOB/DOD as ISO dates\n",
    "lab2_df['ORD_DOB'] = lab2_df['DOB'].astype(str).str.replace('(\\d{4})(\\d\\d)(\\d\\d)', '\\\\1-\\\\2-\\\\3', regex=True) \n",
    "lab2_df['ORD_DOD'] = lab2_df['DOD'].astype(str).str.replace('(\\d{4})(\\d\\d)(\\d\\d)', '\\\\1-\\\\2-\\\\3', regex=True) \n",
    "\n",
    "lab2_df['ORD_DOD'] = lab2_df['ORD_DOD'].replace('0','2199-12-31')\n",
    "\n",
    "lab2_df['ORD_DOD'] = pd.to_datetime(lab2_df['ORD_DOD'],format='%Y-%m-%d').apply(dt.datetime.toordinal)\n",
    "lab2_df['ORD_DOB'] = pd.to_datetime(lab2_df['DOB'],format='%Y-%m-%d').apply(dt.datetime.toordinal)\n",
    "lab2_df['ORD_ClaimStartDt'] = pd.to_datetime(lab2_df['ClaimStartDt'],format='%Y-%m-%d').apply(dt.datetime.toordinal)\n",
    "lab2_df['ORD_ClaimEndDt']   = pd.to_datetime(lab2_df['ClaimEndDt'],format='%Y-%m-%d').apply(dt.datetime.toordinal)\n",
    "lab2_df['ORD_AdmissionDt']  = pd.to_datetime(lab2_df['AdmissionDt'],format='%Y-%m-%d').apply(dt.datetime.toordinal)\n",
    "lab2_df['ORD_DischargeDt']  = pd.to_datetime(lab2_df['DischargeDt'],format='%Y-%m-%d').apply(dt.datetime.toordinal)\n",
    "\n",
    "ord_dte_preds = ['ORD_DOD', 'ORD_DOB','ORD_ClaimStartDt', 'ORD_ClaimEndDt', 'ORD_AdmissionDt','ORD_DischargeDt']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recoding Binary and Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All chronic conditions, Gender, RenalDiseaseIndicator are binary variables i.e. they all have just two values but values are not 0 and 1. e.g. Gender has values 1 or 2, RenalDiseaseIndicator has Y or 1 and all Chronic Conditions has values 1 or 2. \n",
    "\n",
    "We will recode these values to 0 or 1 instead of 1 and 2 for modeling purpose. Leaving two columns for a binary feature can introduce bias, giving one feature artificially more weight in prediction if the model treats the single feature as two.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:16:05.950261Z",
     "start_time": "2020-07-05T05:16:05.111296Z"
    }
   },
   "outputs": [],
   "source": [
    "# Recode below categorical variables \n",
    "\n",
    "lab2_df['Gender']  = lab2_df['Gender'].replace([1,2],[0,1])\n",
    "lab2_df['RenalDiseaseIndicator']  = lab2_df['RenalDiseaseIndicator'].replace('Y',1)\n",
    "\n",
    "\n",
    "lab2_df = lab2_df.replace({'ChronicCond_Alzheimer': 2,      'ChronicCond_Heartfailure': 2, \n",
    "                           'ChronicCond_KidneyDisease': 2,  'ChronicCond_Cancer': 2, \n",
    "                           'ChronicCond_ObstrPulmonary': 2, 'ChronicCond_Depression': 2, \n",
    "                           'ChronicCond_Diabetes': 2,       'ChronicCond_IschemicHeart': 2, \n",
    "                           'ChronicCond_Osteoporasis': 2,   'ChronicCond_rheumatoidarthritis': 2, \n",
    "                           'ChronicCond_stroke': 2 }, '0')\n",
    "\n",
    "lab2_df['Gender'] = lab2_df['Gender'].astype('object')\n",
    "lab2_df['Race'] = lab2_df['Race'].astype('object')\n",
    "lab2_df['State'] = lab2_df['State'].astype('object')\n",
    "lab2_df['County'] = lab2_df['County'].astype('object')\n",
    "lab2_df['OtherPhysicianPresent'] = lab2_df['OtherPhysicianPresent'].astype('object')\n",
    "lab2_df['OperatingPhysicianPresent'] = lab2_df['OperatingPhysicianPresent'].astype('object')\n",
    "lab2_df['AttendingPhysicianPresent'] = lab2_df['AttendingPhysicianPresent'].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Dataframe - All Features\n",
    "All features are GROUPED as follows:\n",
    "* Numeric Predictors\n",
    "* Categorical Predictors\n",
    "* Non-Predictors (Will not be used for modeling)\n",
    "\n",
    "We chose to remove all ID columns from the data, as they aren't useful in prediction (unique IDs = N observations).  We replaced the original date features with their ordinal conversions.  We removed all providerIDs from the dataset, because these are correlated 1:1 with the response.  Unfortunately, our data lists only the provider ID as the response variable (potentially fraudulent), so the prediction algorithm gets 'the answer' if the provider ID shows up in attending, operating, or other physician columns.  Removing these from the dataset limits the prediction ability of our algorithms, but more closely represents reality, where a provider's fraudulent behavior is unknown at the time of claim review.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:19:18.770852Z",
     "start_time": "2020-07-05T05:19:18.661144Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_preds     = ['Age','NoPhysician','NoOfDiag','NoOfProc',\n",
    "                     'ORD_DOD','ORD_DOB','ORD_ClaimStartDt','ORD_ClaimEndDt',\n",
    "                     'ORD_AdmissionDt','ORD_DischargeDt','DaysAdmitted',\n",
    "                     'IPAnnualReimbursementAmt','IPAnnualDeductibleAmt',   \n",
    "                     'InscClaimAmtReimbursed'  \n",
    "                    ]\n",
    "\n",
    "cat_preds_nominal = ['Gender','Race','RenalDiseaseIndicator','State','County',\n",
    "                     'NoOfMonths_PartACov','NoOfMonths_PartBCov',\n",
    "                     'ChronicCond_Alzheimer','ChronicCond_Heartfailure',\n",
    "                     'ChronicCond_KidneyDisease','ChronicCond_Cancer','ChronicCond_ObstrPulmonary',\n",
    "                     'ChronicCond_Depression','ChronicCond_Diabetes','ChronicCond_IschemicHeart',\n",
    "                     'ChronicCond_Osteoporasis','ChronicCond_rheumatoidarthritis','ChronicCond_stroke',\n",
    "                     'Alive','ClmAdmitDiagnosisCode','DiagnosisGroupCode',\n",
    "                     'ClmDiagnosisCode_1','ClmDiagnosisCode_2','ClmDiagnosisCode_3',\n",
    "                     'ClmDiagnosisCode_4','ClmDiagnosisCode_5','ClmDiagnosisCode_6',\n",
    "                     'ClmDiagnosisCode_7','ClmDiagnosisCode_8','ClmDiagnosisCode_9',\n",
    "                     'ClmDiagnosisCode_10','ClmProcedureCode_1','ClmProcedureCode_2',\n",
    "                     'ClmProcedureCode_3','ClmProcedureCode_4','ClmProcedureCode_5',\n",
    "                     'AttendingPhysicianPresent','OtherPhysicianPresent','OperatingPhysicianPresent'\n",
    "                     ]\n",
    "\n",
    "non_preds = ['BeneID','DOB','DOD','state_usps','ClaimID',\n",
    "             'ClaimStartDt','ClaimEndDt','Provider',\n",
    "             'AttendingPhysician','OperatingPhysician','OtherPhysician',\n",
    "             'AdmissionDt','DischargeDt','DRGDesc',\n",
    "             'ProcedureShortDesc_1','ProcedureShortDesc_2','ProcedureShortDesc_3',\n",
    "             'ProcedureShortDesc_4','ProcedureShortDesc_5','DiagnosticDesc_1',\n",
    "             'DiagnosticDesc_2','DiagnosticDesc_3','DiagnosticDesc_4',\n",
    "             'DiagnosticDesc_5','DiagnosticDesc_6','DiagnosticDesc_7',\n",
    "             'DiagnosticDesc_8','DiagnosticDesc_9','DiagnosticDesc_10',\n",
    "             'NoOfChronicCondition'\n",
    "             ]\n",
    "\n",
    "preds_in_model = numeric_preds + cat_preds_nominal\n",
    "\n",
    "Xlab2_df = lab2_df[preds_in_model].copy()\n",
    "\n",
    "Xlab2_df[cat_preds_nominal] = Xlab2_df[cat_preds_nominal].astype('object')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:19:36.727966Z",
     "start_time": "2020-07-05T05:19:36.624396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40474 entries, 0 to 40473\n",
      "Data columns (total 53 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Age                              40474 non-null  int64  \n",
      " 1   NoPhysician                      40474 non-null  int64  \n",
      " 2   NoOfDiag                         40474 non-null  int64  \n",
      " 3   NoOfProc                         40474 non-null  int64  \n",
      " 4   ORD_DOD                          40474 non-null  int64  \n",
      " 5   ORD_DOB                          40474 non-null  int64  \n",
      " 6   ORD_ClaimStartDt                 40474 non-null  int64  \n",
      " 7   ORD_ClaimEndDt                   40474 non-null  int64  \n",
      " 8   ORD_AdmissionDt                  40474 non-null  int64  \n",
      " 9   ORD_DischargeDt                  40474 non-null  int64  \n",
      " 10  DaysAdmitted                     40474 non-null  int64  \n",
      " 11  IPAnnualReimbursementAmt         40474 non-null  float64\n",
      " 12  IPAnnualDeductibleAmt            40474 non-null  float64\n",
      " 13  InscClaimAmtReimbursed           40474 non-null  float64\n",
      " 14  Gender                           40474 non-null  object \n",
      " 15  Race                             40474 non-null  object \n",
      " 16  RenalDiseaseIndicator            40474 non-null  object \n",
      " 17  State                            40474 non-null  object \n",
      " 18  County                           40474 non-null  object \n",
      " 19  NoOfMonths_PartACov              40474 non-null  object \n",
      " 20  NoOfMonths_PartBCov              40474 non-null  object \n",
      " 21  ChronicCond_Alzheimer            40474 non-null  object \n",
      " 22  ChronicCond_Heartfailure         40474 non-null  object \n",
      " 23  ChronicCond_KidneyDisease        40474 non-null  object \n",
      " 24  ChronicCond_Cancer               40474 non-null  object \n",
      " 25  ChronicCond_ObstrPulmonary       40474 non-null  object \n",
      " 26  ChronicCond_Depression           40474 non-null  object \n",
      " 27  ChronicCond_Diabetes             40474 non-null  object \n",
      " 28  ChronicCond_IschemicHeart        40474 non-null  object \n",
      " 29  ChronicCond_Osteoporasis         40474 non-null  object \n",
      " 30  ChronicCond_rheumatoidarthritis  40474 non-null  object \n",
      " 31  ChronicCond_stroke               40474 non-null  object \n",
      " 32  Alive                            40474 non-null  object \n",
      " 33  ClmAdmitDiagnosisCode            40474 non-null  object \n",
      " 34  DiagnosisGroupCode               40474 non-null  object \n",
      " 35  ClmDiagnosisCode_1               40474 non-null  object \n",
      " 36  ClmDiagnosisCode_2               40474 non-null  object \n",
      " 37  ClmDiagnosisCode_3               40474 non-null  object \n",
      " 38  ClmDiagnosisCode_4               40474 non-null  object \n",
      " 39  ClmDiagnosisCode_5               40474 non-null  object \n",
      " 40  ClmDiagnosisCode_6               40474 non-null  object \n",
      " 41  ClmDiagnosisCode_7               40474 non-null  object \n",
      " 42  ClmDiagnosisCode_8               40474 non-null  object \n",
      " 43  ClmDiagnosisCode_9               40474 non-null  object \n",
      " 44  ClmDiagnosisCode_10              40474 non-null  object \n",
      " 45  ClmProcedureCode_1               40474 non-null  object \n",
      " 46  ClmProcedureCode_2               40474 non-null  object \n",
      " 47  ClmProcedureCode_3               40474 non-null  object \n",
      " 48  ClmProcedureCode_4               40474 non-null  object \n",
      " 49  ClmProcedureCode_5               40474 non-null  object \n",
      " 50  AttendingPhysicianPresent        40474 non-null  object \n",
      " 51  OtherPhysicianPresent            40474 non-null  object \n",
      " 52  OperatingPhysicianPresent        40474 non-null  object \n",
      "dtypes: float64(3), int64(11), object(39)\n",
      "memory usage: 16.7+ MB\n"
     ]
    }
   ],
   "source": [
    "Xlab2_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:19:38.446271Z",
     "start_time": "2020-07-05T05:19:38.424271Z"
    }
   },
   "outputs": [],
   "source": [
    "target_df = lab2_df['PotentialFraud'].replace(['Yes','No'],[1,0]).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding using SciKit Learn Multi Label Binarizer\n",
    "\n",
    "Because the claim data can have up to 10 different diagnosis codes and 5 different procedure codes, we created a new array column that combines all used diagnosis codes and another like type column with procedures.  This will reduce our feature counts from >40,000 to around 9,000 and will help maximize feature importance because each code will no longer be split across up to 10 different columns (i.e. diagnosis code columns 1 - 10).  This way if code A gets used in column_1, and in column_2, the usage of code A will be consolidated to the DiagnosisCode_A column.\n",
    "\n",
    "Pandas get_dummies function will not parse lists, we'll need to utilize the multiLabelBinarizer from scikit learn to one-hot encode the list values before calling get_dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:23:27.965602Z",
     "start_time": "2020-07-05T05:23:13.863528Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Xlab2_df['DiagnosisCode'] = Xlab2_df[['ClmDiagnosisCode_1', 'ClmDiagnosisCode_2', 'ClmDiagnosisCode_3', 'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5', 'ClmDiagnosisCode_6', 'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8', 'ClmDiagnosisCode_9', 'ClmDiagnosisCode_10']].values.tolist()\n",
    "\n",
    "Xlab2_df['ProcedureCode'] = Xlab2_df[['ClmProcedureCode_1', 'ClmProcedureCode_2', 'ClmProcedureCode_3', 'ClmProcedureCode_4', 'ClmProcedureCode_5']].values.tolist()\n",
    "\n",
    "ipdata = Xlab2_df.copy()\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "ipdata = ipdata.join(pd.DataFrame(mlb.fit_transform(ipdata['ProcedureCode']),columns='ProcedureCode_'+mlb.classes_))\n",
    "ipdata = ipdata.join(pd.DataFrame(mlb.fit_transform(ipdata['DiagnosisCode']),columns='DiagnosisCode_'+mlb.classes_))\n",
    "\n",
    "ipdata = ipdata.drop(columns=['ClmProcedureCode_1', 'ClmProcedureCode_2', 'ClmProcedureCode_3', 'ClmProcedureCode_4', 'ClmProcedureCode_5','ClmDiagnosisCode_1', 'ClmDiagnosisCode_2', 'ClmDiagnosisCode_3', 'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5', 'ClmDiagnosisCode_6', 'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8', 'ClmDiagnosisCode_9', 'ClmDiagnosisCode_10','ProcedureCode','DiagnosisCode'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding using Pandas\n",
    "\n",
    "Now that we've dropped our multi-columns and lists, we can onehot encode the rest of the features and transform into a sparse matrix using Pandas Get Dummies function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:24:27.990141Z",
     "start_time": "2020-07-05T05:24:23.016370Z"
    }
   },
   "outputs": [],
   "source": [
    "ipdata = pd.get_dummies(ipdata, sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:24:33.226867Z",
     "start_time": "2020-07-05T05:24:29.860095Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40474 entries, 0 to 40473\n",
      "Columns: 9116 entries, Age to OperatingPhysicianPresent_1\n",
      "dtypes: Sparse[uint8, 0](3063), float64(3), int64(6050)\n",
      "memory usage: 1.8 GB\n"
     ]
    }
   ],
   "source": [
    "ipdata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing Encoded Features\n",
    "\n",
    "Because we are using objects, Pandas converts all classes into new columns.  However, for binary features, we want to remove one of the values, in order to prevent the model from introducing bias by weighting each binary feature twice (via separate true/false columns).\n",
    "\n",
    "To correct this, we must search for and remove duplicate columns (indicated by the _0 suffix).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:24:38.149831Z",
     "start_time": "2020-07-05T05:24:35.680613Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed Following Columns:\n",
      "Gender_0\n",
      "RenalDiseaseIndicator_0\n",
      "NoOfMonths_PartACov_0\n",
      "NoOfMonths_PartBCov_0\n",
      "ChronicCond_Alzheimer_0\n",
      "ChronicCond_Heartfailure_0\n",
      "ChronicCond_KidneyDisease_0\n",
      "ChronicCond_Cancer_0\n",
      "ChronicCond_ObstrPulmonary_0\n",
      "ChronicCond_Depression_0\n",
      "ChronicCond_Diabetes_0\n",
      "ChronicCond_IschemicHeart_0\n",
      "ChronicCond_Osteoporasis_0\n",
      "ChronicCond_rheumatoidarthritis_0\n",
      "ChronicCond_stroke_0\n",
      "AttendingPhysicianPresent_0\n",
      "OtherPhysicianPresent_0\n",
      "OperatingPhysicianPresent_0\n"
     ]
    }
   ],
   "source": [
    "StopWords = ['Diagnosis','Procedure','County','State']\n",
    "bins = []\n",
    "print('Removed Following Columns:')\n",
    "for col in ipdata.columns:\n",
    "    if not any(word in col for word in StopWords) and '_0' in col:    \n",
    "        print(col)\n",
    "        bins.append(col)\n",
    "ipdata = ipdata.drop(bins, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove 'None' columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our encoded dataset contains None for Diagnosis and Procedure codes features wherever information is not available on the claim. All claims allows max 5 procedure codes and 10 diagnosis codes and at least one procedure code or diagnosis code is applied on the claim. When claim has only one procedure and one diagnosis all other procedure codes contains NAs or None and one hot encoding treats these as another category which is not correct. therefore we need to remove column Nones created by one hot encoding by pandas.\n",
    "\n",
    "Essentially by creating a 'none' column it creates a column (new feature) for missing data, which would erroneously assign more weight to a value that doesn't exist.  Because it would get a '1' for missing a value, but would also have 0's for the other values.  Also it may mess up our counts because 'None' would count as a valid procedure code if we're summing unique values for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:24:46.913938Z",
     "start_time": "2020-07-05T05:24:44.273922Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed Following Columns:\n",
      "ProcedureCode_None\n",
      "DiagnosisCode_None\n"
     ]
    }
   ],
   "source": [
    "nones = []\n",
    "print('Removed Following Columns:')\n",
    "for col in ipdata.columns:\n",
    "    if 'None' in col:    \n",
    "        nones.append(col)\n",
    "        print(col)\n",
    "ipdata = ipdata.drop(nones, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:24:49.436162Z",
     "start_time": "2020-07-05T05:24:49.246066Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40474 entries, 0 to 40473\n",
      "Columns: 9096 entries, Age to OperatingPhysicianPresent_1\n",
      "dtypes: Sparse[uint8, 0](3045), float64(3), int64(6048)\n",
      "memory usage: 1.8 GB\n"
     ]
    }
   ],
   "source": [
    "ipdata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create separate dataframe for regression tasks as below : <br>\n",
    " 1. Remove new target variable from the original ipdata dataframe\n",
    " 2. create new target variable for regression setting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:33:37.673673Z",
     "start_time": "2020-07-05T05:33:34.651415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40474 entries, 0 to 40473\n",
      "Columns: 9095 entries, Age to OperatingPhysicianPresent_1\n",
      "dtypes: Sparse[uint8, 0](3045), float64(2), int64(6048)\n",
      "memory usage: 1.8 GB\n"
     ]
    }
   ],
   "source": [
    "reg_target = ipdata['InscClaimAmtReimbursed']\n",
    "reg_df = ipdata.drop(columns=['InscClaimAmtReimbursed'])\n",
    "reg_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to use the MinMaxScaler here instead of the standard scaler because we're using a sparse matrix of mostly binary features.  Because we do have some true numeric features, such as: deductible amount, age, the converted ordinal dates, claim dollar amounts etc, these may end up having values outside the bounds of 0 and 1.  A zero mean scaler doesn't make sense with this data because it would cause the numeric features to have inflated importance if observations end up being several standard deviations away from 0, while the binary features are capped at 1.  The minMax scaler allows us to force all values in the dataset to live within the bounds of 0 and 1, allowing our logistic regression algorithms to weight features appropriately using similar measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:26:16.596402Z",
     "start_time": "2020-07-05T05:24:54.885604Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(ipdata)\n",
    "X1 = scaler.transform(ipdata,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:35:07.073824Z",
     "start_time": "2020-07-05T05:33:49.974142Z"
    }
   },
   "outputs": [],
   "source": [
    "reg_scaler = MinMaxScaler()\n",
    "reg_scaler.fit(reg_df)\n",
    "reg_X1 = reg_scaler.transform(reg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Part 2\n",
    "\n",
    "We ended up with two variants of our final dataset: the sparse matrix (ipdata) containing all one-hot encoded features, and the original dataframe (Xlab2_df) so that if we need to retrieve any of the original data, we can share indices to highlight our findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Final DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:37:31.224835Z",
     "start_time": "2020-07-05T05:37:31.184790Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>NoPhysician</th>\n",
       "      <th>NoOfDiag</th>\n",
       "      <th>NoOfProc</th>\n",
       "      <th>ORD_DOD</th>\n",
       "      <th>ORD_DOB</th>\n",
       "      <th>ORD_ClaimStartDt</th>\n",
       "      <th>ORD_ClaimEndDt</th>\n",
       "      <th>ORD_AdmissionDt</th>\n",
       "      <th>ORD_DischargeDt</th>\n",
       "      <th>...</th>\n",
       "      <th>ClmProcedureCode_1</th>\n",
       "      <th>ClmProcedureCode_2</th>\n",
       "      <th>ClmProcedureCode_3</th>\n",
       "      <th>ClmProcedureCode_4</th>\n",
       "      <th>ClmProcedureCode_5</th>\n",
       "      <th>AttendingPhysicianPresent</th>\n",
       "      <th>OtherPhysicianPresent</th>\n",
       "      <th>OperatingPhysicianPresent</th>\n",
       "      <th>DiagnosisCode</th>\n",
       "      <th>ProcedureCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>803168</td>\n",
       "      <td>719163</td>\n",
       "      <td>733509</td>\n",
       "      <td>733515</td>\n",
       "      <td>733509</td>\n",
       "      <td>733515</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1970, 4019, 5853, 7843, 2768, 71590, 2724, 19...</td>\n",
       "      <td>[None, None, None, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>803168</td>\n",
       "      <td>719163</td>\n",
       "      <td>733427</td>\n",
       "      <td>733439</td>\n",
       "      <td>733427</td>\n",
       "      <td>733439</td>\n",
       "      <td>...</td>\n",
       "      <td>7769.0</td>\n",
       "      <td>5849.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[4240, 2639, 2948, 40390, 45821, 28489, 5854, ...</td>\n",
       "      <td>[7769.0, 5849.0, None, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>803168</td>\n",
       "      <td>719163</td>\n",
       "      <td>733697</td>\n",
       "      <td>733715</td>\n",
       "      <td>733697</td>\n",
       "      <td>733715</td>\n",
       "      <td>...</td>\n",
       "      <td>9338.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[V5789, 4168, 73313, 7812, 7993, 78830, 72273,...</td>\n",
       "      <td>[9338.0, None, None, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>803168</td>\n",
       "      <td>719163</td>\n",
       "      <td>733705</td>\n",
       "      <td>733709</td>\n",
       "      <td>733705</td>\n",
       "      <td>733709</td>\n",
       "      <td>...</td>\n",
       "      <td>8154.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[71535, 71960, 4019, V1202, 4240, 2449, 2768, ...</td>\n",
       "      <td>[8154.0, None, None, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>803168</td>\n",
       "      <td>719163</td>\n",
       "      <td>733415</td>\n",
       "      <td>733419</td>\n",
       "      <td>733415</td>\n",
       "      <td>733419</td>\n",
       "      <td>...</td>\n",
       "      <td>8543.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[2330, None, None, None, None, None, None, Non...</td>\n",
       "      <td>[8543.0, None, None, None, None]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  NoPhysician  NoOfDiag  NoOfProc  ORD_DOD  ORD_DOB  ORD_ClaimStartDt  \\\n",
       "0   66            1         9         0   803168   719163            733509   \n",
       "1   95            3         9         2   803168   719163            733427   \n",
       "2   87            2         9         1   803168   719163            733697   \n",
       "3   79            3         7         1   803168   719163            733705   \n",
       "4   83            2         1         1   803168   719163            733415   \n",
       "\n",
       "   ORD_ClaimEndDt  ORD_AdmissionDt  ORD_DischargeDt  ...  ClmProcedureCode_1  \\\n",
       "0          733515           733509           733515  ...                None   \n",
       "1          733439           733427           733439  ...              7769.0   \n",
       "2          733715           733697           733715  ...              9338.0   \n",
       "3          733709           733705           733709  ...              8154.0   \n",
       "4          733419           733415           733419  ...              8543.0   \n",
       "\n",
       "   ClmProcedureCode_2  ClmProcedureCode_3  ClmProcedureCode_4  \\\n",
       "0                None                None                None   \n",
       "1              5849.0                None                None   \n",
       "2                None                None                None   \n",
       "3                None                None                None   \n",
       "4                None                None                None   \n",
       "\n",
       "  ClmProcedureCode_5 AttendingPhysicianPresent OtherPhysicianPresent  \\\n",
       "0               None                         1                     0   \n",
       "1               None                         1                     1   \n",
       "2               None                         1                     0   \n",
       "3               None                         1                     1   \n",
       "4               None                         1                     0   \n",
       "\n",
       "  OperatingPhysicianPresent  \\\n",
       "0                         0   \n",
       "1                         1   \n",
       "2                         1   \n",
       "3                         1   \n",
       "4                         1   \n",
       "\n",
       "                                       DiagnosisCode  \\\n",
       "0  [1970, 4019, 5853, 7843, 2768, 71590, 2724, 19...   \n",
       "1  [4240, 2639, 2948, 40390, 45821, 28489, 5854, ...   \n",
       "2  [V5789, 4168, 73313, 7812, 7993, 78830, 72273,...   \n",
       "3  [71535, 71960, 4019, V1202, 4240, 2449, 2768, ...   \n",
       "4  [2330, None, None, None, None, None, None, Non...   \n",
       "\n",
       "                        ProcedureCode  \n",
       "0      [None, None, None, None, None]  \n",
       "1  [7769.0, 5849.0, None, None, None]  \n",
       "2    [9338.0, None, None, None, None]  \n",
       "3    [8154.0, None, None, None, None]  \n",
       "4    [8543.0, None, None, None, None]  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xlab2_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifcation Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:41:17.645065Z",
     "start_time": "2020-07-05T05:41:17.637562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Yes\n",
       "1        Yes\n",
       "2        Yes\n",
       "3        Yes\n",
       "4        Yes\n",
       "        ... \n",
       "40469     No\n",
       "40470     No\n",
       "40471     No\n",
       "40472     No\n",
       "40473     No\n",
       "Name: PotentialFraud, Length: 40474, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab2_df['PotentialFraud']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:41:28.838576Z",
     "start_time": "2020-07-05T05:41:27.787877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>NoPhysician</th>\n",
       "      <th>NoOfDiag</th>\n",
       "      <th>NoOfProc</th>\n",
       "      <th>ORD_DOD</th>\n",
       "      <th>ORD_DOB</th>\n",
       "      <th>ORD_ClaimStartDt</th>\n",
       "      <th>ORD_ClaimEndDt</th>\n",
       "      <th>ORD_AdmissionDt</th>\n",
       "      <th>ORD_DischargeDt</th>\n",
       "      <th>...</th>\n",
       "      <th>DiagnosisGroupCode_986</th>\n",
       "      <th>DiagnosisGroupCode_987</th>\n",
       "      <th>DiagnosisGroupCode_988</th>\n",
       "      <th>DiagnosisGroupCode_989</th>\n",
       "      <th>DiagnosisGroupCode_998</th>\n",
       "      <th>DiagnosisGroupCode_999</th>\n",
       "      <th>DiagnosisGroupCode_OTH</th>\n",
       "      <th>AttendingPhysicianPresent_1</th>\n",
       "      <th>OtherPhysicianPresent_1</th>\n",
       "      <th>OperatingPhysicianPresent_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>803168</td>\n",
       "      <td>719163</td>\n",
       "      <td>733509</td>\n",
       "      <td>733515</td>\n",
       "      <td>733509</td>\n",
       "      <td>733515</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>803168</td>\n",
       "      <td>719163</td>\n",
       "      <td>733427</td>\n",
       "      <td>733439</td>\n",
       "      <td>733427</td>\n",
       "      <td>733439</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>803168</td>\n",
       "      <td>719163</td>\n",
       "      <td>733697</td>\n",
       "      <td>733715</td>\n",
       "      <td>733697</td>\n",
       "      <td>733715</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>803168</td>\n",
       "      <td>719163</td>\n",
       "      <td>733705</td>\n",
       "      <td>733709</td>\n",
       "      <td>733705</td>\n",
       "      <td>733709</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>803168</td>\n",
       "      <td>719163</td>\n",
       "      <td>733415</td>\n",
       "      <td>733419</td>\n",
       "      <td>733415</td>\n",
       "      <td>733419</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9095 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  NoPhysician  NoOfDiag  NoOfProc  ORD_DOD  ORD_DOB  ORD_ClaimStartDt  \\\n",
       "0   66            1         9         0   803168   719163            733509   \n",
       "1   95            3         9         2   803168   719163            733427   \n",
       "2   87            2         9         1   803168   719163            733697   \n",
       "3   79            3         7         1   803168   719163            733705   \n",
       "4   83            2         1         1   803168   719163            733415   \n",
       "\n",
       "   ORD_ClaimEndDt  ORD_AdmissionDt  ORD_DischargeDt  ...  \\\n",
       "0          733515           733509           733515  ...   \n",
       "1          733439           733427           733439  ...   \n",
       "2          733715           733697           733715  ...   \n",
       "3          733709           733705           733709  ...   \n",
       "4          733419           733415           733419  ...   \n",
       "\n",
       "   DiagnosisGroupCode_986  DiagnosisGroupCode_987  DiagnosisGroupCode_988  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       1                       0   \n",
       "2                       0                       0                       0   \n",
       "3                       0                       0                       0   \n",
       "4                       0                       0                       0   \n",
       "\n",
       "   DiagnosisGroupCode_989  DiagnosisGroupCode_998  DiagnosisGroupCode_999  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "2                       0                       0                       0   \n",
       "3                       0                       0                       0   \n",
       "4                       0                       0                       0   \n",
       "\n",
       "   DiagnosisGroupCode_OTH  AttendingPhysicianPresent_1  \\\n",
       "0                       0                            1   \n",
       "1                       0                            1   \n",
       "2                       0                            1   \n",
       "3                       0                            1   \n",
       "4                       0                            1   \n",
       "\n",
       "   OtherPhysicianPresent_1  OperatingPhysicianPresent_1  \n",
       "0                        0                            0  \n",
       "1                        1                            1  \n",
       "2                        0                            1  \n",
       "3                        1                            1  \n",
       "4                        0                            1  \n",
       "\n",
       "[5 rows x 9095 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:41:31.951486Z",
     "start_time": "2020-07-05T05:41:31.940970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        26000.0\n",
       "1        19000.0\n",
       "2        17000.0\n",
       "3        13000.0\n",
       "4         3000.0\n",
       "          ...   \n",
       "40469    12000.0\n",
       "40470     5000.0\n",
       "40471    14000.0\n",
       "40472    10000.0\n",
       "40473     6000.0\n",
       "Name: InscClaimAmtReimbursed, Length: 40474, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:52:39.913640Z",
     "start_time": "2020-07-05T03:52:39.840958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>NoPhysician</th>\n",
       "      <th>NoOfDiag</th>\n",
       "      <th>NoOfProc</th>\n",
       "      <th>ORD_DOD</th>\n",
       "      <th>ORD_DOB</th>\n",
       "      <th>ORD_ClaimStartDt</th>\n",
       "      <th>ORD_ClaimEndDt</th>\n",
       "      <th>ORD_AdmissionDt</th>\n",
       "      <th>ORD_DischargeDt</th>\n",
       "      <th>DaysAdmitted</th>\n",
       "      <th>IPAnnualReimbursementAmt</th>\n",
       "      <th>IPAnnualDeductibleAmt</th>\n",
       "      <th>InscClaimAmtReimbursed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.0</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>73.181598</td>\n",
       "      <td>1.701883</td>\n",
       "      <td>8.087365</td>\n",
       "      <td>0.733607</td>\n",
       "      <td>802621.757573</td>\n",
       "      <td>719163.0</td>\n",
       "      <td>733577.740698</td>\n",
       "      <td>733583.400949</td>\n",
       "      <td>733577.734867</td>\n",
       "      <td>733583.400035</td>\n",
       "      <td>6.665168</td>\n",
       "      <td>17528.645056</td>\n",
       "      <td>1887.461234</td>\n",
       "      <td>10087.884074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.187784</td>\n",
       "      <td>0.618905</td>\n",
       "      <td>1.851830</td>\n",
       "      <td>0.761113</td>\n",
       "      <td>6138.365984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.884925</td>\n",
       "      <td>104.658338</td>\n",
       "      <td>104.888036</td>\n",
       "      <td>104.659525</td>\n",
       "      <td>5.638538</td>\n",
       "      <td>17562.156402</td>\n",
       "      <td>1686.848629</td>\n",
       "      <td>10303.099402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>733439.000000</td>\n",
       "      <td>719163.0</td>\n",
       "      <td>733373.000000</td>\n",
       "      <td>733408.000000</td>\n",
       "      <td>733373.000000</td>\n",
       "      <td>733408.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>803168.000000</td>\n",
       "      <td>719163.0</td>\n",
       "      <td>733486.000000</td>\n",
       "      <td>733492.000000</td>\n",
       "      <td>733486.000000</td>\n",
       "      <td>733492.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>1068.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>803168.000000</td>\n",
       "      <td>719163.0</td>\n",
       "      <td>733574.000000</td>\n",
       "      <td>733580.000000</td>\n",
       "      <td>733574.000000</td>\n",
       "      <td>733580.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>1068.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>803168.000000</td>\n",
       "      <td>719163.0</td>\n",
       "      <td>733667.000000</td>\n",
       "      <td>733673.000000</td>\n",
       "      <td>733667.000000</td>\n",
       "      <td>733673.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>22000.000000</td>\n",
       "      <td>2136.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>803168.000000</td>\n",
       "      <td>719163.0</td>\n",
       "      <td>733772.000000</td>\n",
       "      <td>733772.000000</td>\n",
       "      <td>733772.000000</td>\n",
       "      <td>733772.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>161470.000000</td>\n",
       "      <td>38272.000000</td>\n",
       "      <td>125000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age   NoPhysician      NoOfDiag      NoOfProc        ORD_DOD  \\\n",
       "count  40474.000000  40474.000000  40474.000000  40474.000000   40474.000000   \n",
       "mean      73.181598      1.701883      8.087365      0.733607  802621.757573   \n",
       "std       13.187784      0.618905      1.851830      0.761113    6138.365984   \n",
       "min       25.000000      0.000000      1.000000      0.000000  733439.000000   \n",
       "25%       67.000000      1.000000      8.000000      0.000000  803168.000000   \n",
       "50%       74.000000      2.000000      9.000000      1.000000  803168.000000   \n",
       "75%       82.000000      2.000000      9.000000      1.000000  803168.000000   \n",
       "max      101.000000      3.000000     10.000000      5.000000  803168.000000   \n",
       "\n",
       "        ORD_DOB  ORD_ClaimStartDt  ORD_ClaimEndDt  ORD_AdmissionDt  \\\n",
       "count   40474.0      40474.000000    40474.000000     40474.000000   \n",
       "mean   719163.0     733577.740698   733583.400949    733577.734867   \n",
       "std         0.0        104.884925      104.658338       104.888036   \n",
       "min    719163.0     733373.000000   733408.000000    733373.000000   \n",
       "25%    719163.0     733486.000000   733492.000000    733486.000000   \n",
       "50%    719163.0     733574.000000   733580.000000    733574.000000   \n",
       "75%    719163.0     733667.000000   733673.000000    733667.000000   \n",
       "max    719163.0     733772.000000   733772.000000    733772.000000   \n",
       "\n",
       "       ORD_DischargeDt  DaysAdmitted  IPAnnualReimbursementAmt  \\\n",
       "count     40474.000000  40474.000000              40474.000000   \n",
       "mean     733583.400035      6.665168              17528.645056   \n",
       "std         104.659525      5.638538              17562.156402   \n",
       "min      733408.000000      1.000000                  0.000000   \n",
       "25%      733492.000000      3.000000               6000.000000   \n",
       "50%      733580.000000      5.000000              12000.000000   \n",
       "75%      733673.000000      8.000000              22000.000000   \n",
       "max      733772.000000     36.000000             161470.000000   \n",
       "\n",
       "       IPAnnualDeductibleAmt  InscClaimAmtReimbursed  \n",
       "count           40474.000000            40474.000000  \n",
       "mean             1887.461234            10087.884074  \n",
       "std              1686.848629            10303.099402  \n",
       "min                 0.000000                0.000000  \n",
       "25%              1068.000000             4000.000000  \n",
       "50%              1068.000000             7000.000000  \n",
       "75%              2136.000000            12000.000000  \n",
       "max             38272.000000           125000.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xlab2_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Classification - Provider Fraud\n",
    "We will predict possible fraudulent claims and measure effectiveness using 10-fold cross validation and focus on attaining high metrics in F-1, recall and precision, in that order. Precision measures the percentage of fraudulent predictions which are truly fraudulent, and recall measures the total percentage of fraudulent claims correctly identified. These two metrics have been identified as most appropriate, due to our objective of correctly identifying fraudulent claims.  We want a high recall score, but not at the expense of precision (we can get 100% recall by classifying everyone as fraudulent).  F-1 should give us a good balance between the two, as they have an inverse relationship, where increasing one often decreases the other. \n",
    "\n",
    "## Task 2: Regression \n",
    "__TODO:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Matrix Conversion and Test/Train Split\n",
    "The minMax Scaler returns a dense numpy array.  Because we have so many features, we need to transform the data back into a sparse matrix for efficient . **CSC(Compressed Sparse Column)** is more efficient at accessing column-vectors or column operations, generally, as it is stored as arrays of columns and their value at each row.\n",
    "\n",
    "We chose to scale, convert to sparse and do test/train splits all before our pipeline in order to save processing time in the pipeline and grid search model execution steps.  The scaler takes a few minutes, and we don't want to introduce this lag to the repetitive pipeline.  This also gives us the advantage of using the exact same test/train splits for all models for a fair evaluation.  \n",
    "\n",
    "## Cross Validation Method\n",
    "\n",
    "We're using 10 fold cross validation because it will utilize it's own splits of the training data and help to ensures we don't overfit to the training data, in addition to witholding test data entirely from the models so we can more effectively evaluate generalization ability on a dataset that hasn't been seen by our models.  It has another benefit of using 10 different test/train splits of the training data, so if we happen by chance to get the best possible prediction outcome the first time we run it, we have 9 more chances to even out our prediction metrics using an average of the 10 runs.  This greatly increases our confidence that we are correctly reporting model performance metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:42:04.049682Z",
     "start_time": "2020-07-05T05:41:46.402188Z"
    }
   },
   "outputs": [],
   "source": [
    "X = csc_matrix(X1)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,target_df,test_size=0.2,random_state=lab2_random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluations 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function Defnitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 testPerformance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a helper function designed to help test our models after hypertuning.  It takes a pipeline object and a parameter array and executes the grid search, as well as running a new cross validation and confusion matrix on the test data that we withheld from the training set.\n",
    "\n",
    "First it creates a cross validation object, with 10-fold cross validation and an 80/20 test split.  Next it fits our training data to the model(s) listed in the grid, then it executes each model once for each combination of parameters given in the parameter array.  After obtaining the results, it displays the metrics data we defined (ROC, Accuracy, Precision, Recall and F1), with the best model being chosen with the highest F1 score.  After displaying these results, it performs 10 fold cross validation on the test data (witheld from the training data) to see how well the model performs on new data outside of the training set.  We then create a confusion matrix which can highlight models that look good on paper (high scores), but are actually poor performers.  We see this in cases where recall gets really great scores, but the vast majority of claims get classified as fraudulent, which is not realistic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:46:31.276260Z",
     "start_time": "2020-07-05T05:46:31.245710Z"
    }
   },
   "outputs": [],
   "source": [
    "def testPerformance(pipeline, params,n1_jobs=-1):\n",
    "    \n",
    "    cv = ShuffleSplit(n_splits=10, test_size=.2, random_state=lab2_random_state)\n",
    "    \n",
    "    #Perform the grid search using accuracy as a metric during cross validation.\n",
    "    grid = GridSearchCV(pipeline, params, cv=cv, \n",
    "                        scoring=['roc_auc','accuracy','f1','recall','precision'], \n",
    "                        n_jobs=n1_jobs, refit='f1')\n",
    "    \n",
    "    #Use the best features from recursive feature elimination during the grid search\n",
    "    start_time = timeit.default_timer()\n",
    "    grid.fit(X_train, y_train)\n",
    "    grid_time = timeit.default_timer() - start_time\n",
    "    #display the best pipeline model identified during the grid search\n",
    "    print(\"\\ngrid time: \", grid_time)\n",
    "\n",
    "    gridResults = pd.DataFrame.from_dict(grid.cv_results_)\n",
    "    \n",
    "    \n",
    "    fileName = str(grid.best_estimator_[0]).split('(')[0]+'_CV_Results.xlsx'\n",
    "    gridResults.to_excel(fileName)\n",
    "    \n",
    "    \n",
    "    fewResults = pd.DataFrame(grid.cv_results_)[['params','mean_fit_time','mean_test_roc_auc',\"mean_test_accuracy\",\"mean_test_precision\",\"mean_test_recall\",\"mean_test_f1\"]].dropna()\n",
    "    display(fewResults.sort_values(by='mean_test_f1'))\n",
    "    \n",
    "    print('Best Estimator   : ',grid.best_estimator_[0])\n",
    "    print('Best Parameters  : ',grid.best_params_)\n",
    "    print('Best Scores      : ',grid.best_score_)    \n",
    "\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    clf = grid.best_estimator_[0]\n",
    "    # fit the model\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    fit_time = timeit.default_timer() - start_time\n",
    "\n",
    "    # do 10-fold cross validation:\n",
    "    f1scores  = cross_val_score(clf, X_test, y_test, cv=cv, scoring='f1'       , n_jobs=n1_jobs)\n",
    "    PreScores = cross_val_score(clf, X_test, y_test, cv=cv, scoring='precision', n_jobs=n1_jobs)\n",
    "    RecScores = cross_val_score(clf, X_test, y_test, cv=cv, scoring='recall'   , n_jobs=n1_jobs)\n",
    "    \n",
    "    print('\\n10-fold Cross Validation results:')\n",
    "    print('---------------------------------')\n",
    "    print('F1 scores:', f1scores)\n",
    "    print('\\nPrecision scores', PreScores)\n",
    "    print('\\nRecall scores', RecScores)\n",
    "\n",
    "    print('\\nAverage F1: ',np.average(f1scores))\n",
    "    print('Min F1: ',np.min(f1scores))\n",
    "    print('Max F1: ',np.max(f1scores))\n",
    "    print('\\nAverage Precision: ',np.average(PreScores))\n",
    "    print('Min Precision: ',np.min(PreScores))\n",
    "    print('Max Precision: ',np.max(PreScores))\n",
    "    print('\\nAverage Recall: ',np.average(RecScores))\n",
    "    print('Min Recall: ',np.min(RecScores))\n",
    "    print('Max Recall: ',np.max(RecScores))\n",
    "\n",
    "    cv_time = timeit.default_timer() - start_time - fit_time\n",
    "\n",
    "    # Build Confusion Matrix to test generality:\n",
    "    y_pred=clf.predict(X_test)\n",
    "    cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    class_names=[0,1] # name  of classes\n",
    "    fig, ax = plt.subplots()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    # create heatmap\n",
    "    sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    plt.tight_layout()\n",
    "    plt.title('Potential Fraud Confusion matrix', y=1.1)\n",
    "    plt.ylabel('Actual Fraud')\n",
    "    plt.xlabel('Predicted Fraud')\n",
    "    plt.show\n",
    "    print('\\nSingle Run results:')\n",
    "    print('---------------------------------')\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "    print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "    print(\"F1:\",metrics.f1_score(y_test, y_pred))\n",
    "    \n",
    "    print(\"\\nFit time: \", fit_time)\n",
    "    print(\"CV time: \", cv_time)\n",
    "    print(\"Total time: \", timeit.default_timer() - start_time)\n",
    "    return(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Display Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:46:34.483043Z",
     "start_time": "2020-07-05T05:46:34.474857Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_weights(grid_object,class_model=\"logistic\"):\n",
    "    # summarize feature importance\n",
    "    \n",
    "    if ( class_model == \"rf\" ):\n",
    "      zip_vars = zip(ipdata.columns,grid_object.best_estimator_[0].feature_importances_) # combine attributes    \n",
    "    else:\n",
    "      zip_vars = zip(ipdata.columns,grid_object.best_estimator_[0].coef_.T) # combine attributes\n",
    "    \n",
    "    FeatureWeights = pd.DataFrame(list(zip_vars), columns=['Feature', 'Weight'])\n",
    "    display(FeatureWeights.sort_values(by='Weight',ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 lab2_grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:46:38.509526Z",
     "start_time": "2020-07-05T05:46:38.497719Z"
    }
   },
   "outputs": [],
   "source": [
    "def lab2_grid_search(estimator,results_filename,\n",
    "                     parm_grid,splits,X,y):\n",
    "\n",
    "    cr_v = ShuffleSplit(n_splits=splits, test_size=.2, random_state=86)\n",
    "    \n",
    "    lab2_scoring = {'AUC'      : 'roc_auc', \n",
    "                    'Accuracy'  : make_scorer(accuracy_score),\n",
    "                    'Recall'    : make_scorer(recall_score),\n",
    "                    'Precision' : make_scorer(precision_score),\n",
    "                    'F1'        : make_scorer(f1_score)\n",
    "                  }\n",
    "\n",
    "    clf = GridSearchCV(estimator,\n",
    "                       param_grid = parm_grid, cv = cr_v, \n",
    "                       verbose=True, n_jobs=1,\n",
    "                       scoring=lab2_scoring,\n",
    "                       refit='AUC', return_train_score=True )\n",
    "        \n",
    "    clf_fit = clf.fit(X, y)\n",
    "    \n",
    "    results= pd.DataFrame.from_dict(clf_fit.cv_results_)\n",
    "    results.to_csv('data/'+results_filename)\n",
    "    \n",
    "    return clf_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T04:05:12.479081Z",
     "start_time": "2020-07-05T04:05:12.471475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': 100,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg  = LogisticRegression(random_state=lab2_random_state)\n",
    "log_pipe = make_pipeline(log_reg)\n",
    "log_reg.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T04:05:51.112258Z",
     "start_time": "2020-07-05T04:05:51.106802Z"
    }
   },
   "outputs": [],
   "source": [
    "log_param_grid = [\n",
    "      {'logisticregression__penalty'      : ['l1'],\n",
    "       'logisticregression__C'            : np.logspace(-4, 4, 20),\n",
    "       'logisticregression__solver'       : ['liblinear'],\n",
    "       'logisticregression__random_state' : [lab2_random_state]},\n",
    "      {'logisticregression__penalty'      : ['l2'],\n",
    "       'logisticregression__C'            : np.logspace(-4, 4, 20),\n",
    "       'logisticregression__solver'       : ['sag'],\n",
    "       'logisticregression__max_iter'     : [800],\n",
    "       'logisticregression__random_state' : [lab2_random_state]}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T04:10:09.294868Z",
     "start_time": "2020-07-05T04:05:52.800466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "grid time:  262.74444518302334\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'logisticregression__C': 0.0001, 'logisticreg...</td>\n",
       "      <td>0.099025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.421649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'logisticregression__C': 0.000263665089873035...</td>\n",
       "      <td>0.121682</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.421649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'logisticregression__C': 10000.0, 'logisticre...</td>\n",
       "      <td>12.371187</td>\n",
       "      <td>0.572839</td>\n",
       "      <td>0.574506</td>\n",
       "      <td>0.626488</td>\n",
       "      <td>0.654579</td>\n",
       "      <td>0.640195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'logisticregression__C': 3792.690190732246, '...</td>\n",
       "      <td>14.144071</td>\n",
       "      <td>0.573006</td>\n",
       "      <td>0.574552</td>\n",
       "      <td>0.626483</td>\n",
       "      <td>0.654794</td>\n",
       "      <td>0.640295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'logisticregression__C': 1438.44988828766, 'l...</td>\n",
       "      <td>13.016100</td>\n",
       "      <td>0.573499</td>\n",
       "      <td>0.574768</td>\n",
       "      <td>0.626648</td>\n",
       "      <td>0.655033</td>\n",
       "      <td>0.640496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'logisticregression__C': 545.5594781168514, '...</td>\n",
       "      <td>16.764305</td>\n",
       "      <td>0.574389</td>\n",
       "      <td>0.575216</td>\n",
       "      <td>0.626988</td>\n",
       "      <td>0.655543</td>\n",
       "      <td>0.640916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'logisticregression__C': 206.913808111479, 'l...</td>\n",
       "      <td>19.962300</td>\n",
       "      <td>0.575775</td>\n",
       "      <td>0.575463</td>\n",
       "      <td>0.627124</td>\n",
       "      <td>0.656022</td>\n",
       "      <td>0.641218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'logisticregression__C': 78.47599703514607, '...</td>\n",
       "      <td>21.700908</td>\n",
       "      <td>0.578384</td>\n",
       "      <td>0.576760</td>\n",
       "      <td>0.628013</td>\n",
       "      <td>0.657894</td>\n",
       "      <td>0.642576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>{'logisticregression__C': 1438.44988828766, 'l...</td>\n",
       "      <td>28.308225</td>\n",
       "      <td>0.580117</td>\n",
       "      <td>0.577409</td>\n",
       "      <td>0.627948</td>\n",
       "      <td>0.660849</td>\n",
       "      <td>0.643952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>{'logisticregression__C': 3792.690190732246, '...</td>\n",
       "      <td>28.232879</td>\n",
       "      <td>0.579938</td>\n",
       "      <td>0.577486</td>\n",
       "      <td>0.628014</td>\n",
       "      <td>0.660903</td>\n",
       "      <td>0.644013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>{'logisticregression__C': 10000.0, 'logisticre...</td>\n",
       "      <td>22.638652</td>\n",
       "      <td>0.579870</td>\n",
       "      <td>0.577532</td>\n",
       "      <td>0.628061</td>\n",
       "      <td>0.660904</td>\n",
       "      <td>0.644038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>{'logisticregression__C': 545.5594781168514, '...</td>\n",
       "      <td>28.302372</td>\n",
       "      <td>0.580584</td>\n",
       "      <td>0.577795</td>\n",
       "      <td>0.628250</td>\n",
       "      <td>0.661251</td>\n",
       "      <td>0.644302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>{'logisticregression__C': 206.913808111479, 'l...</td>\n",
       "      <td>28.265629</td>\n",
       "      <td>0.581754</td>\n",
       "      <td>0.578567</td>\n",
       "      <td>0.628812</td>\n",
       "      <td>0.662244</td>\n",
       "      <td>0.645068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'logisticregression__C': 29.763514416313132, ...</td>\n",
       "      <td>20.088450</td>\n",
       "      <td>0.582862</td>\n",
       "      <td>0.579555</td>\n",
       "      <td>0.629884</td>\n",
       "      <td>0.662085</td>\n",
       "      <td>0.645552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{'logisticregression__C': 78.47599703514607, '...</td>\n",
       "      <td>28.343902</td>\n",
       "      <td>0.584413</td>\n",
       "      <td>0.580111</td>\n",
       "      <td>0.629744</td>\n",
       "      <td>0.664972</td>\n",
       "      <td>0.646849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{'logisticregression__C': 29.763514416313132, ...</td>\n",
       "      <td>23.829468</td>\n",
       "      <td>0.589229</td>\n",
       "      <td>0.582674</td>\n",
       "      <td>0.631030</td>\n",
       "      <td>0.670440</td>\n",
       "      <td>0.650109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'logisticregression__C': 11.288378916846883, ...</td>\n",
       "      <td>17.611577</td>\n",
       "      <td>0.590167</td>\n",
       "      <td>0.583925</td>\n",
       "      <td>0.632117</td>\n",
       "      <td>0.671267</td>\n",
       "      <td>0.651073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'logisticregression__C': 11.288378916846883, ...</td>\n",
       "      <td>13.232832</td>\n",
       "      <td>0.595951</td>\n",
       "      <td>0.587431</td>\n",
       "      <td>0.633805</td>\n",
       "      <td>0.678974</td>\n",
       "      <td>0.655570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'logisticregression__C': 4.281332398719396, '...</td>\n",
       "      <td>14.167302</td>\n",
       "      <td>0.602240</td>\n",
       "      <td>0.592449</td>\n",
       "      <td>0.636590</td>\n",
       "      <td>0.688304</td>\n",
       "      <td>0.661396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'logisticregression__C': 4.281332398719396, '...</td>\n",
       "      <td>6.608211</td>\n",
       "      <td>0.604420</td>\n",
       "      <td>0.593267</td>\n",
       "      <td>0.636820</td>\n",
       "      <td>0.690715</td>\n",
       "      <td>0.662626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'logisticregression__C': 1.623776739188721, '...</td>\n",
       "      <td>3.187096</td>\n",
       "      <td>0.614477</td>\n",
       "      <td>0.600463</td>\n",
       "      <td>0.639832</td>\n",
       "      <td>0.707453</td>\n",
       "      <td>0.671899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'logisticregression__C': 1.623776739188721, '...</td>\n",
       "      <td>7.781393</td>\n",
       "      <td>0.619992</td>\n",
       "      <td>0.604957</td>\n",
       "      <td>0.641979</td>\n",
       "      <td>0.716686</td>\n",
       "      <td>0.677236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'logisticregression__C': 0.615848211066026, '...</td>\n",
       "      <td>2.232658</td>\n",
       "      <td>0.625413</td>\n",
       "      <td>0.608200</td>\n",
       "      <td>0.642564</td>\n",
       "      <td>0.727047</td>\n",
       "      <td>0.682152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'logisticregression__C': 0.23357214690901212,...</td>\n",
       "      <td>6.088042</td>\n",
       "      <td>0.635706</td>\n",
       "      <td>0.616198</td>\n",
       "      <td>0.644835</td>\n",
       "      <td>0.748929</td>\n",
       "      <td>0.692951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'logisticregression__C': 0.615848211066026, '...</td>\n",
       "      <td>4.613144</td>\n",
       "      <td>0.641422</td>\n",
       "      <td>0.621279</td>\n",
       "      <td>0.647428</td>\n",
       "      <td>0.758059</td>\n",
       "      <td>0.698351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'logisticregression__C': 0.08858667904100823,...</td>\n",
       "      <td>2.988222</td>\n",
       "      <td>0.643511</td>\n",
       "      <td>0.623178</td>\n",
       "      <td>0.644310</td>\n",
       "      <td>0.777961</td>\n",
       "      <td>0.704819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'logisticregression__C': 0.23357214690901212,...</td>\n",
       "      <td>1.811559</td>\n",
       "      <td>0.655456</td>\n",
       "      <td>0.630528</td>\n",
       "      <td>0.646704</td>\n",
       "      <td>0.796157</td>\n",
       "      <td>0.713655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'logisticregression__C': 0.03359818286283781,...</td>\n",
       "      <td>1.881979</td>\n",
       "      <td>0.646553</td>\n",
       "      <td>0.624413</td>\n",
       "      <td>0.637732</td>\n",
       "      <td>0.811812</td>\n",
       "      <td>0.714278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'logisticregression__C': 0.012742749857031334...</td>\n",
       "      <td>4.214845</td>\n",
       "      <td>0.643473</td>\n",
       "      <td>0.615581</td>\n",
       "      <td>0.620791</td>\n",
       "      <td>0.861925</td>\n",
       "      <td>0.721706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'logisticregression__C': 0.08858667904100823,...</td>\n",
       "      <td>0.945595</td>\n",
       "      <td>0.655155</td>\n",
       "      <td>0.626174</td>\n",
       "      <td>0.633548</td>\n",
       "      <td>0.838996</td>\n",
       "      <td>0.721896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'logisticregression__C': 0.03359818286283781,...</td>\n",
       "      <td>0.943996</td>\n",
       "      <td>0.637820</td>\n",
       "      <td>0.605806</td>\n",
       "      <td>0.607342</td>\n",
       "      <td>0.900779</td>\n",
       "      <td>0.725490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'logisticregression__C': 0.012742749857031334...</td>\n",
       "      <td>0.864071</td>\n",
       "      <td>0.570866</td>\n",
       "      <td>0.580358</td>\n",
       "      <td>0.582730</td>\n",
       "      <td>0.967353</td>\n",
       "      <td>0.727223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'logisticregression__C': 0.004832930238571752...</td>\n",
       "      <td>3.763043</td>\n",
       "      <td>0.634803</td>\n",
       "      <td>0.600324</td>\n",
       "      <td>0.599839</td>\n",
       "      <td>0.928291</td>\n",
       "      <td>0.728733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'logisticregression__C': 0.001832980710832435...</td>\n",
       "      <td>2.613930</td>\n",
       "      <td>0.623376</td>\n",
       "      <td>0.585191</td>\n",
       "      <td>0.584363</td>\n",
       "      <td>0.979508</td>\n",
       "      <td>0.731988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'logisticregression__C': 0.004832930238571752...</td>\n",
       "      <td>0.790402</td>\n",
       "      <td>0.523617</td>\n",
       "      <td>0.578258</td>\n",
       "      <td>0.578318</td>\n",
       "      <td>0.999790</td>\n",
       "      <td>0.732754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'logisticregression__C': 0.001832980710832435...</td>\n",
       "      <td>0.624130</td>\n",
       "      <td>0.500242</td>\n",
       "      <td>0.578351</td>\n",
       "      <td>0.578351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'logisticregression__C': 0.000695192796177560...</td>\n",
       "      <td>0.408530</td>\n",
       "      <td>0.499888</td>\n",
       "      <td>0.578351</td>\n",
       "      <td>0.578351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'logisticregression__C': 0.0001, 'logisticreg...</td>\n",
       "      <td>0.865077</td>\n",
       "      <td>0.598562</td>\n",
       "      <td>0.578351</td>\n",
       "      <td>0.578351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'logisticregression__C': 0.000263665089873035...</td>\n",
       "      <td>1.146514</td>\n",
       "      <td>0.604169</td>\n",
       "      <td>0.578351</td>\n",
       "      <td>0.578351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'logisticregression__C': 0.000695192796177560...</td>\n",
       "      <td>1.842660</td>\n",
       "      <td>0.612657</td>\n",
       "      <td>0.578474</td>\n",
       "      <td>0.578422</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  mean_fit_time  \\\n",
       "0   {'logisticregression__C': 0.0001, 'logisticreg...       0.099025   \n",
       "1   {'logisticregression__C': 0.000263665089873035...       0.121682   \n",
       "19  {'logisticregression__C': 10000.0, 'logisticre...      12.371187   \n",
       "18  {'logisticregression__C': 3792.690190732246, '...      14.144071   \n",
       "17  {'logisticregression__C': 1438.44988828766, 'l...      13.016100   \n",
       "16  {'logisticregression__C': 545.5594781168514, '...      16.764305   \n",
       "15  {'logisticregression__C': 206.913808111479, 'l...      19.962300   \n",
       "14  {'logisticregression__C': 78.47599703514607, '...      21.700908   \n",
       "37  {'logisticregression__C': 1438.44988828766, 'l...      28.308225   \n",
       "38  {'logisticregression__C': 3792.690190732246, '...      28.232879   \n",
       "39  {'logisticregression__C': 10000.0, 'logisticre...      22.638652   \n",
       "36  {'logisticregression__C': 545.5594781168514, '...      28.302372   \n",
       "35  {'logisticregression__C': 206.913808111479, 'l...      28.265629   \n",
       "13  {'logisticregression__C': 29.763514416313132, ...      20.088450   \n",
       "34  {'logisticregression__C': 78.47599703514607, '...      28.343902   \n",
       "33  {'logisticregression__C': 29.763514416313132, ...      23.829468   \n",
       "12  {'logisticregression__C': 11.288378916846883, ...      17.611577   \n",
       "32  {'logisticregression__C': 11.288378916846883, ...      13.232832   \n",
       "11  {'logisticregression__C': 4.281332398719396, '...      14.167302   \n",
       "31  {'logisticregression__C': 4.281332398719396, '...       6.608211   \n",
       "30  {'logisticregression__C': 1.623776739188721, '...       3.187096   \n",
       "10  {'logisticregression__C': 1.623776739188721, '...       7.781393   \n",
       "29  {'logisticregression__C': 0.615848211066026, '...       2.232658   \n",
       "28  {'logisticregression__C': 0.23357214690901212,...       6.088042   \n",
       "9   {'logisticregression__C': 0.615848211066026, '...       4.613144   \n",
       "27  {'logisticregression__C': 0.08858667904100823,...       2.988222   \n",
       "8   {'logisticregression__C': 0.23357214690901212,...       1.811559   \n",
       "26  {'logisticregression__C': 0.03359818286283781,...       1.881979   \n",
       "25  {'logisticregression__C': 0.012742749857031334...       4.214845   \n",
       "7   {'logisticregression__C': 0.08858667904100823,...       0.945595   \n",
       "6   {'logisticregression__C': 0.03359818286283781,...       0.943996   \n",
       "5   {'logisticregression__C': 0.012742749857031334...       0.864071   \n",
       "24  {'logisticregression__C': 0.004832930238571752...       3.763043   \n",
       "23  {'logisticregression__C': 0.001832980710832435...       2.613930   \n",
       "4   {'logisticregression__C': 0.004832930238571752...       0.790402   \n",
       "3   {'logisticregression__C': 0.001832980710832435...       0.624130   \n",
       "2   {'logisticregression__C': 0.000695192796177560...       0.408530   \n",
       "20  {'logisticregression__C': 0.0001, 'logisticreg...       0.865077   \n",
       "21  {'logisticregression__C': 0.000263665089873035...       1.146514   \n",
       "22  {'logisticregression__C': 0.000695192796177560...       1.842660   \n",
       "\n",
       "    mean_test_roc_auc  mean_test_accuracy  mean_test_precision  \\\n",
       "0            0.500000            0.421649             0.000000   \n",
       "1            0.500000            0.421649             0.000000   \n",
       "19           0.572839            0.574506             0.626488   \n",
       "18           0.573006            0.574552             0.626483   \n",
       "17           0.573499            0.574768             0.626648   \n",
       "16           0.574389            0.575216             0.626988   \n",
       "15           0.575775            0.575463             0.627124   \n",
       "14           0.578384            0.576760             0.628013   \n",
       "37           0.580117            0.577409             0.627948   \n",
       "38           0.579938            0.577486             0.628014   \n",
       "39           0.579870            0.577532             0.628061   \n",
       "36           0.580584            0.577795             0.628250   \n",
       "35           0.581754            0.578567             0.628812   \n",
       "13           0.582862            0.579555             0.629884   \n",
       "34           0.584413            0.580111             0.629744   \n",
       "33           0.589229            0.582674             0.631030   \n",
       "12           0.590167            0.583925             0.632117   \n",
       "32           0.595951            0.587431             0.633805   \n",
       "11           0.602240            0.592449             0.636590   \n",
       "31           0.604420            0.593267             0.636820   \n",
       "30           0.614477            0.600463             0.639832   \n",
       "10           0.619992            0.604957             0.641979   \n",
       "29           0.625413            0.608200             0.642564   \n",
       "28           0.635706            0.616198             0.644835   \n",
       "9            0.641422            0.621279             0.647428   \n",
       "27           0.643511            0.623178             0.644310   \n",
       "8            0.655456            0.630528             0.646704   \n",
       "26           0.646553            0.624413             0.637732   \n",
       "25           0.643473            0.615581             0.620791   \n",
       "7            0.655155            0.626174             0.633548   \n",
       "6            0.637820            0.605806             0.607342   \n",
       "5            0.570866            0.580358             0.582730   \n",
       "24           0.634803            0.600324             0.599839   \n",
       "23           0.623376            0.585191             0.584363   \n",
       "4            0.523617            0.578258             0.578318   \n",
       "3            0.500242            0.578351             0.578351   \n",
       "2            0.499888            0.578351             0.578351   \n",
       "20           0.598562            0.578351             0.578351   \n",
       "21           0.604169            0.578351             0.578351   \n",
       "22           0.612657            0.578474             0.578422   \n",
       "\n",
       "    mean_test_recall  mean_test_f1  \n",
       "0           0.000000      0.000000  \n",
       "1           0.000000      0.000000  \n",
       "19          0.654579      0.640195  \n",
       "18          0.654794      0.640295  \n",
       "17          0.655033      0.640496  \n",
       "16          0.655543      0.640916  \n",
       "15          0.656022      0.641218  \n",
       "14          0.657894      0.642576  \n",
       "37          0.660849      0.643952  \n",
       "38          0.660903      0.644013  \n",
       "39          0.660904      0.644038  \n",
       "36          0.661251      0.644302  \n",
       "35          0.662244      0.645068  \n",
       "13          0.662085      0.645552  \n",
       "34          0.664972      0.646849  \n",
       "33          0.670440      0.650109  \n",
       "12          0.671267      0.651073  \n",
       "32          0.678974      0.655570  \n",
       "11          0.688304      0.661396  \n",
       "31          0.690715      0.662626  \n",
       "30          0.707453      0.671899  \n",
       "10          0.716686      0.677236  \n",
       "29          0.727047      0.682152  \n",
       "28          0.748929      0.692951  \n",
       "9           0.758059      0.698351  \n",
       "27          0.777961      0.704819  \n",
       "8           0.796157      0.713655  \n",
       "26          0.811812      0.714278  \n",
       "25          0.861925      0.721706  \n",
       "7           0.838996      0.721896  \n",
       "6           0.900779      0.725490  \n",
       "5           0.967353      0.727223  \n",
       "24          0.928291      0.728733  \n",
       "23          0.979508      0.731988  \n",
       "4           0.999790      0.732754  \n",
       "3           1.000000      0.732838  \n",
       "2           1.000000      0.732838  \n",
       "20          1.000000      0.732838  \n",
       "21          1.000000      0.732838  \n",
       "22          1.000000      0.732895  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator   :  LogisticRegression(C=0.0006951927961775605, class_weight=None, dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=800, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=100, solver='sag', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Best Parameters  :  {'logisticregression__C': 0.0006951927961775605, 'logisticregression__max_iter': 800, 'logisticregression__penalty': 'l2', 'logisticregression__random_state': 100, 'logisticregression__solver': 'sag'}\n",
      "Best Scores      :  0.7328952206467197\n",
      "\n",
      "10-fold Cross Validation results:\n",
      "---------------------------------\n",
      "F1 scores: [0.74007782 0.73416732 0.75509419 0.7282011  0.74738878 0.7381138\n",
      " 0.74007782 0.7236894  0.71762376 0.72519685]\n",
      "\n",
      "Precision scores [0.58739963 0.57998765 0.60654725 0.57257566 0.59666461 0.58492897\n",
      " 0.58739963 0.56701668 0.55960469 0.56886967]\n",
      "\n",
      "Recall scores [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "Average F1:  0.7349630841463491\n",
      "Min F1:  0.7176237623762376\n",
      "Max F1:  0.7550941945405613\n",
      "\n",
      "Average Precision:  0.5810994441012971\n",
      "Min Precision:  0.5596046942557134\n",
      "Max Precision:  0.6065472513897467\n",
      "\n",
      "Average Recall:  1.0\n",
      "Min Recall:  1.0\n",
      "Max Recall:  1.0\n",
      "\n",
      "Single Run results:\n",
      "---------------------------------\n",
      "Accuracy: 0.5820877084620136\n",
      "Precision: 0.5819104182133136\n",
      "Recall: 0.999150201827066\n",
      "F1: 0.7354757995152085\n",
      "\n",
      "Fit time:  0.6868977620033547\n",
      "CV time:  1.0218927320092916\n",
      "Total time:  1.8363781159860082\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_log_clf = testPerformance(log_pipe,log_param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a dataframe of features sorted by coefficient weight. It shows the top 5 negative an top 5 positive features for importance by how correlated they are with the response variable.  We calculated these weights by transposing the coefficient output from the logistic regression model, and using the Python Zip method to combine the coefficients with their corresponding feature (column) name. This gives us the feature names with their coefficient weight and preserves the index position as the label in a pandas dataframe, which we can then sort as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T21:15:13.947959Z",
     "start_time": "2020-07-04T21:15:13.702993Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6092</th>\n",
       "      <td>State_36</td>\n",
       "      <td>[0.10961150924561747]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6089</th>\n",
       "      <td>State_33</td>\n",
       "      <td>[0.0823917970612495]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6136</th>\n",
       "      <td>County_160</td>\n",
       "      <td>[0.07824457599120582]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>State_10</td>\n",
       "      <td>[0.06418713698370881]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>State_7</td>\n",
       "      <td>[0.06101368747196894]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6067</th>\n",
       "      <td>State_11</td>\n",
       "      <td>[-0.06199798589704838]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6084</th>\n",
       "      <td>State_28</td>\n",
       "      <td>[-0.06240685328314206]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6100</th>\n",
       "      <td>State_45</td>\n",
       "      <td>[-0.06722752975646304]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6095</th>\n",
       "      <td>State_39</td>\n",
       "      <td>[-0.10039220283821143]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9094</th>\n",
       "      <td>OtherPhysicianPresent_1</td>\n",
       "      <td>[-0.15440059565646735]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9096 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Feature                  Weight\n",
       "6092                 State_36   [0.10961150924561747]\n",
       "6089                 State_33    [0.0823917970612495]\n",
       "6136               County_160   [0.07824457599120582]\n",
       "6066                 State_10   [0.06418713698370881]\n",
       "6063                  State_7   [0.06101368747196894]\n",
       "...                       ...                     ...\n",
       "6067                 State_11  [-0.06199798589704838]\n",
       "6084                 State_28  [-0.06240685328314206]\n",
       "6100                 State_45  [-0.06722752975646304]\n",
       "6095                 State_39  [-0.10039220283821143]\n",
       "9094  OtherPhysicianPresent_1  [-0.15440059565646735]\n",
       "\n",
       "[9096 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_weights(best_log_clf)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T02:52:34.212488Z",
     "start_time": "2020-07-05T02:52:34.207176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 100,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=lab2_random_state)\n",
    "rf_pipe = make_pipeline(rf)\n",
    "rf.get_params()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T02:52:37.529661Z",
     "start_time": "2020-07-05T02:52:37.525625Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_param_grid = [\n",
    "      {'randomforestclassifier__max_features' :  np.arange(1,6,1),\n",
    "       'randomforestclassifier__n_estimators' :  np.arange(10,210,10),\n",
    "       'randomforestclassifier__random_state' :  [lab2_random_state],\n",
    "       'randomforestclassifier__n_jobs'       :  [-1]\n",
    "      }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T21:24:41.894347Z",
     "start_time": "2020-07-04T21:23:46.791237Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dustin/anaconda3/envs/DS7331/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "grid time:  3195.4517433720175\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'randomforestclassifier__max_features': 1, 'r...</td>\n",
       "      <td>5.303545</td>\n",
       "      <td>0.526075</td>\n",
       "      <td>0.530420</td>\n",
       "      <td>0.594929</td>\n",
       "      <td>0.589504</td>\n",
       "      <td>0.592142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'randomforestclassifier__max_features': 2, 'r...</td>\n",
       "      <td>7.918934</td>\n",
       "      <td>0.529114</td>\n",
       "      <td>0.533138</td>\n",
       "      <td>0.597288</td>\n",
       "      <td>0.591787</td>\n",
       "      <td>0.594467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>{'randomforestclassifier__max_features': 3, 'r...</td>\n",
       "      <td>8.346876</td>\n",
       "      <td>0.534939</td>\n",
       "      <td>0.536133</td>\n",
       "      <td>0.599265</td>\n",
       "      <td>0.597477</td>\n",
       "      <td>0.598322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>{'randomforestclassifier__max_features': 4, 'r...</td>\n",
       "      <td>8.492380</td>\n",
       "      <td>0.542159</td>\n",
       "      <td>0.540982</td>\n",
       "      <td>0.604337</td>\n",
       "      <td>0.597631</td>\n",
       "      <td>0.600902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>{'randomforestclassifier__max_features': 5, 'r...</td>\n",
       "      <td>8.967054</td>\n",
       "      <td>0.543439</td>\n",
       "      <td>0.542881</td>\n",
       "      <td>0.605413</td>\n",
       "      <td>0.602550</td>\n",
       "      <td>0.603869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>{'randomforestclassifier__max_features': 5, 'r...</td>\n",
       "      <td>76.984839</td>\n",
       "      <td>0.621077</td>\n",
       "      <td>0.602857</td>\n",
       "      <td>0.600538</td>\n",
       "      <td>0.936112</td>\n",
       "      <td>0.731639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>{'randomforestclassifier__max_features': 5, 'r...</td>\n",
       "      <td>86.889605</td>\n",
       "      <td>0.623570</td>\n",
       "      <td>0.601374</td>\n",
       "      <td>0.598999</td>\n",
       "      <td>0.940421</td>\n",
       "      <td>0.731806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>{'randomforestclassifier__max_features': 5, 'r...</td>\n",
       "      <td>82.308565</td>\n",
       "      <td>0.622929</td>\n",
       "      <td>0.602687</td>\n",
       "      <td>0.600138</td>\n",
       "      <td>0.938282</td>\n",
       "      <td>0.732007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>{'randomforestclassifier__max_features': 5, 'r...</td>\n",
       "      <td>90.377248</td>\n",
       "      <td>0.624983</td>\n",
       "      <td>0.601405</td>\n",
       "      <td>0.598728</td>\n",
       "      <td>0.942715</td>\n",
       "      <td>0.732300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>{'randomforestclassifier__max_features': 5, 'r...</td>\n",
       "      <td>71.202222</td>\n",
       "      <td>0.626082</td>\n",
       "      <td>0.601004</td>\n",
       "      <td>0.598276</td>\n",
       "      <td>0.944262</td>\n",
       "      <td>0.732425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  mean_fit_time  \\\n",
       "0   {'randomforestclassifier__max_features': 1, 'r...       5.303545   \n",
       "20  {'randomforestclassifier__max_features': 2, 'r...       7.918934   \n",
       "40  {'randomforestclassifier__max_features': 3, 'r...       8.346876   \n",
       "60  {'randomforestclassifier__max_features': 4, 'r...       8.492380   \n",
       "80  {'randomforestclassifier__max_features': 5, 'r...       8.967054   \n",
       "..                                                ...            ...   \n",
       "95  {'randomforestclassifier__max_features': 5, 'r...      76.984839   \n",
       "97  {'randomforestclassifier__max_features': 5, 'r...      86.889605   \n",
       "96  {'randomforestclassifier__max_features': 5, 'r...      82.308565   \n",
       "98  {'randomforestclassifier__max_features': 5, 'r...      90.377248   \n",
       "99  {'randomforestclassifier__max_features': 5, 'r...      71.202222   \n",
       "\n",
       "    mean_test_roc_auc  mean_test_accuracy  mean_test_precision  \\\n",
       "0            0.526075            0.530420             0.594929   \n",
       "20           0.529114            0.533138             0.597288   \n",
       "40           0.534939            0.536133             0.599265   \n",
       "60           0.542159            0.540982             0.604337   \n",
       "80           0.543439            0.542881             0.605413   \n",
       "..                ...                 ...                  ...   \n",
       "95           0.621077            0.602857             0.600538   \n",
       "97           0.623570            0.601374             0.598999   \n",
       "96           0.622929            0.602687             0.600138   \n",
       "98           0.624983            0.601405             0.598728   \n",
       "99           0.626082            0.601004             0.598276   \n",
       "\n",
       "    mean_test_recall  mean_test_f1  \n",
       "0           0.589504      0.592142  \n",
       "20          0.591787      0.594467  \n",
       "40          0.597477      0.598322  \n",
       "60          0.597631      0.600902  \n",
       "80          0.602550      0.603869  \n",
       "..               ...           ...  \n",
       "95          0.936112      0.731639  \n",
       "97          0.940421      0.731806  \n",
       "96          0.938282      0.732007  \n",
       "98          0.942715      0.732300  \n",
       "99          0.944262      0.732425  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator   :  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features=5,\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=-1, oob_score=False, random_state=100, verbose=0,\n",
      "                       warm_start=False)\n",
      "Best Parameters  :  {'randomforestclassifier__max_features': 5, 'randomforestclassifier__n_estimators': 200, 'randomforestclassifier__n_jobs': -1, 'randomforestclassifier__random_state': 100}\n",
      "Best Scores      :  0.7324248050115264\n",
      "\n",
      "10-fold Cross Validation results:\n",
      "---------------------------------\n",
      "F1 scores: [0.73399015 0.72321429 0.74241812 0.72443532 0.73184584 0.73384803\n",
      " 0.72697503 0.7169193  0.71609996 0.71510204]\n",
      "\n",
      "Precision scores [0.6020202  0.5842623  0.61569416 0.58488064 0.60173449 0.59643329\n",
      " 0.59517426 0.57452397 0.56938111 0.57292348]\n",
      "\n",
      "Recall scores [0.94006309 0.94888179 0.93482688 0.95145631 0.93374741 0.95353749\n",
      " 0.93375394 0.95315904 0.96467991 0.95114007]\n",
      "\n",
      "Average F1:  0.7264848064383308\n",
      "Min F1:  0.7151020408163266\n",
      "Max F1:  0.7424181156490092\n",
      "\n",
      "Average Precision:  0.5897027893138127\n",
      "Min Precision:  0.5693811074918567\n",
      "Max Precision:  0.6156941649899397\n",
      "\n",
      "Average Recall:  0.9465245935477092\n",
      "Min Recall:  0.9337474120082816\n",
      "Max Recall:  0.9646799116997793\n",
      "\n",
      "Single Run results:\n",
      "---------------------------------\n",
      "Accuracy: 0.5995058678196418\n",
      "Precision: 0.5989998648466008\n",
      "Recall: 0.9415763756107924\n",
      "F1: 0.7321989096315876\n",
      "\n",
      "Fit time:  6.694946264964528\n",
      "CV time:  31.295652821019758\n",
      "Total time:  38.28958940500161\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_rf_clf = testPerformance(rf_pipe,rf_param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T21:25:05.318896Z",
     "start_time": "2020-07-04T21:25:05.283577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ORD_AdmissionDt</td>\n",
       "      <td>0.017621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ORD_ClaimEndDt</td>\n",
       "      <td>0.017372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ORD_DischargeDt</td>\n",
       "      <td>0.017323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ORD_ClaimStartDt</td>\n",
       "      <td>0.017316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IPAnnualReimbursementAmt</td>\n",
       "      <td>0.017093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6981</th>\n",
       "      <td>ClmAdmitDiagnosisCode_3589</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>ProcedureCode_7719.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>ProcedureCode_7707.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7568</th>\n",
       "      <td>ClmAdmitDiagnosisCode_62212</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7377</th>\n",
       "      <td>ClmAdmitDiagnosisCode_5552</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9096 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Feature    Weight\n",
       "8                 ORD_AdmissionDt  0.017621\n",
       "7                  ORD_ClaimEndDt  0.017372\n",
       "9                 ORD_DischargeDt  0.017323\n",
       "6                ORD_ClaimStartDt  0.017316\n",
       "11       IPAnnualReimbursementAmt  0.017093\n",
       "...                           ...       ...\n",
       "6981   ClmAdmitDiagnosisCode_3589  0.000000\n",
       "819          ProcedureCode_7719.0  0.000000\n",
       "818          ProcedureCode_7707.0  0.000000\n",
       "7568  ClmAdmitDiagnosisCode_62212  0.000000\n",
       "7377   ClmAdmitDiagnosisCode_5552  0.000000\n",
       "\n",
       "[9096 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_weights(best_rf_clf,\"rf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T04:12:31.655363Z",
     "start_time": "2020-07-05T04:12:31.649536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline : \n",
      "Pipeline(memory=None,\n",
      "         steps=[('multinomialnb',\n",
      "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
      "         verbose=False)\n",
      "\n",
      "Hyperparameters : \n",
      "{'alpha': 1.0, 'class_prior': None, 'fit_prior': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['alpha', 'class_prior', 'fit_prior'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mult_nb = MultinomialNB()\n",
    "mult_pipe = make_pipeline(mult_nb)\n",
    "print(\"Pipeline : \")\n",
    "print(mult_pipe)\n",
    "print(\"\\nHyperparameters : \")\n",
    "print(mult_nb.get_params())\n",
    "mult_nb.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T16:41:27.251017Z",
     "start_time": "2020-07-04T16:41:27.248793Z"
    }
   },
   "source": [
    "\n",
    "#### Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T04:20:11.365148Z",
     "start_time": "2020-07-05T04:20:11.361926Z"
    }
   },
   "outputs": [],
   "source": [
    "nb_param_grid = [\n",
    "      {'multinomialnb__alpha'       :  np.logspace(-4, 4, 20),#[np.arange(1,3,10)],\n",
    "       'multinomialnb__fit_prior'   :  [True]\n",
    "      }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T04:20:20.226911Z",
     "start_time": "2020-07-05T04:20:13.652968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "grid time:  4.527057753002737\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'multinomialnb__alpha': 0.0001, 'multinomialn...</td>\n",
       "      <td>0.012231</td>\n",
       "      <td>0.585309</td>\n",
       "      <td>0.585053</td>\n",
       "      <td>0.630567</td>\n",
       "      <td>0.682411</td>\n",
       "      <td>0.655419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'multinomialnb__alpha': 0.0002636650898730358...</td>\n",
       "      <td>0.011672</td>\n",
       "      <td>0.585312</td>\n",
       "      <td>0.585053</td>\n",
       "      <td>0.630567</td>\n",
       "      <td>0.682411</td>\n",
       "      <td>0.655419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'multinomialnb__alpha': 0.0006951927961775605...</td>\n",
       "      <td>0.011626</td>\n",
       "      <td>0.585321</td>\n",
       "      <td>0.585083</td>\n",
       "      <td>0.630585</td>\n",
       "      <td>0.682464</td>\n",
       "      <td>0.655453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'multinomialnb__alpha': 0.0018329807108324356...</td>\n",
       "      <td>0.011582</td>\n",
       "      <td>0.585358</td>\n",
       "      <td>0.585161</td>\n",
       "      <td>0.630618</td>\n",
       "      <td>0.682651</td>\n",
       "      <td>0.655557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'multinomialnb__alpha': 0.004832930238571752,...</td>\n",
       "      <td>0.012034</td>\n",
       "      <td>0.585500</td>\n",
       "      <td>0.585176</td>\n",
       "      <td>0.630614</td>\n",
       "      <td>0.682731</td>\n",
       "      <td>0.655592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'multinomialnb__alpha': 0.012742749857031334,...</td>\n",
       "      <td>0.011564</td>\n",
       "      <td>0.585977</td>\n",
       "      <td>0.585222</td>\n",
       "      <td>0.630613</td>\n",
       "      <td>0.682918</td>\n",
       "      <td>0.655678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'multinomialnb__alpha': 0.03359818286283781, ...</td>\n",
       "      <td>0.012241</td>\n",
       "      <td>0.587359</td>\n",
       "      <td>0.585377</td>\n",
       "      <td>0.630608</td>\n",
       "      <td>0.683553</td>\n",
       "      <td>0.655970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'multinomialnb__alpha': 0.08858667904100823, ...</td>\n",
       "      <td>0.011775</td>\n",
       "      <td>0.590629</td>\n",
       "      <td>0.586535</td>\n",
       "      <td>0.630997</td>\n",
       "      <td>0.686785</td>\n",
       "      <td>0.657663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'multinomialnb__alpha': 0.23357214690901212, ...</td>\n",
       "      <td>0.012201</td>\n",
       "      <td>0.596518</td>\n",
       "      <td>0.588867</td>\n",
       "      <td>0.631539</td>\n",
       "      <td>0.694203</td>\n",
       "      <td>0.661348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'multinomialnb__alpha': 0.615848211066026, 'm...</td>\n",
       "      <td>0.012071</td>\n",
       "      <td>0.604550</td>\n",
       "      <td>0.595213</td>\n",
       "      <td>0.633007</td>\n",
       "      <td>0.714257</td>\n",
       "      <td>0.671141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'multinomialnb__alpha': 1.623776739188721, 'm...</td>\n",
       "      <td>0.011973</td>\n",
       "      <td>0.612866</td>\n",
       "      <td>0.601729</td>\n",
       "      <td>0.628539</td>\n",
       "      <td>0.761511</td>\n",
       "      <td>0.688612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'multinomialnb__alpha': 4.281332398719396, 'm...</td>\n",
       "      <td>0.011825</td>\n",
       "      <td>0.619418</td>\n",
       "      <td>0.605250</td>\n",
       "      <td>0.612072</td>\n",
       "      <td>0.867085</td>\n",
       "      <td>0.717556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'multinomialnb__alpha': 78.47599703514607, 'm...</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>0.579324</td>\n",
       "      <td>0.578351</td>\n",
       "      <td>0.578351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'multinomialnb__alpha': 206.913808111479, 'mu...</td>\n",
       "      <td>0.012462</td>\n",
       "      <td>0.553114</td>\n",
       "      <td>0.578351</td>\n",
       "      <td>0.578351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'multinomialnb__alpha': 545.5594781168514, 'm...</td>\n",
       "      <td>0.012545</td>\n",
       "      <td>0.533400</td>\n",
       "      <td>0.578351</td>\n",
       "      <td>0.578351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'multinomialnb__alpha': 1438.44988828766, 'mu...</td>\n",
       "      <td>0.012395</td>\n",
       "      <td>0.520464</td>\n",
       "      <td>0.578351</td>\n",
       "      <td>0.578351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'multinomialnb__alpha': 3792.690190732246, 'm...</td>\n",
       "      <td>0.012427</td>\n",
       "      <td>0.513249</td>\n",
       "      <td>0.578351</td>\n",
       "      <td>0.578351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'multinomialnb__alpha': 10000.0, 'multinomial...</td>\n",
       "      <td>0.012565</td>\n",
       "      <td>0.509837</td>\n",
       "      <td>0.578351</td>\n",
       "      <td>0.578351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'multinomialnb__alpha': 29.763514416313132, '...</td>\n",
       "      <td>0.012141</td>\n",
       "      <td>0.606296</td>\n",
       "      <td>0.578413</td>\n",
       "      <td>0.578394</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>0.732851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'multinomialnb__alpha': 11.288378916846883, '...</td>\n",
       "      <td>0.011923</td>\n",
       "      <td>0.619977</td>\n",
       "      <td>0.587832</td>\n",
       "      <td>0.585599</td>\n",
       "      <td>0.982952</td>\n",
       "      <td>0.733924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  mean_fit_time  \\\n",
       "0   {'multinomialnb__alpha': 0.0001, 'multinomialn...       0.012231   \n",
       "1   {'multinomialnb__alpha': 0.0002636650898730358...       0.011672   \n",
       "2   {'multinomialnb__alpha': 0.0006951927961775605...       0.011626   \n",
       "3   {'multinomialnb__alpha': 0.0018329807108324356...       0.011582   \n",
       "4   {'multinomialnb__alpha': 0.004832930238571752,...       0.012034   \n",
       "5   {'multinomialnb__alpha': 0.012742749857031334,...       0.011564   \n",
       "6   {'multinomialnb__alpha': 0.03359818286283781, ...       0.012241   \n",
       "7   {'multinomialnb__alpha': 0.08858667904100823, ...       0.011775   \n",
       "8   {'multinomialnb__alpha': 0.23357214690901212, ...       0.012201   \n",
       "9   {'multinomialnb__alpha': 0.615848211066026, 'm...       0.012071   \n",
       "10  {'multinomialnb__alpha': 1.623776739188721, 'm...       0.011973   \n",
       "11  {'multinomialnb__alpha': 4.281332398719396, 'm...       0.011825   \n",
       "14  {'multinomialnb__alpha': 78.47599703514607, 'm...       0.012024   \n",
       "15  {'multinomialnb__alpha': 206.913808111479, 'mu...       0.012462   \n",
       "16  {'multinomialnb__alpha': 545.5594781168514, 'm...       0.012545   \n",
       "17  {'multinomialnb__alpha': 1438.44988828766, 'mu...       0.012395   \n",
       "18  {'multinomialnb__alpha': 3792.690190732246, 'm...       0.012427   \n",
       "19  {'multinomialnb__alpha': 10000.0, 'multinomial...       0.012565   \n",
       "13  {'multinomialnb__alpha': 29.763514416313132, '...       0.012141   \n",
       "12  {'multinomialnb__alpha': 11.288378916846883, '...       0.011923   \n",
       "\n",
       "    mean_test_roc_auc  mean_test_accuracy  mean_test_precision  \\\n",
       "0            0.585309            0.585053             0.630567   \n",
       "1            0.585312            0.585053             0.630567   \n",
       "2            0.585321            0.585083             0.630585   \n",
       "3            0.585358            0.585161             0.630618   \n",
       "4            0.585500            0.585176             0.630614   \n",
       "5            0.585977            0.585222             0.630613   \n",
       "6            0.587359            0.585377             0.630608   \n",
       "7            0.590629            0.586535             0.630997   \n",
       "8            0.596518            0.588867             0.631539   \n",
       "9            0.604550            0.595213             0.633007   \n",
       "10           0.612866            0.601729             0.628539   \n",
       "11           0.619418            0.605250             0.612072   \n",
       "14           0.579324            0.578351             0.578351   \n",
       "15           0.553114            0.578351             0.578351   \n",
       "16           0.533400            0.578351             0.578351   \n",
       "17           0.520464            0.578351             0.578351   \n",
       "18           0.513249            0.578351             0.578351   \n",
       "19           0.509837            0.578351             0.578351   \n",
       "13           0.606296            0.578413             0.578394   \n",
       "12           0.619977            0.587832             0.585599   \n",
       "\n",
       "    mean_test_recall  mean_test_f1  \n",
       "0           0.682411      0.655419  \n",
       "1           0.682411      0.655419  \n",
       "2           0.682464      0.655453  \n",
       "3           0.682651      0.655557  \n",
       "4           0.682731      0.655592  \n",
       "5           0.682918      0.655678  \n",
       "6           0.683553      0.655970  \n",
       "7           0.686785      0.657663  \n",
       "8           0.694203      0.661348  \n",
       "9           0.714257      0.671141  \n",
       "10          0.761511      0.688612  \n",
       "11          0.867085      0.717556  \n",
       "14          1.000000      0.732838  \n",
       "15          1.000000      0.732838  \n",
       "16          1.000000      0.732838  \n",
       "17          1.000000      0.732838  \n",
       "18          1.000000      0.732838  \n",
       "19          1.000000      0.732838  \n",
       "13          0.999920      0.732851  \n",
       "12          0.982952      0.733924  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator   :  MultinomialNB(alpha=11.288378916846883, class_prior=None, fit_prior=True)\n",
      "Best Parameters  :  {'multinomialnb__alpha': 11.288378916846883, 'multinomialnb__fit_prior': True}\n",
      "Best Scores      :  0.7339238845056288\n",
      "\n",
      "10-fold Cross Validation results:\n",
      "---------------------------------\n",
      "F1 scores: [0.74007782 0.73416732 0.75509419 0.7282011  0.74738878 0.7381138\n",
      " 0.74007782 0.7236894  0.71762376 0.72548247]\n",
      "\n",
      "Precision scores [0.58739963 0.57998765 0.60654725 0.57257566 0.59666461 0.58492897\n",
      " 0.58739963 0.56701668 0.55960469 0.56922126]\n",
      "\n",
      "Recall scores [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "Average F1:  0.734991646448452\n",
      "Min F1:  0.7176237623762376\n",
      "Max F1:  0.7550941945405613\n",
      "\n",
      "Average Precision:  0.5811346029191362\n",
      "Min Precision:  0.5596046942557134\n",
      "Max Precision:  0.6065472513897467\n",
      "\n",
      "Average Recall:  1.0\n",
      "Min Recall:  1.0\n",
      "Max Recall:  1.0\n",
      "\n",
      "Single Run results:\n",
      "---------------------------------\n",
      "Accuracy: 0.591846819024089\n",
      "Precision: 0.5909032007256706\n",
      "Recall: 0.9687699171446782\n",
      "F1: 0.7340631036703156\n",
      "\n",
      "Fit time:  0.008868990000337362\n",
      "CV time:  0.15493889298522845\n",
      "Total time:  0.24309683195315301\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_nb_clf = testPerformance(mult_pipe,nb_param_grid,n1_jobs=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T23:01:31.076513Z",
     "start_time": "2020-07-04T23:01:30.891726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9093</th>\n",
       "      <td>AttendingPhysicianPresent_1</td>\n",
       "      <td>[-3.5823621148168243]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6403</th>\n",
       "      <td>NoOfMonths_PartACov_12</td>\n",
       "      <td>[-3.587036077828108]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORD_DOD</td>\n",
       "      <td>[-3.5876059096564443]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6427</th>\n",
       "      <td>Alive_N</td>\n",
       "      <td>[-3.5876285973924205]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6415</th>\n",
       "      <td>NoOfMonths_PartBCov_12</td>\n",
       "      <td>[-3.5886528679271024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5689</th>\n",
       "      <td>DiagnosisCode_V1012</td>\n",
       "      <td>[-10.99258047924537]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7526</th>\n",
       "      <td>ClmAdmitDiagnosisCode_6073</td>\n",
       "      <td>[-10.99258047924537]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7525</th>\n",
       "      <td>ClmAdmitDiagnosisCode_605</td>\n",
       "      <td>[-10.99258047924537]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5693</th>\n",
       "      <td>DiagnosisCode_V1040</td>\n",
       "      <td>[-10.99258047924537]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3346</th>\n",
       "      <td>DiagnosisCode_52469</td>\n",
       "      <td>[-10.99258047924537]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9096 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Feature                 Weight\n",
       "9093  AttendingPhysicianPresent_1  [-3.5823621148168243]\n",
       "6403       NoOfMonths_PartACov_12   [-3.587036077828108]\n",
       "4                         ORD_DOD  [-3.5876059096564443]\n",
       "6427                      Alive_N  [-3.5876285973924205]\n",
       "6415       NoOfMonths_PartBCov_12  [-3.5886528679271024]\n",
       "...                           ...                    ...\n",
       "5689          DiagnosisCode_V1012   [-10.99258047924537]\n",
       "7526   ClmAdmitDiagnosisCode_6073   [-10.99258047924537]\n",
       "7525    ClmAdmitDiagnosisCode_605   [-10.99258047924537]\n",
       "5693          DiagnosisCode_V1040   [-10.99258047924537]\n",
       "3346          DiagnosisCode_52469   [-10.99258047924537]\n",
       "\n",
       "[9096 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_weights(best_nb_clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:49:57.586307Z",
     "start_time": "2020-07-05T05:49:45.874334Z"
    }
   },
   "outputs": [],
   "source": [
    "reg_X = csc_matrix(reg_X1)\n",
    "reg_X_train,reg_X_test,reg_y_train,reg_y_test = train_test_split(reg_X,reg_target,test_size=0.2,random_state=86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alpha',\n",
       " 'copy_X',\n",
       " 'fit_intercept',\n",
       " 'max_iter',\n",
       " 'normalize',\n",
       " 'positive',\n",
       " 'precompute',\n",
       " 'random_state',\n",
       " 'selection',\n",
       " 'tol',\n",
       " 'warm_start']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Lasso().get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "grid time:  234.66972893098136\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_lasso__alpha</th>\n",
       "      <th>param_lasso__max_iter</th>\n",
       "      <th>param_lasso__selection</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_mean_squared_error</th>\n",
       "      <th>split1_test_neg_mean_squared_error</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_r2</th>\n",
       "      <th>split4_test_r2</th>\n",
       "      <th>split5_test_r2</th>\n",
       "      <th>split6_test_r2</th>\n",
       "      <th>split7_test_r2</th>\n",
       "      <th>split8_test_r2</th>\n",
       "      <th>split9_test_r2</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>std_test_r2</th>\n",
       "      <th>rank_test_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.963092</td>\n",
       "      <td>0.246689</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>cyclic</td>\n",
       "      <td>{'lasso__alpha': 1, 'lasso__max_iter': 100, 'l...</td>\n",
       "      <td>-4.239498e+07</td>\n",
       "      <td>-3.849005e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614846</td>\n",
       "      <td>0.624079</td>\n",
       "      <td>0.624343</td>\n",
       "      <td>0.629439</td>\n",
       "      <td>0.632260</td>\n",
       "      <td>0.609078</td>\n",
       "      <td>0.616680</td>\n",
       "      <td>0.619115</td>\n",
       "      <td>0.008261</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.007411</td>\n",
       "      <td>0.200564</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>random</td>\n",
       "      <td>{'lasso__alpha': 1, 'lasso__max_iter': 100, 'l...</td>\n",
       "      <td>-4.239154e+07</td>\n",
       "      <td>-3.849036e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614846</td>\n",
       "      <td>0.624089</td>\n",
       "      <td>0.626171</td>\n",
       "      <td>0.629392</td>\n",
       "      <td>0.632261</td>\n",
       "      <td>0.610943</td>\n",
       "      <td>0.616737</td>\n",
       "      <td>0.619487</td>\n",
       "      <td>0.008181</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.605519</td>\n",
       "      <td>0.492751</td>\n",
       "      <td>0.001226</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>cyclic</td>\n",
       "      <td>{'lasso__alpha': 1, 'lasso__max_iter': 250, 'l...</td>\n",
       "      <td>-4.239682e+07</td>\n",
       "      <td>-3.849040e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614837</td>\n",
       "      <td>0.624079</td>\n",
       "      <td>0.624330</td>\n",
       "      <td>0.629451</td>\n",
       "      <td>0.632251</td>\n",
       "      <td>0.609071</td>\n",
       "      <td>0.616677</td>\n",
       "      <td>0.619110</td>\n",
       "      <td>0.008262</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.990673</td>\n",
       "      <td>13.578260</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>random</td>\n",
       "      <td>{'lasso__alpha': 1, 'lasso__max_iter': 250, 'l...</td>\n",
       "      <td>-4.239416e+07</td>\n",
       "      <td>-3.849084e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614841</td>\n",
       "      <td>0.624090</td>\n",
       "      <td>0.626172</td>\n",
       "      <td>0.629399</td>\n",
       "      <td>0.632284</td>\n",
       "      <td>0.610936</td>\n",
       "      <td>0.616743</td>\n",
       "      <td>0.619491</td>\n",
       "      <td>0.008180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.324906</td>\n",
       "      <td>0.097267</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>cyclic</td>\n",
       "      <td>{'lasso__alpha': 3, 'lasso__max_iter': 100, 'l...</td>\n",
       "      <td>-4.282724e+07</td>\n",
       "      <td>-3.850482e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.604664</td>\n",
       "      <td>0.613499</td>\n",
       "      <td>0.618395</td>\n",
       "      <td>0.622126</td>\n",
       "      <td>0.621213</td>\n",
       "      <td>0.595883</td>\n",
       "      <td>0.616777</td>\n",
       "      <td>0.611895</td>\n",
       "      <td>0.009278</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.825066</td>\n",
       "      <td>2.912539</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>random</td>\n",
       "      <td>{'lasso__alpha': 3, 'lasso__max_iter': 100, 'l...</td>\n",
       "      <td>-4.283203e+07</td>\n",
       "      <td>-3.850113e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.604755</td>\n",
       "      <td>0.613524</td>\n",
       "      <td>0.618420</td>\n",
       "      <td>0.622049</td>\n",
       "      <td>0.621191</td>\n",
       "      <td>0.595905</td>\n",
       "      <td>0.616748</td>\n",
       "      <td>0.611890</td>\n",
       "      <td>0.009268</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.887463</td>\n",
       "      <td>0.505481</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "      <td>cyclic</td>\n",
       "      <td>{'lasso__alpha': 3, 'lasso__max_iter': 250, 'l...</td>\n",
       "      <td>-4.283173e+07</td>\n",
       "      <td>-3.849974e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.604754</td>\n",
       "      <td>0.613521</td>\n",
       "      <td>0.618419</td>\n",
       "      <td>0.622053</td>\n",
       "      <td>0.621192</td>\n",
       "      <td>0.595904</td>\n",
       "      <td>0.616747</td>\n",
       "      <td>0.611896</td>\n",
       "      <td>0.009262</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.044000</td>\n",
       "      <td>2.399980</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "      <td>random</td>\n",
       "      <td>{'lasso__alpha': 3, 'lasso__max_iter': 250, 'l...</td>\n",
       "      <td>-4.283143e+07</td>\n",
       "      <td>-3.849961e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.604753</td>\n",
       "      <td>0.613522</td>\n",
       "      <td>0.618419</td>\n",
       "      <td>0.622052</td>\n",
       "      <td>0.621189</td>\n",
       "      <td>0.595904</td>\n",
       "      <td>0.616745</td>\n",
       "      <td>0.611896</td>\n",
       "      <td>0.009262</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.048690</td>\n",
       "      <td>0.364536</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>cyclic</td>\n",
       "      <td>{'lasso__alpha': 5, 'lasso__max_iter': 100, 'l...</td>\n",
       "      <td>-4.421125e+07</td>\n",
       "      <td>-3.982569e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590724</td>\n",
       "      <td>0.596825</td>\n",
       "      <td>0.603576</td>\n",
       "      <td>0.610614</td>\n",
       "      <td>0.604539</td>\n",
       "      <td>0.582268</td>\n",
       "      <td>0.606639</td>\n",
       "      <td>0.598472</td>\n",
       "      <td>0.009188</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.340024</td>\n",
       "      <td>2.625585</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>random</td>\n",
       "      <td>{'lasso__alpha': 5, 'lasso__max_iter': 100, 'l...</td>\n",
       "      <td>-4.421128e+07</td>\n",
       "      <td>-3.982581e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590724</td>\n",
       "      <td>0.596824</td>\n",
       "      <td>0.603577</td>\n",
       "      <td>0.610613</td>\n",
       "      <td>0.604537</td>\n",
       "      <td>0.582267</td>\n",
       "      <td>0.606636</td>\n",
       "      <td>0.598472</td>\n",
       "      <td>0.009187</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.010463</td>\n",
       "      <td>0.321208</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>5</td>\n",
       "      <td>250</td>\n",
       "      <td>cyclic</td>\n",
       "      <td>{'lasso__alpha': 5, 'lasso__max_iter': 250, 'l...</td>\n",
       "      <td>-4.421125e+07</td>\n",
       "      <td>-3.982569e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590724</td>\n",
       "      <td>0.596825</td>\n",
       "      <td>0.603576</td>\n",
       "      <td>0.610614</td>\n",
       "      <td>0.604539</td>\n",
       "      <td>0.582268</td>\n",
       "      <td>0.606639</td>\n",
       "      <td>0.598472</td>\n",
       "      <td>0.009188</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15.159253</td>\n",
       "      <td>4.813383</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>5</td>\n",
       "      <td>250</td>\n",
       "      <td>random</td>\n",
       "      <td>{'lasso__alpha': 5, 'lasso__max_iter': 250, 'l...</td>\n",
       "      <td>-4.421120e+07</td>\n",
       "      <td>-3.982586e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590729</td>\n",
       "      <td>0.596826</td>\n",
       "      <td>0.603578</td>\n",
       "      <td>0.610616</td>\n",
       "      <td>0.604540</td>\n",
       "      <td>0.582270</td>\n",
       "      <td>0.606639</td>\n",
       "      <td>0.598473</td>\n",
       "      <td>0.009189</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.883204</td>\n",
       "      <td>0.239424</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>cyclic</td>\n",
       "      <td>{'lasso__alpha': 10, 'lasso__max_iter': 100, '...</td>\n",
       "      <td>-4.604276e+07</td>\n",
       "      <td>-4.199476e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568125</td>\n",
       "      <td>0.578535</td>\n",
       "      <td>0.581956</td>\n",
       "      <td>0.590731</td>\n",
       "      <td>0.585918</td>\n",
       "      <td>0.561567</td>\n",
       "      <td>0.586840</td>\n",
       "      <td>0.578571</td>\n",
       "      <td>0.009873</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9.871216</td>\n",
       "      <td>2.777381</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>random</td>\n",
       "      <td>{'lasso__alpha': 10, 'lasso__max_iter': 100, '...</td>\n",
       "      <td>-4.604256e+07</td>\n",
       "      <td>-4.199498e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568135</td>\n",
       "      <td>0.578533</td>\n",
       "      <td>0.581956</td>\n",
       "      <td>0.590727</td>\n",
       "      <td>0.585919</td>\n",
       "      <td>0.561567</td>\n",
       "      <td>0.586840</td>\n",
       "      <td>0.578572</td>\n",
       "      <td>0.009872</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.869673</td>\n",
       "      <td>0.241767</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>10</td>\n",
       "      <td>250</td>\n",
       "      <td>cyclic</td>\n",
       "      <td>{'lasso__alpha': 10, 'lasso__max_iter': 250, '...</td>\n",
       "      <td>-4.604276e+07</td>\n",
       "      <td>-4.199476e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568125</td>\n",
       "      <td>0.578535</td>\n",
       "      <td>0.581956</td>\n",
       "      <td>0.590731</td>\n",
       "      <td>0.585918</td>\n",
       "      <td>0.561567</td>\n",
       "      <td>0.586840</td>\n",
       "      <td>0.578571</td>\n",
       "      <td>0.009873</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.160742</td>\n",
       "      <td>2.195996</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>10</td>\n",
       "      <td>250</td>\n",
       "      <td>random</td>\n",
       "      <td>{'lasso__alpha': 10, 'lasso__max_iter': 250, '...</td>\n",
       "      <td>-4.604264e+07</td>\n",
       "      <td>-4.199486e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568123</td>\n",
       "      <td>0.578530</td>\n",
       "      <td>0.581956</td>\n",
       "      <td>0.590730</td>\n",
       "      <td>0.585919</td>\n",
       "      <td>0.561568</td>\n",
       "      <td>0.586839</td>\n",
       "      <td>0.578570</td>\n",
       "      <td>0.009874</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       23.963092      0.246689         0.001531        0.000157   \n",
       "1       24.007411      0.200564         0.001391        0.000166   \n",
       "2       59.605519      0.492751         0.001226        0.000082   \n",
       "3       42.990673     13.578260         0.001191        0.000027   \n",
       "4       19.324906      0.097267         0.001196        0.000042   \n",
       "5       15.825066      2.912539         0.001187        0.000050   \n",
       "6       23.887463      0.505481         0.001178        0.000011   \n",
       "7       15.044000      2.399980         0.001168        0.000013   \n",
       "8       15.048690      0.364536         0.001200        0.000047   \n",
       "9       13.340024      2.625585         0.001179        0.000022   \n",
       "10      15.010463      0.321208         0.001212        0.000086   \n",
       "11      15.159253      4.813383         0.001177        0.000019   \n",
       "12       8.883204      0.239424         0.001191        0.000034   \n",
       "13       9.871216      2.777381         0.001190        0.000049   \n",
       "14       8.869673      0.241767         0.001171        0.000013   \n",
       "15       9.160742      2.195996         0.000892        0.000020   \n",
       "\n",
       "   param_lasso__alpha param_lasso__max_iter param_lasso__selection  \\\n",
       "0                   1                   100                 cyclic   \n",
       "1                   1                   100                 random   \n",
       "2                   1                   250                 cyclic   \n",
       "3                   1                   250                 random   \n",
       "4                   3                   100                 cyclic   \n",
       "5                   3                   100                 random   \n",
       "6                   3                   250                 cyclic   \n",
       "7                   3                   250                 random   \n",
       "8                   5                   100                 cyclic   \n",
       "9                   5                   100                 random   \n",
       "10                  5                   250                 cyclic   \n",
       "11                  5                   250                 random   \n",
       "12                 10                   100                 cyclic   \n",
       "13                 10                   100                 random   \n",
       "14                 10                   250                 cyclic   \n",
       "15                 10                   250                 random   \n",
       "\n",
       "                                               params  \\\n",
       "0   {'lasso__alpha': 1, 'lasso__max_iter': 100, 'l...   \n",
       "1   {'lasso__alpha': 1, 'lasso__max_iter': 100, 'l...   \n",
       "2   {'lasso__alpha': 1, 'lasso__max_iter': 250, 'l...   \n",
       "3   {'lasso__alpha': 1, 'lasso__max_iter': 250, 'l...   \n",
       "4   {'lasso__alpha': 3, 'lasso__max_iter': 100, 'l...   \n",
       "5   {'lasso__alpha': 3, 'lasso__max_iter': 100, 'l...   \n",
       "6   {'lasso__alpha': 3, 'lasso__max_iter': 250, 'l...   \n",
       "7   {'lasso__alpha': 3, 'lasso__max_iter': 250, 'l...   \n",
       "8   {'lasso__alpha': 5, 'lasso__max_iter': 100, 'l...   \n",
       "9   {'lasso__alpha': 5, 'lasso__max_iter': 100, 'l...   \n",
       "10  {'lasso__alpha': 5, 'lasso__max_iter': 250, 'l...   \n",
       "11  {'lasso__alpha': 5, 'lasso__max_iter': 250, 'l...   \n",
       "12  {'lasso__alpha': 10, 'lasso__max_iter': 100, '...   \n",
       "13  {'lasso__alpha': 10, 'lasso__max_iter': 100, '...   \n",
       "14  {'lasso__alpha': 10, 'lasso__max_iter': 250, '...   \n",
       "15  {'lasso__alpha': 10, 'lasso__max_iter': 250, '...   \n",
       "\n",
       "    split0_test_neg_mean_squared_error  split1_test_neg_mean_squared_error  \\\n",
       "0                        -4.239498e+07                       -3.849005e+07   \n",
       "1                        -4.239154e+07                       -3.849036e+07   \n",
       "2                        -4.239682e+07                       -3.849040e+07   \n",
       "3                        -4.239416e+07                       -3.849084e+07   \n",
       "4                        -4.282724e+07                       -3.850482e+07   \n",
       "5                        -4.283203e+07                       -3.850113e+07   \n",
       "6                        -4.283173e+07                       -3.849974e+07   \n",
       "7                        -4.283143e+07                       -3.849961e+07   \n",
       "8                        -4.421125e+07                       -3.982569e+07   \n",
       "9                        -4.421128e+07                       -3.982581e+07   \n",
       "10                       -4.421125e+07                       -3.982569e+07   \n",
       "11                       -4.421120e+07                       -3.982586e+07   \n",
       "12                       -4.604276e+07                       -4.199476e+07   \n",
       "13                       -4.604256e+07                       -4.199498e+07   \n",
       "14                       -4.604276e+07                       -4.199476e+07   \n",
       "15                       -4.604264e+07                       -4.199486e+07   \n",
       "\n",
       "    ...  split3_test_r2  split4_test_r2  split5_test_r2  split6_test_r2  \\\n",
       "0   ...        0.614846        0.624079        0.624343        0.629439   \n",
       "1   ...        0.614846        0.624089        0.626171        0.629392   \n",
       "2   ...        0.614837        0.624079        0.624330        0.629451   \n",
       "3   ...        0.614841        0.624090        0.626172        0.629399   \n",
       "4   ...        0.604664        0.613499        0.618395        0.622126   \n",
       "5   ...        0.604755        0.613524        0.618420        0.622049   \n",
       "6   ...        0.604754        0.613521        0.618419        0.622053   \n",
       "7   ...        0.604753        0.613522        0.618419        0.622052   \n",
       "8   ...        0.590724        0.596825        0.603576        0.610614   \n",
       "9   ...        0.590724        0.596824        0.603577        0.610613   \n",
       "10  ...        0.590724        0.596825        0.603576        0.610614   \n",
       "11  ...        0.590729        0.596826        0.603578        0.610616   \n",
       "12  ...        0.568125        0.578535        0.581956        0.590731   \n",
       "13  ...        0.568135        0.578533        0.581956        0.590727   \n",
       "14  ...        0.568125        0.578535        0.581956        0.590731   \n",
       "15  ...        0.568123        0.578530        0.581956        0.590730   \n",
       "\n",
       "    split7_test_r2  split8_test_r2  split9_test_r2  mean_test_r2  std_test_r2  \\\n",
       "0         0.632260        0.609078        0.616680      0.619115     0.008261   \n",
       "1         0.632261        0.610943        0.616737      0.619487     0.008181   \n",
       "2         0.632251        0.609071        0.616677      0.619110     0.008262   \n",
       "3         0.632284        0.610936        0.616743      0.619491     0.008180   \n",
       "4         0.621213        0.595883        0.616777      0.611895     0.009278   \n",
       "5         0.621191        0.595905        0.616748      0.611890     0.009268   \n",
       "6         0.621192        0.595904        0.616747      0.611896     0.009262   \n",
       "7         0.621189        0.595904        0.616745      0.611896     0.009262   \n",
       "8         0.604539        0.582268        0.606639      0.598472     0.009188   \n",
       "9         0.604537        0.582267        0.606636      0.598472     0.009187   \n",
       "10        0.604539        0.582268        0.606639      0.598472     0.009188   \n",
       "11        0.604540        0.582270        0.606639      0.598473     0.009189   \n",
       "12        0.585918        0.561567        0.586840      0.578571     0.009873   \n",
       "13        0.585919        0.561567        0.586840      0.578572     0.009872   \n",
       "14        0.585918        0.561567        0.586840      0.578571     0.009873   \n",
       "15        0.585919        0.561568        0.586839      0.578570     0.009874   \n",
       "\n",
       "    rank_test_r2  \n",
       "0              3  \n",
       "1              2  \n",
       "2              4  \n",
       "3              1  \n",
       "4              7  \n",
       "5              8  \n",
       "6              6  \n",
       "7              5  \n",
       "8             10  \n",
       "9             12  \n",
       "10            10  \n",
       "11             9  \n",
       "12            14  \n",
       "13            13  \n",
       "14            14  \n",
       "15            16  \n",
       "\n",
       "[16 rows x 34 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Lasso Regression code\"\"\"\n",
    "LassoPipe= make_pipeline(Lasso())\n",
    "LassoParams = [\n",
    "    {\n",
    "         'lasso__alpha':[1,3,5,10],\n",
    "         'lasso__selection':['cyclic','random'],\n",
    "         'lasso__max_iter':[100,250]\n",
    "    }\n",
    "]\n",
    "cv = ShuffleSplit(n_splits=10, test_size=.2, random_state=86)\n",
    "#Perform the grid search using accuracy as a metric during cross validation.\n",
    "grid = GridSearchCV(LassoPipe, LassoParams, cv=cv, scoring=['neg_mean_squared_error','r2'], n_jobs=-1, refit='neg_mean_squared_error')\n",
    "#Use the best features from recursive feature elimination during the grid search\n",
    "start_time = timeit.default_timer()\n",
    "grid.fit(reg_X_train, reg_y_train)\n",
    "grid_time = timeit.default_timer() - start_time\n",
    "#display the best pipeline model identified during the grid search\n",
    "print(\"\\ngrid time: \", grid_time)\n",
    "gridResults = pd.DataFrame.from_dict(grid.cv_results_)\n",
    "gridResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dustin/anaconda3/envs/DS7331/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "grid time:  1351.2681903149933\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_randomforestregressor__max_features</th>\n",
       "      <th>param_randomforestregressor__min_samples_leaf</th>\n",
       "      <th>param_randomforestregressor__n_jobs</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_mean_squared_error</th>\n",
       "      <th>split1_test_neg_mean_squared_error</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_r2</th>\n",
       "      <th>split4_test_r2</th>\n",
       "      <th>split5_test_r2</th>\n",
       "      <th>split6_test_r2</th>\n",
       "      <th>split7_test_r2</th>\n",
       "      <th>split8_test_r2</th>\n",
       "      <th>split9_test_r2</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>std_test_r2</th>\n",
       "      <th>rank_test_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>824.424405</td>\n",
       "      <td>3.063638</td>\n",
       "      <td>0.591503</td>\n",
       "      <td>0.069788</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>{'randomforestregressor__max_features': 'auto'...</td>\n",
       "      <td>-3.227463e+07</td>\n",
       "      <td>-2.540520e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717625</td>\n",
       "      <td>0.753864</td>\n",
       "      <td>0.749695</td>\n",
       "      <td>0.747150</td>\n",
       "      <td>0.752879</td>\n",
       "      <td>0.730562</td>\n",
       "      <td>0.744089</td>\n",
       "      <td>0.739281</td>\n",
       "      <td>0.013740</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>479.674176</td>\n",
       "      <td>33.791510</td>\n",
       "      <td>0.853033</td>\n",
       "      <td>0.162235</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>{'randomforestregressor__max_features': 'auto'...</td>\n",
       "      <td>-3.126961e+07</td>\n",
       "      <td>-2.576737e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715874</td>\n",
       "      <td>0.748649</td>\n",
       "      <td>0.748802</td>\n",
       "      <td>0.750466</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.727782</td>\n",
       "      <td>0.747192</td>\n",
       "      <td>0.740282</td>\n",
       "      <td>0.013346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>343.001057</td>\n",
       "      <td>9.452606</td>\n",
       "      <td>0.614221</td>\n",
       "      <td>0.098093</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>{'randomforestregressor__max_features': 'auto'...</td>\n",
       "      <td>-3.115812e+07</td>\n",
       "      <td>-2.635577e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715230</td>\n",
       "      <td>0.745633</td>\n",
       "      <td>0.748341</td>\n",
       "      <td>0.751811</td>\n",
       "      <td>0.756444</td>\n",
       "      <td>0.725691</td>\n",
       "      <td>0.746277</td>\n",
       "      <td>0.738886</td>\n",
       "      <td>0.013071</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>246.118938</td>\n",
       "      <td>22.519513</td>\n",
       "      <td>0.783523</td>\n",
       "      <td>0.266114</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>{'randomforestregressor__max_features': 'auto'...</td>\n",
       "      <td>-3.228376e+07</td>\n",
       "      <td>-2.643556e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.709505</td>\n",
       "      <td>0.740073</td>\n",
       "      <td>0.745272</td>\n",
       "      <td>0.744977</td>\n",
       "      <td>0.751783</td>\n",
       "      <td>0.720423</td>\n",
       "      <td>0.745622</td>\n",
       "      <td>0.734175</td>\n",
       "      <td>0.014182</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69.452546</td>\n",
       "      <td>3.220573</td>\n",
       "      <td>0.904599</td>\n",
       "      <td>0.173984</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>{'randomforestregressor__max_features': 'sqrt'...</td>\n",
       "      <td>-5.329502e+07</td>\n",
       "      <td>-4.575603e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519887</td>\n",
       "      <td>0.518910</td>\n",
       "      <td>0.519820</td>\n",
       "      <td>0.514946</td>\n",
       "      <td>0.528366</td>\n",
       "      <td>0.502515</td>\n",
       "      <td>0.530100</td>\n",
       "      <td>0.520722</td>\n",
       "      <td>0.010078</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.516783</td>\n",
       "      <td>0.528763</td>\n",
       "      <td>0.829661</td>\n",
       "      <td>0.143279</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>{'randomforestregressor__max_features': 'sqrt'...</td>\n",
       "      <td>-6.239979e+07</td>\n",
       "      <td>-5.342955e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458844</td>\n",
       "      <td>0.446899</td>\n",
       "      <td>0.443512</td>\n",
       "      <td>0.449501</td>\n",
       "      <td>0.456716</td>\n",
       "      <td>0.442085</td>\n",
       "      <td>0.454276</td>\n",
       "      <td>0.451695</td>\n",
       "      <td>0.007043</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.991392</td>\n",
       "      <td>1.677915</td>\n",
       "      <td>0.717533</td>\n",
       "      <td>0.139458</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>{'randomforestregressor__max_features': 'sqrt'...</td>\n",
       "      <td>-6.565054e+07</td>\n",
       "      <td>-5.502786e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.431732</td>\n",
       "      <td>0.419561</td>\n",
       "      <td>0.426908</td>\n",
       "      <td>0.408839</td>\n",
       "      <td>0.416869</td>\n",
       "      <td>0.407426</td>\n",
       "      <td>0.421648</td>\n",
       "      <td>0.420417</td>\n",
       "      <td>0.011184</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.840731</td>\n",
       "      <td>1.089959</td>\n",
       "      <td>0.679229</td>\n",
       "      <td>0.155467</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>{'randomforestregressor__max_features': 'sqrt'...</td>\n",
       "      <td>-7.214923e+07</td>\n",
       "      <td>-6.108773e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380340</td>\n",
       "      <td>0.374289</td>\n",
       "      <td>0.371431</td>\n",
       "      <td>0.375120</td>\n",
       "      <td>0.383868</td>\n",
       "      <td>0.369289</td>\n",
       "      <td>0.358128</td>\n",
       "      <td>0.371895</td>\n",
       "      <td>0.009286</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>53.305910</td>\n",
       "      <td>2.667983</td>\n",
       "      <td>0.658304</td>\n",
       "      <td>0.290947</td>\n",
       "      <td>log2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>{'randomforestregressor__max_features': 'log2'...</td>\n",
       "      <td>-6.782676e+07</td>\n",
       "      <td>-5.988690e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390978</td>\n",
       "      <td>0.386582</td>\n",
       "      <td>0.389897</td>\n",
       "      <td>0.381304</td>\n",
       "      <td>0.394662</td>\n",
       "      <td>0.370049</td>\n",
       "      <td>0.388103</td>\n",
       "      <td>0.386476</td>\n",
       "      <td>0.009058</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.127103</td>\n",
       "      <td>0.655390</td>\n",
       "      <td>0.891023</td>\n",
       "      <td>0.088306</td>\n",
       "      <td>log2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>{'randomforestregressor__max_features': 'log2'...</td>\n",
       "      <td>-8.888983e+07</td>\n",
       "      <td>-7.847161e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218144</td>\n",
       "      <td>0.231553</td>\n",
       "      <td>0.226063</td>\n",
       "      <td>0.217273</td>\n",
       "      <td>0.222863</td>\n",
       "      <td>0.238675</td>\n",
       "      <td>0.209781</td>\n",
       "      <td>0.217647</td>\n",
       "      <td>0.012152</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.334024</td>\n",
       "      <td>1.046823</td>\n",
       "      <td>0.643627</td>\n",
       "      <td>0.146950</td>\n",
       "      <td>log2</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>{'randomforestregressor__max_features': 'log2'...</td>\n",
       "      <td>-9.327403e+07</td>\n",
       "      <td>-8.129973e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184179</td>\n",
       "      <td>0.154816</td>\n",
       "      <td>0.158329</td>\n",
       "      <td>0.165610</td>\n",
       "      <td>0.164882</td>\n",
       "      <td>0.162990</td>\n",
       "      <td>0.158970</td>\n",
       "      <td>0.165549</td>\n",
       "      <td>0.009495</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.238643</td>\n",
       "      <td>0.571418</td>\n",
       "      <td>0.331926</td>\n",
       "      <td>0.158573</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>{'randomforestregressor__max_features': 'log2'...</td>\n",
       "      <td>-1.031494e+08</td>\n",
       "      <td>-8.965640e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102184</td>\n",
       "      <td>0.114223</td>\n",
       "      <td>0.069746</td>\n",
       "      <td>0.092290</td>\n",
       "      <td>0.077326</td>\n",
       "      <td>0.095549</td>\n",
       "      <td>0.078587</td>\n",
       "      <td>0.089456</td>\n",
       "      <td>0.012698</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      824.424405      3.063638         0.591503        0.069788   \n",
       "1      479.674176     33.791510         0.853033        0.162235   \n",
       "2      343.001057      9.452606         0.614221        0.098093   \n",
       "3      246.118938     22.519513         0.783523        0.266114   \n",
       "4       69.452546      3.220573         0.904599        0.173984   \n",
       "5       21.516783      0.528763         0.829661        0.143279   \n",
       "6       13.991392      1.677915         0.717533        0.139458   \n",
       "7        7.840731      1.089959         0.679229        0.155467   \n",
       "8       53.305910      2.667983         0.658304        0.290947   \n",
       "9       10.127103      0.655390         0.891023        0.088306   \n",
       "10       6.334024      1.046823         0.643627        0.146950   \n",
       "11       2.238643      0.571418         0.331926        0.158573   \n",
       "\n",
       "   param_randomforestregressor__max_features  \\\n",
       "0                                       auto   \n",
       "1                                       auto   \n",
       "2                                       auto   \n",
       "3                                       auto   \n",
       "4                                       sqrt   \n",
       "5                                       sqrt   \n",
       "6                                       sqrt   \n",
       "7                                       sqrt   \n",
       "8                                       log2   \n",
       "9                                       log2   \n",
       "10                                      log2   \n",
       "11                                      log2   \n",
       "\n",
       "   param_randomforestregressor__min_samples_leaf  \\\n",
       "0                                              1   \n",
       "1                                              3   \n",
       "2                                              5   \n",
       "3                                             10   \n",
       "4                                              1   \n",
       "5                                              3   \n",
       "6                                              5   \n",
       "7                                             10   \n",
       "8                                              1   \n",
       "9                                              3   \n",
       "10                                             5   \n",
       "11                                            10   \n",
       "\n",
       "   param_randomforestregressor__n_jobs  \\\n",
       "0                                   -1   \n",
       "1                                   -1   \n",
       "2                                   -1   \n",
       "3                                   -1   \n",
       "4                                   -1   \n",
       "5                                   -1   \n",
       "6                                   -1   \n",
       "7                                   -1   \n",
       "8                                   -1   \n",
       "9                                   -1   \n",
       "10                                  -1   \n",
       "11                                  -1   \n",
       "\n",
       "                                               params  \\\n",
       "0   {'randomforestregressor__max_features': 'auto'...   \n",
       "1   {'randomforestregressor__max_features': 'auto'...   \n",
       "2   {'randomforestregressor__max_features': 'auto'...   \n",
       "3   {'randomforestregressor__max_features': 'auto'...   \n",
       "4   {'randomforestregressor__max_features': 'sqrt'...   \n",
       "5   {'randomforestregressor__max_features': 'sqrt'...   \n",
       "6   {'randomforestregressor__max_features': 'sqrt'...   \n",
       "7   {'randomforestregressor__max_features': 'sqrt'...   \n",
       "8   {'randomforestregressor__max_features': 'log2'...   \n",
       "9   {'randomforestregressor__max_features': 'log2'...   \n",
       "10  {'randomforestregressor__max_features': 'log2'...   \n",
       "11  {'randomforestregressor__max_features': 'log2'...   \n",
       "\n",
       "    split0_test_neg_mean_squared_error  split1_test_neg_mean_squared_error  \\\n",
       "0                        -3.227463e+07                       -2.540520e+07   \n",
       "1                        -3.126961e+07                       -2.576737e+07   \n",
       "2                        -3.115812e+07                       -2.635577e+07   \n",
       "3                        -3.228376e+07                       -2.643556e+07   \n",
       "4                        -5.329502e+07                       -4.575603e+07   \n",
       "5                        -6.239979e+07                       -5.342955e+07   \n",
       "6                        -6.565054e+07                       -5.502786e+07   \n",
       "7                        -7.214923e+07                       -6.108773e+07   \n",
       "8                        -6.782676e+07                       -5.988690e+07   \n",
       "9                        -8.888983e+07                       -7.847161e+07   \n",
       "10                       -9.327403e+07                       -8.129973e+07   \n",
       "11                       -1.031494e+08                       -8.965640e+07   \n",
       "\n",
       "    ...  split3_test_r2  split4_test_r2  split5_test_r2  split6_test_r2  \\\n",
       "0   ...        0.717625        0.753864        0.749695        0.747150   \n",
       "1   ...        0.715874        0.748649        0.748802        0.750466   \n",
       "2   ...        0.715230        0.745633        0.748341        0.751811   \n",
       "3   ...        0.709505        0.740073        0.745272        0.744977   \n",
       "4   ...        0.519887        0.518910        0.519820        0.514946   \n",
       "5   ...        0.458844        0.446899        0.443512        0.449501   \n",
       "6   ...        0.431732        0.419561        0.426908        0.408839   \n",
       "7   ...        0.380340        0.374289        0.371431        0.375120   \n",
       "8   ...        0.390978        0.386582        0.389897        0.381304   \n",
       "9   ...        0.218144        0.231553        0.226063        0.217273   \n",
       "10  ...        0.184179        0.154816        0.158329        0.165610   \n",
       "11  ...        0.102184        0.114223        0.069746        0.092290   \n",
       "\n",
       "    split7_test_r2  split8_test_r2  split9_test_r2  mean_test_r2  std_test_r2  \\\n",
       "0         0.752879        0.730562        0.744089      0.739281     0.013740   \n",
       "1         0.759427        0.727782        0.747192      0.740282     0.013346   \n",
       "2         0.756444        0.725691        0.746277      0.738886     0.013071   \n",
       "3         0.751783        0.720423        0.745622      0.734175     0.014182   \n",
       "4         0.528366        0.502515        0.530100      0.520722     0.010078   \n",
       "5         0.456716        0.442085        0.454276      0.451695     0.007043   \n",
       "6         0.416869        0.407426        0.421648      0.420417     0.011184   \n",
       "7         0.383868        0.369289        0.358128      0.371895     0.009286   \n",
       "8         0.394662        0.370049        0.388103      0.386476     0.009058   \n",
       "9         0.222863        0.238675        0.209781      0.217647     0.012152   \n",
       "10        0.164882        0.162990        0.158970      0.165549     0.009495   \n",
       "11        0.077326        0.095549        0.078587      0.089456     0.012698   \n",
       "\n",
       "    rank_test_r2  \n",
       "0              2  \n",
       "1              1  \n",
       "2              3  \n",
       "3              4  \n",
       "4              5  \n",
       "5              6  \n",
       "6              7  \n",
       "7              9  \n",
       "8              8  \n",
       "9             10  \n",
       "10            11  \n",
       "11            12  \n",
       "\n",
       "[12 rows x 34 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Random Forest Regression code\"\"\"\n",
    "\n",
    "rfrPipe = make_pipeline(RandomForestRegressor())\n",
    "rfrParams = [\n",
    "    {\n",
    "         'randomforestregressor__n_jobs':[-1],\n",
    "         'randomforestregressor__max_features':['auto','sqrt','log2'],\n",
    "         'randomforestregressor__min_samples_leaf':[1,3,5,10]\n",
    "\n",
    "\n",
    "    }\n",
    "]\n",
    "cv = ShuffleSplit(n_splits=10, test_size=.2, random_state=86)\n",
    "#Perform the grid search using accuracy as a metric during cross validation.\n",
    "grid = GridSearchCV(rfrPipe, rfrParams, cv=cv, scoring=['neg_mean_squared_error','r2'], n_jobs=-1, refit='neg_mean_squared_error')\n",
    "#Use the best features from recursive feature elimination during the grid search\n",
    "start_time = timeit.default_timer()\n",
    "grid.fit(reg_X_train, reg_y_train)\n",
    "grid_time = timeit.default_timer() - start_time\n",
    "#display the best pipeline model identified during the grid search\n",
    "print(\"\\ngrid time: \", grid_time)\n",
    "gridResults = pd.DataFrame.from_dict(grid.cv_results_)\n",
    "gridResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:57:36.790894Z",
     "start_time": "2020-07-05T05:50:09.659939Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dustin/anaconda3/envs/DS7331/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    }
   ],
   "source": [
    "\n",
    "RegKnnPipe = make_pipeline(KNeighborsRegressor())\n",
    "RegKnnParams = [\n",
    "    {\n",
    "         'kneighborsregressor__weights': ['uniform','distance'],\n",
    "         'kneighborsregressor__leaf_size': [30,50,100],\n",
    "         'kneighborsregressor__p': [1,2],\n",
    "         'kneighborsregressor__algorithm':['atuo','ball_tre','kd_tree','brute'],\n",
    "         'kneighborsregressor__n_neighbors':[3,5,7,9,11,13,15],\n",
    "         'kneighborsregressor__n_jobs':[-1]\n",
    "    }\n",
    "]\n",
    "cv = ShuffleSplit(n_splits=10, test_size=.2, random_state=86)\n",
    "#Perform the grid search using accuracy as a metric during cross validation.\n",
    "grid = GridSearchCV(RegKnnPipe, RegKnnParams, cv=cv, scoring=['neg_mean_squared_error','r2'], n_jobs=-1, refit='neg_mean_squared_error')\n",
    "#Use the best features from recursive feature elimination during the grid search\n",
    "start_time = timeit.default_timer()\n",
    "grid.fit(reg_X_train, reg_y_train)\n",
    "grid_time = timeit.default_timer() - start_time\n",
    "#display the best pipeline model identified during the grid search\n",
    "print(\"\\ngrid time: \", grid_time)\n",
    "gridResults = pd.DataFrame.from_dict(grid.cv_results_)\n",
    "gridResults\n",
    "#grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T06:14:13.613305Z",
     "start_time": "2020-07-05T06:14:12.389006Z"
    }
   },
   "outputs": [],
   "source": [
    "#reg_y_pred = grid.predict(reg_X_test)\n",
    "from yellowbrick.regressor import PredictionError\n",
    "\n",
    "model = grid.best_estimator_[0]\n",
    "visualizer = PredictionError(model)\n",
    "\n",
    "visualizer.fit(reg_X_train, reg_y_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(reg_X_test, reg_y_test)  # Evaluate the model on the test data\n",
    "visualizer.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluations 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO:__ Visualize results \n",
    "\n",
    "People don't explain 'why' which will deduct points \n",
    "\n",
    "Analyze how the model is performing \n",
    "\n",
    "Explaination is bolstered by analysis \n",
    "\n",
    "TIP: YellowBrick (it's a pkg) for visualizing estimators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interp\n",
    "#define 3 functions to plot the ROC curve\n",
    "def calculate_probability(classifier, A, B, D):\n",
    "    probas_ = classifier.fit(A, B).predict_proba(D)\n",
    "    return probas_\n",
    "\n",
    "#def calculate_probability_based_on_confidence(classifier, A, B, D):\n",
    "#    probas_ = classifier.fit(A, B).decision_function(D)\n",
    "#    return probas_\n",
    "    \n",
    "def plotROCcurve(classifier, X, y, cv, calculate_probability, model):\n",
    "    # Run classifier with cross-validation and plot ROC curves\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "    i = 0\n",
    "    for train, test in cv.split(X, y):\n",
    "        probas_ = calculate_probability(classifier, X[train], y[train], X[test])\n",
    "        # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "        plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "             label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "        i += 1\n",
    "        \n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "        \n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "        \n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "    \n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Receiver operating characteristic--{model}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    return mean_fpr, mean_tpr, mean_auc, std_auc\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#plot random forest ROC curves and AUC\n",
    "classifier = best_rf_clf.best_estimator_\n",
    "\n",
    "mean_fpr_rf, mean_tpr_rf, mean_auc_rf, std_auc_rf = plotROCcurve(classifier, X,target_df, cv, calculate_probability, model='Random Forest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluations 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO:__\n",
    "Discuss advantages of models for a classification task \n",
    "\n",
    "Give table, how many models you built \n",
    "\n",
    "CV results object from grid search will give all of that information \n",
    "\n",
    "TIP Put in a dataframe in ME5 and then talk about \n",
    "\n",
    "Here's all the models we did, here is the best one (or top 3) \n",
    "\n",
    "Is there one that runs 10x as long and a slightly inferior runs fast \n",
    "\n",
    "Is the difference between models significant? \n",
    "\n",
    "Long method 1: Notebook #6 and use student's paired t test (at bottom), correct t value and folds \n",
    "\n",
    "Long method 2: generate ROC curves for each model \n",
    "\n",
    "If you use ROC as your eval metric, it is statistically sound measure, so if one has a larger area under curve, it is a better model statistically speaking. \n",
    "\n",
    "Can use micro average ROC curve with multiclass problem \n",
    "\n",
    "If you already did both, ask for exceptional points \n",
    "\n",
    "TIP: mlxtend has an 'evaluate' library for significant test \n",
    "\n",
    "Can get comprehensive with paired_ttest5x2cv \n",
    "\n",
    "Calling library and function will spit out exactly what you need "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluations 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO:__\n",
    "    Two options: \n",
    "\n",
    "Both tasks are on same dataset.  do two feature importance and opine difference between two \n",
    "\n",
    "Make sure you do feature importance on scaled data if you're using coefficients \n",
    "\n",
    "Use some other type of feature eval technique (mlextend library has multiple options) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO:__\n",
    "    Address each question (in a subsection) \n",
    "\n",
    "2 ways to go about it \n",
    "\n",
    "Just because you can't predict something in the real world, doesn't necessarily mean you aren't interested in model's ability to predict \n",
    "\n",
    "Predict graduation rate for public schools (schools know their rates.. But they would be interested in what is correlated with grad rates) \n",
    "\n",
    "Maybe it's not useful for prediction, but could be used for EDA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exceptional Work\n",
    "### Preprocessing:\n",
    "We would like credit for the large amount of preprocessing that went into our data.  We have a large variety of features in the dataset, many of which required clever feature engineering tricks to improve performance.  Conversion to the sparse matrix took a good bit of research, and continues to be an effort for implementation, since not every model or library will accept a sparse matrix.  The conversion of procedure codes and diagnosis codes from multiple columns into a one hot encoded dataframe took a significant amount of time/effort, most of the out of the box libraries we tried would not parse a list object and it took a lot of experimentation and research.  The performance improved as it reduced our total featureset footprint from > 40,000 to around 9,000.   \n",
    "\n",
    "### Pipelines and Grid Search:\n",
    "We decided to implement Pipelines and Grid Search in order to reduce the copy/paste and number of variables we need to work with.  This is a new concept barely touched on in class, and it required significant amounts of research time to implement before we could move on to model evaluation, visualization and discussion.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <a href=\"https://machinelearningmastery.com/k-fold-cross-validation/\"> https://machinelearningmastery.com/k-fold-cross-validation/ </a> K-Fold Cross Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": false,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": true,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "285px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 365,
   "position": {
    "height": "40px",
    "left": "789px",
    "right": "20px",
    "top": "119px",
    "width": "630px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
