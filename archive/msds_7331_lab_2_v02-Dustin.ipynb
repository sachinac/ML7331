{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6> <b> SMU Lab Two - MSDS7331 - Machine Learning-1 </b> </font>\n",
    "\n",
    "<font size=5> <b> Summer 2020 Group - Sachin, Ikenna, Edgar, Dustin </b></font> \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/sachinac/ML7331/blob/master/data/data_mining.jpg?raw=true\"> \n",
    "\n",
    "<p align=\"center\"><font size=5> <b> Health Care Fraud Detection  </b></font> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-1\">Import Libraries</a></span></li><li><span><a href=\"#Data-Preparation-Part-1\" data-toc-modified-id=\"Data-Preparation-Part-1-2\">Data Preparation Part 1</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-2.1\">Load Data</a></span></li><li><span><a href=\"#Categorical-Variables\" data-toc-modified-id=\"Categorical-Variables-2.2\">Categorical Variables</a></span></li><li><span><a href=\"#Float-Variables\" data-toc-modified-id=\"Float-Variables-2.3\">Float Variables</a></span></li><li><span><a href=\"#Integer-Variables\" data-toc-modified-id=\"Integer-Variables-2.4\">Integer Variables</a></span></li><li><span><a href=\"#Dates-Variables\" data-toc-modified-id=\"Dates-Variables-2.5\">Dates Variables</a></span></li><li><span><a href=\"#Recoding\" data-toc-modified-id=\"Recoding-2.6\">Recoding</a></span></li><li><span><a href=\"#Dataframe\" data-toc-modified-id=\"Dataframe-2.7\">Dataframe</a></span></li><li><span><a href=\"#All-Features\" data-toc-modified-id=\"All-Features-2.8\">All Features</a></span></li><li><span><a href=\"#Target-Variable\" data-toc-modified-id=\"Target-Variable-2.9\">Target Variable</a></span></li><li><span><a href=\"#One-Hot-Encoding-using-Pandas\" data-toc-modified-id=\"One-Hot-Encoding-using-Pandas-2.10\">One Hot Encoding using Pandas</a></span></li><li><span><a href=\"#Remove-None-columns\" data-toc-modified-id=\"Remove-None-columns-2.11\">Remove None columns</a></span></li><li><span><a href=\"#MinMaxScaler\" data-toc-modified-id=\"MinMaxScaler-2.12\">MinMaxScaler</a></span></li></ul></li><li><span><a href=\"#Data-Preparation-Part-2\" data-toc-modified-id=\"Data-Preparation-Part-2-3\">Data Preparation Part 2</a></span><ul class=\"toc-item\"><li><span><a href=\"#Final-DataSet\" data-toc-modified-id=\"Final-DataSet-3.1\">Final DataSet</a></span></li><li><span><a href=\"#Sparse-Matrix\" data-toc-modified-id=\"Sparse-Matrix-3.2\">Sparse Matrix</a></span></li><li><span><a href=\"#Train-and-Test-split\" data-toc-modified-id=\"Train-and-Test-split-3.3\">Train and Test split</a></span></li></ul></li><li><span><a href=\"#Modeling-and-Evaluations-1\" data-toc-modified-id=\"Modeling-and-Evaluations-1-4\">Modeling and Evaluations 1</a></span></li><li><span><a href=\"#Modeling-and-Evaluations-2\" data-toc-modified-id=\"Modeling-and-Evaluations-2-5\">Modeling and Evaluations 2</a></span></li><li><span><a href=\"#Modeling-and-Evaluations-3\" data-toc-modified-id=\"Modeling-and-Evaluations-3-6\">Modeling and Evaluations 3</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-Models\" data-toc-modified-id=\"Create-Models-6.1\">Create Models</a></span></li></ul></li><li><span><a href=\"#Modeling-and-Evaluations-4\" data-toc-modified-id=\"Modeling-and-Evaluations-4-7\">Modeling and Evaluations 4</a></span></li><li><span><a href=\"#Modeling-and-Evaluations-5\" data-toc-modified-id=\"Modeling-and-Evaluations-5-8\">Modeling and Evaluations 5</a></span></li><li><span><a href=\"#Modeling-and-Evaluations-6\" data-toc-modified-id=\"Modeling-and-Evaluations-6-9\">Modeling and Evaluations 6</a></span></li><li><span><a href=\"#Deployment\" data-toc-modified-id=\"Deployment-10\">Deployment</a></span></li><li><span><a href=\"#Exceptional-Work\" data-toc-modified-id=\"Exceptional-Work-11\">Exceptional Work</a></span></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-12\">References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:20:22.306706Z",
     "start_time": "2020-07-01T06:20:21.565885Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import timeit\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, MultiLabelBinarizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.sparse import csc_matrix\n",
    "from math import sqrt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data into memory. EDA was already performed on this data. We had originally received Beneficiary, Encounters and target variable datasets in three different spreadsheets and EDA combined that into single spreadsheet using keys of the tables. We still need to perform some additional operations before we actually start with modeling. So in first we prepare our data for modeling as follows :\n",
    "* Prepare variables. Setup data type correctly.\n",
    "* Remove unnecessary variables\n",
    "* Transform categorical features into dummy variables \n",
    "* Feature selection.\n",
    "\n",
    "Lets first print the information of this dataframe. As we can see from below dataframe info this data has total of 79 features. We definately dont need all features. This step will process some of the features before we actually use this data for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:20:22.862306Z",
     "start_time": "2020-07-01T06:20:22.308794Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lab2_df = pd.read_csv('data/final_fraud_dataset.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T08:51:44.322459Z",
     "start_time": "2020-06-30T08:51:44.318865Z"
    }
   },
   "source": [
    "Following are nominal categorical attributes. Pandas requires these to be datatype of 'object' or 'category'. We are setting nominal categorical variables as 'object'. Here is the list of categorical variables :\n",
    "\n",
    "* Race\n",
    "* Gender\n",
    "* RenalDiseaseIndicator\n",
    "* State\n",
    "* County\n",
    "* AttendingPhysicianPresent\n",
    "* OtherPhysicianPresent\n",
    "* OperatingPhysicianPresent\n",
    "* 11 Chronic Conditions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:20:22.941163Z",
     "start_time": "2020-07-01T06:20:22.864346Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_preds = ['Gender','Race','RenalDiseaseIndicator','State','County',\n",
    "                     'NoOfMonths_PartACov','NoOfMonths_PartBCov',\n",
    "                     'ChronicCond_Alzheimer','ChronicCond_Heartfailure',\n",
    "                     'ChronicCond_KidneyDisease','ChronicCond_Cancer','ChronicCond_ObstrPulmonary',\n",
    "                     'ChronicCond_Depression','ChronicCond_Diabetes','ChronicCond_IschemicHeart',\n",
    "                     'ChronicCond_Osteoporasis','ChronicCond_rheumatoidarthritis','ChronicCond_stroke',\n",
    "                     'Alive','ClmAdmitDiagnosisCode','DiagnosisGroupCode',\n",
    "                     'ClmDiagnosisCode_1','ClmDiagnosisCode_2','ClmDiagnosisCode_3',\n",
    "                     'ClmDiagnosisCode_4','ClmDiagnosisCode_5','ClmDiagnosisCode_6',\n",
    "                     'ClmDiagnosisCode_7','ClmDiagnosisCode_8','ClmDiagnosisCode_9',\n",
    "                     'ClmDiagnosisCode_10','ClmProcedureCode_1','ClmProcedureCode_2',\n",
    "                     'ClmProcedureCode_3','ClmProcedureCode_4','ClmProcedureCode_5',\n",
    "                     'AttendingPhysicianPresent','OtherPhysicianPresent','OperatingPhysicianPresent']\n",
    "\n",
    "lab2_df[cat_preds]   = lab2_df[cat_preds].astype('object')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Float Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following varibles are required to be datatype of floating point. These are amounts and hence it makes sense to changt it's type to float\n",
    "\n",
    "* InscClaimAmtReimbursed\n",
    "* IPAnnualReimbursementAmt\n",
    "* IPAnnualDeductibleAmt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:20:23.228305Z",
     "start_time": "2020-07-01T06:20:23.213497Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "float_preds = ['InscClaimAmtReimbursed','IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt']\n",
    "\n",
    "lab2_df[float_preds]   = lab2_df[float_preds].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Integer Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These variables contains all numbers but they are actually nominal categorical attributes. They are all binary in nature. So we can keep them as integer as we will be converting this dataset into sparse matrix for model building exercise. \n",
    "\n",
    "Following variables will be set as integer data type :\n",
    "* NoOfMonths_PartACov - Number of months of Medicare part A coverage\n",
    "* NoOfMonths_PartBCov - Number of months of Medicare part B coverage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:20:23.670649Z",
     "start_time": "2020-07-01T06:20:23.653465Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "int_preds = ['NoOfMonths_PartACov', \n",
    "             'NoOfMonths_PartBCov']\n",
    "\n",
    "lab2_df[int_preds] = lab2_df[int_preds].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Date Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are new attributes are derived from existing attritbutes of type dates. All date attributes are converted to the proleptic Gregorian ordinal of a date.In simple terms datetime.toordinal() returns the day count from the date 01/01/01\n",
    "\n",
    "\n",
    "* ORD_DOD - Set ORD_DOD to open end date where date is not available to indicate that Beneficiary is alive\n",
    "* ORD_DOB \n",
    "* ORD_ClaimStartDt\n",
    "* ORD_ClaimEndDt\n",
    "* ORD_AdmissionDt\n",
    "* ORD_DischargeDt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:20:24.921116Z",
     "start_time": "2020-07-01T06:20:24.103048Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dte_preds = ['ClaimStartDt', 'ClaimEndDt','AdmissionDt', 'DischargeDt', 'DOB','DOD']\n",
    "\n",
    "# Regex to normalize integer DOB/DOD as ISO dates\n",
    "lab2_df['DOB'] = lab2_df['DOB'].astype(str).str.replace('(\\d{4})(\\d\\d)(\\d\\d)', '\\\\1-\\\\2-\\\\3', regex=True) \n",
    "lab2_df['DOD'] = lab2_df['DOD'].astype(str).str.replace('(\\d{4})(\\d\\d)(\\d\\d)', '\\\\1-\\\\2-\\\\3', regex=True) \n",
    "\n",
    "lab2_df['ORD_DOD'] = lab2_df['DOD']\n",
    "lab2_df['ORD_DOD'] = lab2_df['ORD_DOD'].replace('0','2199-12-31')\n",
    "\n",
    "lab2_df['ORD_DOD'] = pd.to_datetime(lab2_df['ORD_DOD'],format='%Y-%m-%d').apply(dt.datetime.toordinal)\n",
    "lab2_df['ORD_DOB'] = pd.to_datetime(lab2_df['DOB'],format='%Y-%m-%d').apply(dt.datetime.toordinal)\n",
    "lab2_df['ORD_ClaimStartDt'] = pd.to_datetime(lab2_df['ClaimStartDt'],format='%Y-%m-%d').apply(dt.datetime.toordinal)\n",
    "lab2_df['ORD_ClaimEndDt']   = pd.to_datetime(lab2_df['ClaimEndDt'],format='%Y-%m-%d').apply(dt.datetime.toordinal)\n",
    "lab2_df['ORD_AdmissionDt']  = pd.to_datetime(lab2_df['AdmissionDt'],format='%Y-%m-%d').apply(dt.datetime.toordinal)\n",
    "lab2_df['ORD_DischargeDt']  = pd.to_datetime(lab2_df['DischargeDt'],format='%Y-%m-%d').apply(dt.datetime.toordinal)\n",
    "\n",
    "ord_dte_preds = ['ORD_DOD', 'ORD_DOB','ORD_ClaimStartDt', 'ORD_ClaimEndDt', 'ORD_AdmissionDt','ORD_DischargeDt']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recoding Binary and Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All chronic conditions, Gender, RenalDiseaseIndicator are binary variables i.e. they all have just two values but values are not 0 and 1. e.g. Gender has values 1 or 2, RenalDiseaseIndicator has Y or 1 and all Chronic Conditions has values 1 or 2. \n",
    "\n",
    "We will recode these values to 0 or 1 instead of 1 and 2 for modeling purpose. Leaving two columns for a binary feature can introduce bias, giving one feature artificially more weight in prediction if the model treats the single feature as two.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:20:25.019661Z",
     "start_time": "2020-07-01T06:20:24.923231Z"
    }
   },
   "outputs": [],
   "source": [
    "# Recode below categorical variables \n",
    "\n",
    "lab2_df['Gender']  = lab2_df['Gender'].replace([1,2],[0,1])\n",
    "lab2_df['RenalDiseaseIndicator']  = lab2_df['RenalDiseaseIndicator'].replace('Y',1)\n",
    "\n",
    "\n",
    "lab2_df = lab2_df.replace({'ChronicCond_Alzheimer': 2,      'ChronicCond_Heartfailure': 2, \n",
    "                           'ChronicCond_KidneyDisease': 2,  'ChronicCond_Cancer': 2, \n",
    "                           'ChronicCond_ObstrPulmonary': 2, 'ChronicCond_Depression': 2, \n",
    "                           'ChronicCond_Diabetes': 2,       'ChronicCond_IschemicHeart': 2, \n",
    "                           'ChronicCond_Osteoporasis': 2,   'ChronicCond_rheumatoidarthritis': 2, \n",
    "                           'ChronicCond_stroke': 2 }, '0')\n",
    "\n",
    "lab2_df['Gender'] = lab2_df['Gender'].astype('object')\n",
    "lab2_df['Race'] = lab2_df['Race'].astype('object')\n",
    "lab2_df['State'] = lab2_df['State'].astype('object')\n",
    "lab2_df['County'] = lab2_df['County'].astype('object')\n",
    "lab2_df['OtherPhysicianPresent'] = lab2_df['OtherPhysicianPresent'].astype('object')\n",
    "lab2_df['OperatingPhysicianPresent'] = lab2_df['OperatingPhysicianPresent'].astype('object')\n",
    "lab2_df['AttendingPhysicianPresent'] = lab2_df['AttendingPhysicianPresent'].astype('object')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Dataframe - All Features\n",
    "All features are GROUPED as follows:\n",
    "* Numeric Predictors\n",
    "* Categorical Predictors\n",
    "* Non-Predictors (Will not be used for modeling)\n",
    "\n",
    "We chose to remove all ID columns from the data, as they aren't useful in prediction (unique IDs = N observations).  We replaced the original date features with their ordinal conversions.  We removed all providerIDs from the dataset, because these are correlated 1:1 with the response.  Unfortunately, our data lists only the provider ID as the response variable (potentially fraudulent), so the prediction algorithm gets 'the answer' if the provider ID shows up in attending, operating, or other physician columns.  Removing these from the dataset limits the prediction ability of our algorithms, but more closely represents reality, where a provider's fraudulent behavior is unknown at the time of claim review.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:20:25.274701Z",
     "start_time": "2020-07-01T06:20:25.213964Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_preds     = ['Age','NoPhysician','NoOfDiag','NoOfProc',\n",
    "                     'ORD_DOD','ORD_DOB','ORD_ClaimStartDt','ORD_ClaimEndDt',\n",
    "                     'ORD_AdmissionDt','ORD_DischargeDt','DaysAdmitted',\n",
    "                     'IPAnnualReimbursementAmt','IPAnnualDeductibleAmt',   \n",
    "                     'InscClaimAmtReimbursed'  \n",
    "                    ]\n",
    "\n",
    "cat_preds_nominal = ['Gender','Race','RenalDiseaseIndicator','State','County',\n",
    "                     'NoOfMonths_PartACov','NoOfMonths_PartBCov',\n",
    "                     'ChronicCond_Alzheimer','ChronicCond_Heartfailure',\n",
    "                     'ChronicCond_KidneyDisease','ChronicCond_Cancer','ChronicCond_ObstrPulmonary',\n",
    "                     'ChronicCond_Depression','ChronicCond_Diabetes','ChronicCond_IschemicHeart',\n",
    "                     'ChronicCond_Osteoporasis','ChronicCond_rheumatoidarthritis','ChronicCond_stroke',\n",
    "                     'Alive','ClmAdmitDiagnosisCode','DiagnosisGroupCode',\n",
    "                     'ClmDiagnosisCode_1','ClmDiagnosisCode_2','ClmDiagnosisCode_3',\n",
    "                     'ClmDiagnosisCode_4','ClmDiagnosisCode_5','ClmDiagnosisCode_6',\n",
    "                     'ClmDiagnosisCode_7','ClmDiagnosisCode_8','ClmDiagnosisCode_9',\n",
    "                     'ClmDiagnosisCode_10','ClmProcedureCode_1','ClmProcedureCode_2',\n",
    "                     'ClmProcedureCode_3','ClmProcedureCode_4','ClmProcedureCode_5',\n",
    "                     'AttendingPhysicianPresent','OtherPhysicianPresent','OperatingPhysicianPresent'\n",
    "                     ]\n",
    "\n",
    "non_preds = ['BeneID','DOB','DOD','state_usps','ClaimID',\n",
    "             'ClaimStartDt','ClaimEndDt','Provider',\n",
    "             'AttendingPhysician','OperatingPhysician','OtherPhysician',\n",
    "             'AdmissionDt','DischargeDt','DRGDesc',\n",
    "             'ProcedureShortDesc_1','ProcedureShortDesc_2','ProcedureShortDesc_3',\n",
    "             'ProcedureShortDesc_4','ProcedureShortDesc_5','DiagnosticDesc_1',\n",
    "             'DiagnosticDesc_2','DiagnosticDesc_3','DiagnosticDesc_4',\n",
    "             'DiagnosticDesc_5','DiagnosticDesc_6','DiagnosticDesc_7',\n",
    "             'DiagnosticDesc_8','DiagnosticDesc_9','DiagnosticDesc_10',\n",
    "             'NoOfChronicCondition'\n",
    "             ]\n",
    "\n",
    "preds_in_model = numeric_preds + cat_preds_nominal\n",
    "\n",
    "Xlab2_df = lab2_df[preds_in_model]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:20:25.452959Z",
     "start_time": "2020-07-01T06:20:25.438950Z"
    }
   },
   "outputs": [],
   "source": [
    "target_df = lab2_df['PotentialFraud'].replace(['Yes','No'],[1,0]).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding using SciKit Learn Multi Label Binarizer\n",
    "\n",
    "Because the claim data can have up to 10 different diagnosis codes and 5 different procedure codes, we created a new array column that combines all used diagnosis codes and another like type column with procedures.  This will reduce our feature counts from >40,000 to around 9,000 and will help maximize feature importance because each code will no longer be split across up to 10 different columns (i.e. diagnosis code columns 1 - 10).  This way if code A gets used in column_1, and in column_2, the usage of code A will be consolidated to the DiagnosisCode_A column.\n",
    "\n",
    "Pandas get_dummies function will not parse lists, we'll need to utilize the multiLabelBinarizer from scikit learn to one-hot encode the list values before calling get_dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dustin/anaconda3/envs/DS7331/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/dustin/anaconda3/envs/DS7331/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "Xlab2_df['DiagnosisCode'] = Xlab2_df[['ClmDiagnosisCode_1', 'ClmDiagnosisCode_2', 'ClmDiagnosisCode_3', 'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5', 'ClmDiagnosisCode_6', 'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8', 'ClmDiagnosisCode_9', 'ClmDiagnosisCode_10']].values.tolist()\n",
    "Xlab2_df['ProcedureCode'] = Xlab2_df[['ClmProcedureCode_1', 'ClmProcedureCode_2', 'ClmProcedureCode_3', 'ClmProcedureCode_4', 'ClmProcedureCode_5']].values.tolist()\n",
    "\n",
    "\n",
    "ipdata = Xlab2_df.copy()\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "ipdata = ipdata.join(pd.DataFrame(mlb.fit_transform(ipdata['ProcedureCode']),columns='ProcedureCode_'+mlb.classes_))\n",
    "ipdata = ipdata.join(pd.DataFrame(mlb.fit_transform(ipdata['DiagnosisCode']),columns='DiagnosisCode_'+mlb.classes_))\n",
    "\n",
    "ipdata = ipdata.drop(columns=['ClmProcedureCode_1', 'ClmProcedureCode_2', 'ClmProcedureCode_3', 'ClmProcedureCode_4', 'ClmProcedureCode_5','ClmDiagnosisCode_1', 'ClmDiagnosisCode_2', 'ClmDiagnosisCode_3', 'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5', 'ClmDiagnosisCode_6', 'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8', 'ClmDiagnosisCode_9', 'ClmDiagnosisCode_10','ProcedureCode','DiagnosisCode'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding using Pandas\n",
    "\n",
    "Now that we've dropped our multi-columns and lists, we can onehot encode the rest of the features and transform into a sparse matrix using Pandas Get Dummies function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:20:32.550699Z",
     "start_time": "2020-07-01T06:20:25.870249Z"
    }
   },
   "outputs": [],
   "source": [
    "ipdata = pd.get_dummies(ipdata, sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:20:33.917009Z",
     "start_time": "2020-07-01T06:20:32.552787Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40474 entries, 0 to 40473\n",
      "Columns: 9095 entries, Age to OperatingPhysicianPresent_1\n",
      "dtypes: Sparse[uint8, 0](3040), float64(3), int64(6052)\n",
      "memory usage: 1.8 GB\n"
     ]
    }
   ],
   "source": [
    "ipdata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing Encoded Features\n",
    "\n",
    "Because we are using objects, Pandas converts all classes into new columns.  However, for binary features, we want to remove one of the values, in order to prevent the model from introducing bias by weighting each binary feature twice (via separate true/false columns).\n",
    "\n",
    "To correct this, we must search for and remove duplicate columns (indicated by the _0 suffix).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed Following Columns:\n",
      "Gender_0\n",
      "RenalDiseaseIndicator_0\n",
      "ChronicCond_Alzheimer_0\n",
      "ChronicCond_Heartfailure_0\n",
      "ChronicCond_KidneyDisease_0\n",
      "ChronicCond_Cancer_0\n",
      "ChronicCond_ObstrPulmonary_0\n",
      "ChronicCond_Depression_0\n",
      "ChronicCond_Diabetes_0\n",
      "ChronicCond_IschemicHeart_0\n",
      "ChronicCond_Osteoporasis_0\n",
      "ChronicCond_rheumatoidarthritis_0\n",
      "ChronicCond_stroke_0\n",
      "AttendingPhysicianPresent_0\n",
      "OtherPhysicianPresent_0\n",
      "OperatingPhysicianPresent_0\n"
     ]
    }
   ],
   "source": [
    "StopWords = ['Diagnosis','Procedure','County','State']\n",
    "bins = []\n",
    "print('Removed Following Columns:')\n",
    "for col in ipdata.columns:\n",
    "    if not any(word in col for word in StopWords) and '_0' in col:    \n",
    "        print(col)\n",
    "        bins.append(col)\n",
    "ipdata = ipdata.drop(bins, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove 'None' columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our encoded dataset contains None for Diagnosis and Procedure codes features wherever information is not available on the claim. All claims allows max 5 procedure codes and 10 diagnosis codes and at least one procedure code or diagnosis code is applied on the claim. When claim has only one procedure and one diagnosis all other procedure codes contains NAs or None and one hot encoding treats these as another category which is not correct. therefore we need to remove column Nones created by one hot encoding by pandas.\n",
    "\n",
    "Essentially by creating a 'none' column it creates a column (new feature) for missing data, which would erroneously assign more weight to a value that doesn't exist.  Because it would get a '1' for missing a value, but would also have 0's for the other values.  Also it may mess up our counts because 'None' would count as a valid procedure code if we're summing unique values for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:20:36.456807Z",
     "start_time": "2020-07-01T06:20:33.919257Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed Following Columns:\n",
      "ProcedureCode_None\n",
      "DiagnosisCode_None\n"
     ]
    }
   ],
   "source": [
    "nones = []\n",
    "print('Removed Following Columns:')\n",
    "for col in ipdata.columns:\n",
    "    if 'None' in col:    \n",
    "        nones.append(col)\n",
    "        print(col)\n",
    "ipdata = ipdata.drop(nones, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:20:37.867818Z",
     "start_time": "2020-07-01T06:20:36.458927Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40474 entries, 0 to 40473\n",
      "Columns: 9077 entries, Age to OperatingPhysicianPresent_1\n",
      "dtypes: Sparse[uint8, 0](3024), float64(3), int64(6050)\n",
      "memory usage: 1.8 GB\n"
     ]
    }
   ],
   "source": [
    "ipdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stash an unscaled copy of the target column, and the dataframe\n",
    "reg_target = ipdata['InscClaimAmtReimbursed']\n",
    "reg_df = ipdata.drop(columns=['InscClaimAmtReimbursed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to use the MinMaxScaler here instead of the standard scaler because we're using a sparse matrix of mostly binary features.  Because we do have some true numeric features, such as: deductible amount, age, the converted ordinal dates, claim dollar amounts etc, these may end up having values outside the bounds of 0 and 1.  A zero mean scaler doesn't make sense with this data because it would cause the numeric features to have inflated importance if observations end up being several standard deviations away from 0, while the binary features are capped at 1.  The minMax scaler allows us to force all values in the dataset to live within the bounds of 0 and 1, allowing our logistic regression algorithms to weight features appropriately using similar measures.\n",
    "\n",
    "For regression, we must also scale the response variable, so that we can correctly predict against "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:22:57.635492Z",
     "start_time": "2020-07-01T06:20:37.870137Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(ipdata)\n",
    "X1 = scaler.transform(ipdata)\n",
    "\n",
    "#reg_scaler = MinMaxScaler()\n",
    "#reg_scaler.fit(reg_df)\n",
    "#X1 = scaler.transform(reg_df)\n",
    "\n",
    "#scaler = MinMaxScaler()\n",
    "#scaler.fit(ipdata)\n",
    "#X1 = scaler.transform(ipdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Part 2\n",
    "\n",
    "We ended up with two variants of our final dataset: the sparse matrix (ipdata) containing all one-hot encoded features, and the original dataframe (Xlab2_df) so that if we need to retrieve any of the original data, we can share indices to highlight our findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:22:57.784631Z",
     "start_time": "2020-07-01T06:22:57.649511Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40474 entries, 0 to 40473\n",
      "Data columns (total 55 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Age                              40474 non-null  int64  \n",
      " 1   NoPhysician                      40474 non-null  int64  \n",
      " 2   NoOfDiag                         40474 non-null  int64  \n",
      " 3   NoOfProc                         40474 non-null  int64  \n",
      " 4   ORD_DOD                          40474 non-null  int64  \n",
      " 5   ORD_DOB                          40474 non-null  int64  \n",
      " 6   ORD_ClaimStartDt                 40474 non-null  int64  \n",
      " 7   ORD_ClaimEndDt                   40474 non-null  int64  \n",
      " 8   ORD_AdmissionDt                  40474 non-null  int64  \n",
      " 9   ORD_DischargeDt                  40474 non-null  int64  \n",
      " 10  DaysAdmitted                     40474 non-null  int64  \n",
      " 11  IPAnnualReimbursementAmt         40474 non-null  float64\n",
      " 12  IPAnnualDeductibleAmt            40474 non-null  float64\n",
      " 13  InscClaimAmtReimbursed           40474 non-null  float64\n",
      " 14  Gender                           40474 non-null  object \n",
      " 15  Race                             40474 non-null  object \n",
      " 16  RenalDiseaseIndicator            40474 non-null  object \n",
      " 17  State                            40474 non-null  object \n",
      " 18  County                           40474 non-null  object \n",
      " 19  NoOfMonths_PartACov              40474 non-null  int64  \n",
      " 20  NoOfMonths_PartBCov              40474 non-null  int64  \n",
      " 21  ChronicCond_Alzheimer            40474 non-null  object \n",
      " 22  ChronicCond_Heartfailure         40474 non-null  object \n",
      " 23  ChronicCond_KidneyDisease        40474 non-null  object \n",
      " 24  ChronicCond_Cancer               40474 non-null  object \n",
      " 25  ChronicCond_ObstrPulmonary       40474 non-null  object \n",
      " 26  ChronicCond_Depression           40474 non-null  object \n",
      " 27  ChronicCond_Diabetes             40474 non-null  object \n",
      " 28  ChronicCond_IschemicHeart        40474 non-null  object \n",
      " 29  ChronicCond_Osteoporasis         40474 non-null  object \n",
      " 30  ChronicCond_rheumatoidarthritis  40474 non-null  object \n",
      " 31  ChronicCond_stroke               40474 non-null  object \n",
      " 32  Alive                            40474 non-null  object \n",
      " 33  ClmAdmitDiagnosisCode            40474 non-null  object \n",
      " 34  DiagnosisGroupCode               40474 non-null  object \n",
      " 35  ClmDiagnosisCode_1               40474 non-null  object \n",
      " 36  ClmDiagnosisCode_2               40474 non-null  object \n",
      " 37  ClmDiagnosisCode_3               40474 non-null  object \n",
      " 38  ClmDiagnosisCode_4               40474 non-null  object \n",
      " 39  ClmDiagnosisCode_5               40474 non-null  object \n",
      " 40  ClmDiagnosisCode_6               40474 non-null  object \n",
      " 41  ClmDiagnosisCode_7               40474 non-null  object \n",
      " 42  ClmDiagnosisCode_8               40474 non-null  object \n",
      " 43  ClmDiagnosisCode_9               40474 non-null  object \n",
      " 44  ClmDiagnosisCode_10              40474 non-null  object \n",
      " 45  ClmProcedureCode_1               40474 non-null  object \n",
      " 46  ClmProcedureCode_2               40474 non-null  object \n",
      " 47  ClmProcedureCode_3               40474 non-null  object \n",
      " 48  ClmProcedureCode_4               40474 non-null  object \n",
      " 49  ClmProcedureCode_5               40474 non-null  object \n",
      " 50  AttendingPhysicianPresent        40474 non-null  object \n",
      " 51  OtherPhysicianPresent            40474 non-null  object \n",
      " 52  OperatingPhysicianPresent        40474 non-null  object \n",
      " 53  DiagnosisCode                    40474 non-null  object \n",
      " 54  ProcedureCode                    40474 non-null  object \n",
      "dtypes: float64(3), int64(13), object(39)\n",
      "memory usage: 17.3+ MB\n"
     ]
    }
   ],
   "source": [
    "Xlab2_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:22:57.872722Z",
     "start_time": "2020-07-01T06:22:57.786692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>NoPhysician</th>\n",
       "      <th>NoOfDiag</th>\n",
       "      <th>NoOfProc</th>\n",
       "      <th>ORD_DOD</th>\n",
       "      <th>ORD_DOB</th>\n",
       "      <th>ORD_ClaimStartDt</th>\n",
       "      <th>ORD_ClaimEndDt</th>\n",
       "      <th>ORD_AdmissionDt</th>\n",
       "      <th>ORD_DischargeDt</th>\n",
       "      <th>...</th>\n",
       "      <th>ClmProcedureCode_1</th>\n",
       "      <th>ClmProcedureCode_2</th>\n",
       "      <th>ClmProcedureCode_3</th>\n",
       "      <th>ClmProcedureCode_4</th>\n",
       "      <th>ClmProcedureCode_5</th>\n",
       "      <th>AttendingPhysicianPresent</th>\n",
       "      <th>OtherPhysicianPresent</th>\n",
       "      <th>OperatingPhysicianPresent</th>\n",
       "      <th>DiagnosisCode</th>\n",
       "      <th>ProcedureCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>803168</td>\n",
       "      <td>709301</td>\n",
       "      <td>733509</td>\n",
       "      <td>733515</td>\n",
       "      <td>733509</td>\n",
       "      <td>733515</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1970, 4019, 5853, 7843, 2768, 71590, 2724, 19...</td>\n",
       "      <td>[None, None, None, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>803168</td>\n",
       "      <td>698678</td>\n",
       "      <td>733427</td>\n",
       "      <td>733439</td>\n",
       "      <td>733427</td>\n",
       "      <td>733439</td>\n",
       "      <td>...</td>\n",
       "      <td>7769.0</td>\n",
       "      <td>5849.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[4240, 2639, 2948, 40390, 45821, 28489, 5854, ...</td>\n",
       "      <td>[7769.0, 5849.0, None, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>803168</td>\n",
       "      <td>701904</td>\n",
       "      <td>733697</td>\n",
       "      <td>733715</td>\n",
       "      <td>733697</td>\n",
       "      <td>733715</td>\n",
       "      <td>...</td>\n",
       "      <td>9338.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[V5789, 4168, 73313, 7812, 7993, 78830, 72273,...</td>\n",
       "      <td>[9338.0, None, None, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>803168</td>\n",
       "      <td>704734</td>\n",
       "      <td>733705</td>\n",
       "      <td>733709</td>\n",
       "      <td>733705</td>\n",
       "      <td>733709</td>\n",
       "      <td>...</td>\n",
       "      <td>8154.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[71535, 71960, 4019, V1202, 4240, 2449, 2768, ...</td>\n",
       "      <td>[8154.0, None, None, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>803168</td>\n",
       "      <td>702970</td>\n",
       "      <td>733415</td>\n",
       "      <td>733419</td>\n",
       "      <td>733415</td>\n",
       "      <td>733419</td>\n",
       "      <td>...</td>\n",
       "      <td>8543.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[2330, None, None, None, None, None, None, Non...</td>\n",
       "      <td>[8543.0, None, None, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40469</th>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>803168</td>\n",
       "      <td>712648</td>\n",
       "      <td>733582</td>\n",
       "      <td>733589</td>\n",
       "      <td>733582</td>\n",
       "      <td>733589</td>\n",
       "      <td>...</td>\n",
       "      <td>9955.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[78079, 45341, V1251, 41401, 2449, 2930, 78830...</td>\n",
       "      <td>[9955.0, None, None, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40470</th>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>803168</td>\n",
       "      <td>709360</td>\n",
       "      <td>733656</td>\n",
       "      <td>733663</td>\n",
       "      <td>733656</td>\n",
       "      <td>733663</td>\n",
       "      <td>...</td>\n",
       "      <td>3326.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[486, 7905, V5867, 5990, 2859, 7904, 49121, 41...</td>\n",
       "      <td>[3326.0, None, None, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40471</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>803168</td>\n",
       "      <td>708174</td>\n",
       "      <td>733726</td>\n",
       "      <td>733734</td>\n",
       "      <td>733726</td>\n",
       "      <td>733734</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[42821, E9342, 42731, 5856, 4280, 5859, 51881,...</td>\n",
       "      <td>[None, None, None, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40472</th>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>803168</td>\n",
       "      <td>714719</td>\n",
       "      <td>733430</td>\n",
       "      <td>733430</td>\n",
       "      <td>733430</td>\n",
       "      <td>733430</td>\n",
       "      <td>...</td>\n",
       "      <td>9390.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[41071, 78552, 5856, V4581, 5789, 39891, 40390...</td>\n",
       "      <td>[9390.0, None, None, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40473</th>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>803168</td>\n",
       "      <td>712404</td>\n",
       "      <td>733456</td>\n",
       "      <td>733463</td>\n",
       "      <td>733456</td>\n",
       "      <td>733463</td>\n",
       "      <td>...</td>\n",
       "      <td>3324.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[1629, 1985, 2841, 7907, 1983, 53081, V4582, 2...</td>\n",
       "      <td>[3324.0, None, None, None, None]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40474 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  NoPhysician  NoOfDiag  NoOfProc  ORD_DOD  ORD_DOB  \\\n",
       "0       66            1         9         0   803168   709301   \n",
       "1       95            3         9         2   803168   698678   \n",
       "2       87            2         9         1   803168   701904   \n",
       "3       79            3         7         1   803168   704734   \n",
       "4       83            2         1         1   803168   702970   \n",
       "...    ...          ...       ...       ...      ...      ...   \n",
       "40469   57            3         9         1   803168   712648   \n",
       "40470   66            3         9         1   803168   709360   \n",
       "40471   70            1         9         0   803168   708174   \n",
       "40472   51            2         8         1   803168   714719   \n",
       "40473   57            2        10         1   803168   712404   \n",
       "\n",
       "       ORD_ClaimStartDt  ORD_ClaimEndDt  ORD_AdmissionDt  ORD_DischargeDt  \\\n",
       "0                733509          733515           733509           733515   \n",
       "1                733427          733439           733427           733439   \n",
       "2                733697          733715           733697           733715   \n",
       "3                733705          733709           733705           733709   \n",
       "4                733415          733419           733415           733419   \n",
       "...                 ...             ...              ...              ...   \n",
       "40469            733582          733589           733582           733589   \n",
       "40470            733656          733663           733656           733663   \n",
       "40471            733726          733734           733726           733734   \n",
       "40472            733430          733430           733430           733430   \n",
       "40473            733456          733463           733456           733463   \n",
       "\n",
       "       ...  ClmProcedureCode_1  ClmProcedureCode_2  ClmProcedureCode_3  \\\n",
       "0      ...                None                None                None   \n",
       "1      ...              7769.0              5849.0                None   \n",
       "2      ...              9338.0                None                None   \n",
       "3      ...              8154.0                None                None   \n",
       "4      ...              8543.0                None                None   \n",
       "...    ...                 ...                 ...                 ...   \n",
       "40469  ...              9955.0                None                None   \n",
       "40470  ...              3326.0                None                None   \n",
       "40471  ...                None                None                None   \n",
       "40472  ...              9390.0                None                None   \n",
       "40473  ...              3324.0                None                None   \n",
       "\n",
       "       ClmProcedureCode_4 ClmProcedureCode_5 AttendingPhysicianPresent  \\\n",
       "0                    None               None                         1   \n",
       "1                    None               None                         1   \n",
       "2                    None               None                         1   \n",
       "3                    None               None                         1   \n",
       "4                    None               None                         1   \n",
       "...                   ...                ...                       ...   \n",
       "40469                None               None                         1   \n",
       "40470                None               None                         1   \n",
       "40471                None               None                         1   \n",
       "40472                None               None                         1   \n",
       "40473                None               None                         1   \n",
       "\n",
       "      OtherPhysicianPresent OperatingPhysicianPresent  \\\n",
       "0                         0                         0   \n",
       "1                         1                         1   \n",
       "2                         0                         1   \n",
       "3                         1                         1   \n",
       "4                         0                         1   \n",
       "...                     ...                       ...   \n",
       "40469                     1                         1   \n",
       "40470                     1                         1   \n",
       "40471                     0                         0   \n",
       "40472                     0                         1   \n",
       "40473                     0                         1   \n",
       "\n",
       "                                           DiagnosisCode  \\\n",
       "0      [1970, 4019, 5853, 7843, 2768, 71590, 2724, 19...   \n",
       "1      [4240, 2639, 2948, 40390, 45821, 28489, 5854, ...   \n",
       "2      [V5789, 4168, 73313, 7812, 7993, 78830, 72273,...   \n",
       "3      [71535, 71960, 4019, V1202, 4240, 2449, 2768, ...   \n",
       "4      [2330, None, None, None, None, None, None, Non...   \n",
       "...                                                  ...   \n",
       "40469  [78079, 45341, V1251, 41401, 2449, 2930, 78830...   \n",
       "40470  [486, 7905, V5867, 5990, 2859, 7904, 49121, 41...   \n",
       "40471  [42821, E9342, 42731, 5856, 4280, 5859, 51881,...   \n",
       "40472  [41071, 78552, 5856, V4581, 5789, 39891, 40390...   \n",
       "40473  [1629, 1985, 2841, 7907, 1983, 53081, V4582, 2...   \n",
       "\n",
       "                            ProcedureCode  \n",
       "0          [None, None, None, None, None]  \n",
       "1      [7769.0, 5849.0, None, None, None]  \n",
       "2        [9338.0, None, None, None, None]  \n",
       "3        [8154.0, None, None, None, None]  \n",
       "4        [8543.0, None, None, None, None]  \n",
       "...                                   ...  \n",
       "40469    [9955.0, None, None, None, None]  \n",
       "40470    [3326.0, None, None, None, None]  \n",
       "40471      [None, None, None, None, None]  \n",
       "40472    [9390.0, None, None, None, None]  \n",
       "40473    [3324.0, None, None, None, None]  \n",
       "\n",
       "[40474 rows x 55 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xlab2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:22:58.026733Z",
     "start_time": "2020-07-01T06:22:57.879730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>NoPhysician</th>\n",
       "      <th>NoOfDiag</th>\n",
       "      <th>NoOfProc</th>\n",
       "      <th>ORD_DOD</th>\n",
       "      <th>ORD_DOB</th>\n",
       "      <th>ORD_ClaimStartDt</th>\n",
       "      <th>ORD_ClaimEndDt</th>\n",
       "      <th>ORD_AdmissionDt</th>\n",
       "      <th>ORD_DischargeDt</th>\n",
       "      <th>DaysAdmitted</th>\n",
       "      <th>IPAnnualReimbursementAmt</th>\n",
       "      <th>IPAnnualDeductibleAmt</th>\n",
       "      <th>InscClaimAmtReimbursed</th>\n",
       "      <th>NoOfMonths_PartACov</th>\n",
       "      <th>NoOfMonths_PartBCov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "      <td>40474.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>73.181598</td>\n",
       "      <td>1.701883</td>\n",
       "      <td>8.087365</td>\n",
       "      <td>0.733607</td>\n",
       "      <td>802621.757573</td>\n",
       "      <td>706684.599867</td>\n",
       "      <td>733577.740698</td>\n",
       "      <td>733583.400949</td>\n",
       "      <td>733577.734867</td>\n",
       "      <td>733583.400035</td>\n",
       "      <td>6.665168</td>\n",
       "      <td>17528.645056</td>\n",
       "      <td>1887.461234</td>\n",
       "      <td>10087.884074</td>\n",
       "      <td>11.915402</td>\n",
       "      <td>11.922642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.187784</td>\n",
       "      <td>0.618905</td>\n",
       "      <td>1.851830</td>\n",
       "      <td>0.761113</td>\n",
       "      <td>6138.365984</td>\n",
       "      <td>4812.387520</td>\n",
       "      <td>104.884925</td>\n",
       "      <td>104.658338</td>\n",
       "      <td>104.888036</td>\n",
       "      <td>104.659525</td>\n",
       "      <td>5.638538</td>\n",
       "      <td>17562.156402</td>\n",
       "      <td>1686.848629</td>\n",
       "      <td>10303.099402</td>\n",
       "      <td>0.987961</td>\n",
       "      <td>0.879923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>733439.000000</td>\n",
       "      <td>696883.000000</td>\n",
       "      <td>733373.000000</td>\n",
       "      <td>733408.000000</td>\n",
       "      <td>733373.000000</td>\n",
       "      <td>733408.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>803168.000000</td>\n",
       "      <td>703426.000000</td>\n",
       "      <td>733486.000000</td>\n",
       "      <td>733492.000000</td>\n",
       "      <td>733486.000000</td>\n",
       "      <td>733492.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>1068.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>803168.000000</td>\n",
       "      <td>706287.000000</td>\n",
       "      <td>733574.000000</td>\n",
       "      <td>733580.000000</td>\n",
       "      <td>733574.000000</td>\n",
       "      <td>733580.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>1068.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>803168.000000</td>\n",
       "      <td>708905.000000</td>\n",
       "      <td>733667.000000</td>\n",
       "      <td>733673.000000</td>\n",
       "      <td>733667.000000</td>\n",
       "      <td>733673.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>22000.000000</td>\n",
       "      <td>2136.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>803168.000000</td>\n",
       "      <td>724245.000000</td>\n",
       "      <td>733772.000000</td>\n",
       "      <td>733772.000000</td>\n",
       "      <td>733772.000000</td>\n",
       "      <td>733772.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>161470.000000</td>\n",
       "      <td>38272.000000</td>\n",
       "      <td>125000.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age   NoPhysician      NoOfDiag      NoOfProc        ORD_DOD  \\\n",
       "count  40474.000000  40474.000000  40474.000000  40474.000000   40474.000000   \n",
       "mean      73.181598      1.701883      8.087365      0.733607  802621.757573   \n",
       "std       13.187784      0.618905      1.851830      0.761113    6138.365984   \n",
       "min       25.000000      0.000000      1.000000      0.000000  733439.000000   \n",
       "25%       67.000000      1.000000      8.000000      0.000000  803168.000000   \n",
       "50%       74.000000      2.000000      9.000000      1.000000  803168.000000   \n",
       "75%       82.000000      2.000000      9.000000      1.000000  803168.000000   \n",
       "max      101.000000      3.000000     10.000000      5.000000  803168.000000   \n",
       "\n",
       "             ORD_DOB  ORD_ClaimStartDt  ORD_ClaimEndDt  ORD_AdmissionDt  \\\n",
       "count   40474.000000      40474.000000    40474.000000     40474.000000   \n",
       "mean   706684.599867     733577.740698   733583.400949    733577.734867   \n",
       "std      4812.387520        104.884925      104.658338       104.888036   \n",
       "min    696883.000000     733373.000000   733408.000000    733373.000000   \n",
       "25%    703426.000000     733486.000000   733492.000000    733486.000000   \n",
       "50%    706287.000000     733574.000000   733580.000000    733574.000000   \n",
       "75%    708905.000000     733667.000000   733673.000000    733667.000000   \n",
       "max    724245.000000     733772.000000   733772.000000    733772.000000   \n",
       "\n",
       "       ORD_DischargeDt  DaysAdmitted  IPAnnualReimbursementAmt  \\\n",
       "count     40474.000000  40474.000000              40474.000000   \n",
       "mean     733583.400035      6.665168              17528.645056   \n",
       "std         104.659525      5.638538              17562.156402   \n",
       "min      733408.000000      1.000000                  0.000000   \n",
       "25%      733492.000000      3.000000               6000.000000   \n",
       "50%      733580.000000      5.000000              12000.000000   \n",
       "75%      733673.000000      8.000000              22000.000000   \n",
       "max      733772.000000     36.000000             161470.000000   \n",
       "\n",
       "       IPAnnualDeductibleAmt  InscClaimAmtReimbursed  NoOfMonths_PartACov  \\\n",
       "count           40474.000000            40474.000000         40474.000000   \n",
       "mean             1887.461234            10087.884074            11.915402   \n",
       "std              1686.848629            10303.099402             0.987961   \n",
       "min                 0.000000                0.000000             0.000000   \n",
       "25%              1068.000000             4000.000000            12.000000   \n",
       "50%              1068.000000             7000.000000            12.000000   \n",
       "75%              2136.000000            12000.000000            12.000000   \n",
       "max             38272.000000           125000.000000            12.000000   \n",
       "\n",
       "       NoOfMonths_PartBCov  \n",
       "count         40474.000000  \n",
       "mean             11.922642  \n",
       "std               0.879923  \n",
       "min               0.000000  \n",
       "25%              12.000000  \n",
       "50%              12.000000  \n",
       "75%              12.000000  \n",
       "max              12.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xlab2_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Classification - Provider Fraud\n",
    "We will predict possible fraudulent claims and measure effectiveness using 10-fold cross validation and focus on attaining high metrics in F-1, recall and precision, in that order. Precision measures the percentage of fraudulent predictions which are truly fraudulent, and recall measures the total percentage of fraudulent claims correctly identified. These two metrics have been identified as most appropriate, due to our objective of correctly identifying fraudulent claims.  We want a high recall score, but not at the expense of precision (we can get 100% recall by classifying everyone as fraudulent).  F-1 should give us a good balance between the two, as they have an inverse relationship, where increasing one often decreases the other. \n",
    "\n",
    "## Task 2: Regression \n",
    "__TODO:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Matrix Conversion and Test/Train Split\n",
    "The minMax Scaler returns a dense numpy array.  Because we have so many features, we need to transform the data back into a sparse matrix for efficient . **CSC(Compressed Sparse Column)** is more efficient at accessing column-vectors or column operations, generally, as it is stored as arrays of columns and their value at each row.\n",
    "\n",
    "We chose to scale, convert to sparse and do test/train splits all before our pipeline in order to save processing time in the pipeline and grid search model execution steps.  The scaler takes a few minutes, and we don't want to introduce this lag to the repetitive pipeline.  This also gives us the advantage of using the exact same test/train splits for all models for a fair evaluation.  \n",
    "\n",
    "## Cross Validation Method\n",
    "\n",
    "We're using 10 fold cross validation because it will utilize it's own splits of the training data and help to ensures we don't overfit to the training data, in addition to witholding test data entirely from the models so we can more effectively evaluate generalization ability on a dataset that hasn't been seen by our models.  It has another benefit of using 10 different test/train splits of the training data, so if we happen by chance to get the best possible prediction outcome the first time we run it, we have 9 more chances to even out our prediction metrics using an average of the 10 runs.  This greatly increases our confidence that we are correctly reporting model performance metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:23:23.583989Z",
     "start_time": "2020-07-01T06:23:23.537526Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save a copy of the scaled regression dataframe & target\n",
    "reg_X1 = pd.DataFrame(X1, columns = ipdata.columns).drop(columns=['InscClaimAmtReimbursed'])\n",
    "scaled_reg_target = pd.DataFrame(X1, columns = ipdata.columns)['InscClaimAmtReimbursed']\n",
    "\n",
    "# Convert to Sparse\n",
    "X = csc_matrix(X1)\n",
    "reg_X = csc_matrix(reg_X1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import save_npz\n",
    "\n",
    "save_npz('X.csv',X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,target_df,test_size=0.2,random_state=86)\n",
    "\n",
    "reg_X_train,reg_X_test,reg_y_train,reg_y_test = train_test_split(reg_X,scaled_reg_target,test_size=0.2,random_state=86)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluations 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:48:18.365325Z",
     "start_time": "2020-07-01T06:48:18.361523Z"
    }
   },
   "source": [
    "### Classification Models \n",
    "#### Logistic regression\n",
    "* For logistic regression \n",
    "#### Random Forest\n",
    "\n",
    "#### Naive Bayes\n",
    "\n",
    "### Regression Models\n",
    "#### Multiple Linear Regression\n",
    "#### Random Forest\n",
    "#### kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a helper function designed to help test our models after hypertuning.  It takes a pipeline object and a parameter array and executes the grid search, as well as running a new cross validation and confusion matrix on the test data that we withheld from the training set.\n",
    "\n",
    "First it creates a cross validation object, with 10-fold cross validation and an 80/20 test split.  Next it fits our training data to the model(s) listed in the grid, then it executes each model once for each combination of parameters given in the parameter array.  After obtaining the results, it displays the metrics data we defined (ROC, Accuracy, Precision, Recall and F1), with the best model being chosen with the highest F1 score.  After displaying these results, it performs 10 fold cross validation on the test data (witheld from the training data) to see how well the model performs on new data outside of the training set.  We then create a confusion matrix which can highlight models that look good on paper (high scores), but are actually poor performers.  We see this in cases where recall gets really great scores, but the vast majority of claims get classified as fraudulent, which is not realistic.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testPerformance(pipeline, params):\n",
    "    \n",
    "    cv = ShuffleSplit(n_splits=10, test_size=.2, random_state=86)\n",
    "    \n",
    "    #Perform the grid search using accuracy as a metric during cross validation.\n",
    "    grid = GridSearchCV(pipeline, params, cv=cv, scoring=['roc_auc','accuracy','f1','recall','precision'], n_jobs=-1, refit='f1')\n",
    "    #Use the best features from recursive feature elimination during the grid search\n",
    "    start_time = timeit.default_timer()\n",
    "    grid.fit(X_train, y_train)\n",
    "    grid_time = timeit.default_timer() - start_time\n",
    "    #display the best pipeline model identified during the grid search\n",
    "    print(\"\\ngrid time: \", grid_time)\n",
    "\n",
    "    gridResults = pd.DataFrame.from_dict(grid.cv_results_)\n",
    "    \n",
    "    fileName = str(grid.best_estimator_[0]).split('(')[0]+'_CV_Results.xlsx'\n",
    "    gridResults.to_excel(fileName)\n",
    "    \n",
    "    \n",
    "    fewResults = pd.DataFrame(grid.cv_results_)[['params','mean_fit_time','mean_test_roc_auc',\"mean_test_accuracy\",\"mean_test_precision\",\"mean_test_recall\",\"mean_test_f1\"]].dropna()\n",
    "    display(fewResults.sort_values(by='mean_test_f1'))\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    clf = grid.best_estimator_[0]\n",
    "    # fit the model\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    fit_time = timeit.default_timer() - start_time\n",
    "\n",
    "    # do 10-fold cross validation:\n",
    "    f1scores = cross_val_score(clf, X_test, y_test, cv=cv, scoring='f1', n_jobs=-1)\n",
    "    PreScores = cross_val_score(clf, X_test, y_test, cv=cv, scoring='precision', n_jobs=-1)\n",
    "    RecScores = cross_val_score(clf, X_test, y_test, cv=cv, scoring='recall', n_jobs=-1)\n",
    "    print('\\n10-fold Cross Validation results:')\n",
    "    print('---------------------------------')\n",
    "    print('F1 scores:', f1scores)\n",
    "    print('\\nPrecision scores', PreScores)\n",
    "    print('\\nRecall scores', RecScores)\n",
    "\n",
    "    print('\\nAverage F1: ',np.average(f1scores))\n",
    "    print('Min F1: ',np.min(f1scores))\n",
    "    print('Max F1: ',np.max(f1scores))\n",
    "    print('\\nAverage Precision: ',np.average(PreScores))\n",
    "    print('Min Precision: ',np.min(PreScores))\n",
    "    print('Max Precision: ',np.max(PreScores))\n",
    "    print('\\nAverage Recall: ',np.average(RecScores))\n",
    "    print('Min Recall: ',np.min(RecScores))\n",
    "    print('Max Recall: ',np.max(RecScores))\n",
    "\n",
    "    cv_time = timeit.default_timer() - start_time - fit_time\n",
    "\n",
    "    # Build Confusion Matrix to test generality:\n",
    "    y_pred=clf.predict(X_test)\n",
    "    cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    class_names=[0,1] # name  of classes\n",
    "    fig, ax = plt.subplots()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    # create heatmap\n",
    "    sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    plt.tight_layout()\n",
    "    plt.title('Potential Fraud Confusion matrix', y=1.1)\n",
    "    plt.ylabel('Actual Fraud')\n",
    "    plt.xlabel('Predicted Fraud')\n",
    "    plt.show\n",
    "    print('\\nSingle Run results:')\n",
    "    print('---------------------------------')\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "    print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "    print(\"F1:\",metrics.f1_score(y_test, y_pred))\n",
    "    \n",
    "    print(\"\\nFit time: \", fit_time)\n",
    "    print(\"CV time: \", cv_time)\n",
    "    print(\"Total time: \", timeit.default_timer() - start_time)\n",
    "    return(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up pipe for logistic regression hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "grid time:  419.77436868601944\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'logisticregression__C': 0.001, 'logisticregr...</td>\n",
       "      <td>0.112866</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.424583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>{'logisticregression__C': 1000, 'logisticregre...</td>\n",
       "      <td>58.634833</td>\n",
       "      <td>0.573268</td>\n",
       "      <td>0.565426</td>\n",
       "      <td>0.631108</td>\n",
       "      <td>0.589354</td>\n",
       "      <td>0.609447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>83.907564</td>\n",
       "      <td>0.577911</td>\n",
       "      <td>0.567495</td>\n",
       "      <td>0.632985</td>\n",
       "      <td>0.591313</td>\n",
       "      <td>0.611369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>{'logisticregression__C': 1000, 'logisticregre...</td>\n",
       "      <td>92.786063</td>\n",
       "      <td>0.576350</td>\n",
       "      <td>0.566955</td>\n",
       "      <td>0.631214</td>\n",
       "      <td>0.595389</td>\n",
       "      <td>0.612700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>{'logisticregression__C': 1000, 'logisticregre...</td>\n",
       "      <td>30.908189</td>\n",
       "      <td>0.582514</td>\n",
       "      <td>0.569503</td>\n",
       "      <td>0.633964</td>\n",
       "      <td>0.596200</td>\n",
       "      <td>0.614430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>{'logisticregression__C': 1000, 'logisticregre...</td>\n",
       "      <td>11.371463</td>\n",
       "      <td>0.581221</td>\n",
       "      <td>0.568993</td>\n",
       "      <td>0.633015</td>\n",
       "      <td>0.597416</td>\n",
       "      <td>0.614635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>37.429099</td>\n",
       "      <td>0.583644</td>\n",
       "      <td>0.569951</td>\n",
       "      <td>0.634519</td>\n",
       "      <td>0.596094</td>\n",
       "      <td>0.614635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>31.346915</td>\n",
       "      <td>0.585191</td>\n",
       "      <td>0.570337</td>\n",
       "      <td>0.634932</td>\n",
       "      <td>0.596253</td>\n",
       "      <td>0.614912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>9.562209</td>\n",
       "      <td>0.585913</td>\n",
       "      <td>0.571387</td>\n",
       "      <td>0.635803</td>\n",
       "      <td>0.597452</td>\n",
       "      <td>0.615964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>36.737785</td>\n",
       "      <td>0.592474</td>\n",
       "      <td>0.574506</td>\n",
       "      <td>0.639731</td>\n",
       "      <td>0.596743</td>\n",
       "      <td>0.617410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>8.845455</td>\n",
       "      <td>0.598386</td>\n",
       "      <td>0.576915</td>\n",
       "      <td>0.641382</td>\n",
       "      <td>0.600683</td>\n",
       "      <td>0.620307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>22.184853</td>\n",
       "      <td>0.598365</td>\n",
       "      <td>0.577116</td>\n",
       "      <td>0.641579</td>\n",
       "      <td>0.600787</td>\n",
       "      <td>0.620461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>14.168690</td>\n",
       "      <td>0.598340</td>\n",
       "      <td>0.577085</td>\n",
       "      <td>0.641525</td>\n",
       "      <td>0.600841</td>\n",
       "      <td>0.620465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>6.021952</td>\n",
       "      <td>0.621756</td>\n",
       "      <td>0.590117</td>\n",
       "      <td>0.654660</td>\n",
       "      <td>0.609151</td>\n",
       "      <td>0.631012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>6.036913</td>\n",
       "      <td>0.621758</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.654702</td>\n",
       "      <td>0.609204</td>\n",
       "      <td>0.631058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>5.699237</td>\n",
       "      <td>0.621761</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.654703</td>\n",
       "      <td>0.609206</td>\n",
       "      <td>0.631059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>2.599597</td>\n",
       "      <td>0.656964</td>\n",
       "      <td>0.608477</td>\n",
       "      <td>0.684450</td>\n",
       "      <td>0.592899</td>\n",
       "      <td>0.635357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'logisticregression__C': 0.001, 'logisticregr...</td>\n",
       "      <td>0.457919</td>\n",
       "      <td>0.617798</td>\n",
       "      <td>0.591028</td>\n",
       "      <td>0.652023</td>\n",
       "      <td>0.620260</td>\n",
       "      <td>0.635697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'logisticregression__C': 0.001, 'logisticregr...</td>\n",
       "      <td>1.209740</td>\n",
       "      <td>0.617692</td>\n",
       "      <td>0.591137</td>\n",
       "      <td>0.652044</td>\n",
       "      <td>0.620578</td>\n",
       "      <td>0.635874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'logisticregression__C': 0.001, 'logisticregr...</td>\n",
       "      <td>0.314251</td>\n",
       "      <td>0.617687</td>\n",
       "      <td>0.591152</td>\n",
       "      <td>0.652053</td>\n",
       "      <td>0.620604</td>\n",
       "      <td>0.635893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>23.355930</td>\n",
       "      <td>0.632347</td>\n",
       "      <td>0.597344</td>\n",
       "      <td>0.662772</td>\n",
       "      <td>0.611484</td>\n",
       "      <td>0.636020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.555966</td>\n",
       "      <td>0.642379</td>\n",
       "      <td>0.602641</td>\n",
       "      <td>0.672002</td>\n",
       "      <td>0.604521</td>\n",
       "      <td>0.636420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>5.721984</td>\n",
       "      <td>0.642377</td>\n",
       "      <td>0.602671</td>\n",
       "      <td>0.672020</td>\n",
       "      <td>0.604575</td>\n",
       "      <td>0.636458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.681763</td>\n",
       "      <td>0.642395</td>\n",
       "      <td>0.602594</td>\n",
       "      <td>0.671864</td>\n",
       "      <td>0.604706</td>\n",
       "      <td>0.636463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>1.738241</td>\n",
       "      <td>0.643798</td>\n",
       "      <td>0.603999</td>\n",
       "      <td>0.670191</td>\n",
       "      <td>0.614113</td>\n",
       "      <td>0.640867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>1.957609</td>\n",
       "      <td>0.643782</td>\n",
       "      <td>0.604046</td>\n",
       "      <td>0.670243</td>\n",
       "      <td>0.614140</td>\n",
       "      <td>0.640904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>21.115176</td>\n",
       "      <td>0.643787</td>\n",
       "      <td>0.604092</td>\n",
       "      <td>0.670272</td>\n",
       "      <td>0.614220</td>\n",
       "      <td>0.640961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>{'logisticregression__C': 1000, 'logisticregre...</td>\n",
       "      <td>6.789589</td>\n",
       "      <td>0.582411</td>\n",
       "      <td>0.576405</td>\n",
       "      <td>0.624256</td>\n",
       "      <td>0.663083</td>\n",
       "      <td>0.643000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>{'logisticregression__C': 1000, 'logisticregre...</td>\n",
       "      <td>29.735272</td>\n",
       "      <td>0.582814</td>\n",
       "      <td>0.576992</td>\n",
       "      <td>0.624646</td>\n",
       "      <td>0.663930</td>\n",
       "      <td>0.643608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>28.449233</td>\n",
       "      <td>0.585477</td>\n",
       "      <td>0.578505</td>\n",
       "      <td>0.625696</td>\n",
       "      <td>0.666020</td>\n",
       "      <td>0.645151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>5.974370</td>\n",
       "      <td>0.586384</td>\n",
       "      <td>0.578567</td>\n",
       "      <td>0.625634</td>\n",
       "      <td>0.666527</td>\n",
       "      <td>0.645356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>18.560797</td>\n",
       "      <td>0.598645</td>\n",
       "      <td>0.585361</td>\n",
       "      <td>0.629317</td>\n",
       "      <td>0.680199</td>\n",
       "      <td>0.653683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>5.978709</td>\n",
       "      <td>0.598779</td>\n",
       "      <td>0.585330</td>\n",
       "      <td>0.629211</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>0.653765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.176550</td>\n",
       "      <td>0.557380</td>\n",
       "      <td>0.568823</td>\n",
       "      <td>0.598591</td>\n",
       "      <td>0.761927</td>\n",
       "      <td>0.668570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>3.572941</td>\n",
       "      <td>0.622031</td>\n",
       "      <td>0.603552</td>\n",
       "      <td>0.637786</td>\n",
       "      <td>0.720130</td>\n",
       "      <td>0.676391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>6.927003</td>\n",
       "      <td>0.622028</td>\n",
       "      <td>0.603629</td>\n",
       "      <td>0.637862</td>\n",
       "      <td>0.720130</td>\n",
       "      <td>0.676434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>1.783875</td>\n",
       "      <td>0.643950</td>\n",
       "      <td>0.619966</td>\n",
       "      <td>0.638924</td>\n",
       "      <td>0.781214</td>\n",
       "      <td>0.702848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>5.994278</td>\n",
       "      <td>0.643958</td>\n",
       "      <td>0.620074</td>\n",
       "      <td>0.639004</td>\n",
       "      <td>0.781294</td>\n",
       "      <td>0.702929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.661570</td>\n",
       "      <td>0.642246</td>\n",
       "      <td>0.608910</td>\n",
       "      <td>0.609865</td>\n",
       "      <td>0.889470</td>\n",
       "      <td>0.723524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>6.910107</td>\n",
       "      <td>0.642249</td>\n",
       "      <td>0.608925</td>\n",
       "      <td>0.609872</td>\n",
       "      <td>0.889496</td>\n",
       "      <td>0.723538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'logisticregression__C': 0.001, 'logisticregr...</td>\n",
       "      <td>0.249338</td>\n",
       "      <td>0.617375</td>\n",
       "      <td>0.576050</td>\n",
       "      <td>0.575877</td>\n",
       "      <td>0.998987</td>\n",
       "      <td>0.730562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'logisticregression__C': 0.001, 'logisticregr...</td>\n",
       "      <td>2.460682</td>\n",
       "      <td>0.617380</td>\n",
       "      <td>0.576050</td>\n",
       "      <td>0.575877</td>\n",
       "      <td>0.998987</td>\n",
       "      <td>0.730562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                params  mean_fit_time  \\\n",
       "1    {'logisticregression__C': 0.001, 'logisticregr...       0.112866   \n",
       "145  {'logisticregression__C': 1000, 'logisticregre...      58.634833   \n",
       "121  {'logisticregression__C': 100, 'logisticregres...      83.907564   \n",
       "148  {'logisticregression__C': 1000, 'logisticregre...      92.786063   \n",
       "147  {'logisticregression__C': 1000, 'logisticregre...      30.908189   \n",
       "149  {'logisticregression__C': 1000, 'logisticregre...      11.371463   \n",
       "124  {'logisticregression__C': 100, 'logisticregres...      37.429099   \n",
       "123  {'logisticregression__C': 100, 'logisticregres...      31.346915   \n",
       "125  {'logisticregression__C': 100, 'logisticregres...       9.562209   \n",
       "97   {'logisticregression__C': 10, 'logisticregress...      36.737785   \n",
       "101  {'logisticregression__C': 10, 'logisticregress...       8.845455   \n",
       "99   {'logisticregression__C': 10, 'logisticregress...      22.184853   \n",
       "100  {'logisticregression__C': 10, 'logisticregress...      14.168690   \n",
       "77   {'logisticregression__C': 1, 'logisticregressi...       6.021952   \n",
       "76   {'logisticregression__C': 1, 'logisticregressi...       6.036913   \n",
       "75   {'logisticregression__C': 1, 'logisticregressi...       5.699237   \n",
       "49   {'logisticregression__C': 0.1, 'logisticregres...       2.599597   \n",
       "4    {'logisticregression__C': 0.001, 'logisticregr...       0.457919   \n",
       "3    {'logisticregression__C': 0.001, 'logisticregr...       1.209740   \n",
       "5    {'logisticregression__C': 0.001, 'logisticregr...       0.314251   \n",
       "73   {'logisticregression__C': 1, 'logisticregressi...      23.355930   \n",
       "29   {'logisticregression__C': 0.01, 'logisticregre...       0.555966   \n",
       "27   {'logisticregression__C': 0.01, 'logisticregre...       5.721984   \n",
       "28   {'logisticregression__C': 0.01, 'logisticregre...       0.681763   \n",
       "52   {'logisticregression__C': 0.1, 'logisticregres...       1.738241   \n",
       "53   {'logisticregression__C': 0.1, 'logisticregres...       1.957609   \n",
       "51   {'logisticregression__C': 0.1, 'logisticregres...      21.115176   \n",
       "161  {'logisticregression__C': 1000, 'logisticregre...       6.789589   \n",
       "159  {'logisticregression__C': 1000, 'logisticregre...      29.735272   \n",
       "135  {'logisticregression__C': 100, 'logisticregres...      28.449233   \n",
       "137  {'logisticregression__C': 100, 'logisticregres...       5.974370   \n",
       "111  {'logisticregression__C': 10, 'logisticregress...      18.560797   \n",
       "113  {'logisticregression__C': 10, 'logisticregress...       5.978709   \n",
       "25   {'logisticregression__C': 0.01, 'logisticregre...       0.176550   \n",
       "87   {'logisticregression__C': 1, 'logisticregressi...       3.572941   \n",
       "89   {'logisticregression__C': 1, 'logisticregressi...       6.927003   \n",
       "65   {'logisticregression__C': 0.1, 'logisticregres...       1.783875   \n",
       "63   {'logisticregression__C': 0.1, 'logisticregres...       5.994278   \n",
       "41   {'logisticregression__C': 0.01, 'logisticregre...       0.661570   \n",
       "39   {'logisticregression__C': 0.01, 'logisticregre...       6.910107   \n",
       "17   {'logisticregression__C': 0.001, 'logisticregr...       0.249338   \n",
       "15   {'logisticregression__C': 0.001, 'logisticregr...       2.460682   \n",
       "\n",
       "     mean_test_roc_auc  mean_test_accuracy  mean_test_precision  \\\n",
       "1             0.500000            0.424583             0.000000   \n",
       "145           0.573268            0.565426             0.631108   \n",
       "121           0.577911            0.567495             0.632985   \n",
       "148           0.576350            0.566955             0.631214   \n",
       "147           0.582514            0.569503             0.633964   \n",
       "149           0.581221            0.568993             0.633015   \n",
       "124           0.583644            0.569951             0.634519   \n",
       "123           0.585191            0.570337             0.634932   \n",
       "125           0.585913            0.571387             0.635803   \n",
       "97            0.592474            0.574506             0.639731   \n",
       "101           0.598386            0.576915             0.641382   \n",
       "99            0.598365            0.577116             0.641579   \n",
       "100           0.598340            0.577085             0.641525   \n",
       "77            0.621756            0.590117             0.654660   \n",
       "76            0.621758            0.590164             0.654702   \n",
       "75            0.621761            0.590164             0.654703   \n",
       "49            0.656964            0.608477             0.684450   \n",
       "4             0.617798            0.591028             0.652023   \n",
       "3             0.617692            0.591137             0.652044   \n",
       "5             0.617687            0.591152             0.652053   \n",
       "73            0.632347            0.597344             0.662772   \n",
       "29            0.642379            0.602641             0.672002   \n",
       "27            0.642377            0.602671             0.672020   \n",
       "28            0.642395            0.602594             0.671864   \n",
       "52            0.643798            0.603999             0.670191   \n",
       "53            0.643782            0.604046             0.670243   \n",
       "51            0.643787            0.604092             0.670272   \n",
       "161           0.582411            0.576405             0.624256   \n",
       "159           0.582814            0.576992             0.624646   \n",
       "135           0.585477            0.578505             0.625696   \n",
       "137           0.586384            0.578567             0.625634   \n",
       "111           0.598645            0.585361             0.629317   \n",
       "113           0.598779            0.585330             0.629211   \n",
       "25            0.557380            0.568823             0.598591   \n",
       "87            0.622031            0.603552             0.637786   \n",
       "89            0.622028            0.603629             0.637862   \n",
       "65            0.643950            0.619966             0.638924   \n",
       "63            0.643958            0.620074             0.639004   \n",
       "41            0.642246            0.608910             0.609865   \n",
       "39            0.642249            0.608925             0.609872   \n",
       "17            0.617375            0.576050             0.575877   \n",
       "15            0.617380            0.576050             0.575877   \n",
       "\n",
       "     mean_test_recall  mean_test_f1  \n",
       "1            0.000000      0.000000  \n",
       "145          0.589354      0.609447  \n",
       "121          0.591313      0.611369  \n",
       "148          0.595389      0.612700  \n",
       "147          0.596200      0.614430  \n",
       "149          0.597416      0.614635  \n",
       "124          0.596094      0.614635  \n",
       "123          0.596253      0.614912  \n",
       "125          0.597452      0.615964  \n",
       "97           0.596743      0.617410  \n",
       "101          0.600683      0.620307  \n",
       "99           0.600787      0.620461  \n",
       "100          0.600841      0.620465  \n",
       "77           0.609151      0.631012  \n",
       "76           0.609204      0.631058  \n",
       "75           0.609206      0.631059  \n",
       "49           0.592899      0.635357  \n",
       "4            0.620260      0.635697  \n",
       "3            0.620578      0.635874  \n",
       "5            0.620604      0.635893  \n",
       "73           0.611484      0.636020  \n",
       "29           0.604521      0.636420  \n",
       "27           0.604575      0.636458  \n",
       "28           0.604706      0.636463  \n",
       "52           0.614113      0.640867  \n",
       "53           0.614140      0.640904  \n",
       "51           0.614220      0.640961  \n",
       "161          0.663083      0.643000  \n",
       "159          0.663930      0.643608  \n",
       "135          0.666020      0.645151  \n",
       "137          0.666527      0.645356  \n",
       "111          0.680199      0.653683  \n",
       "113          0.680488      0.653765  \n",
       "25           0.761927      0.668570  \n",
       "87           0.720130      0.676391  \n",
       "89           0.720130      0.676434  \n",
       "65           0.781214      0.702848  \n",
       "63           0.781294      0.702929  \n",
       "41           0.889470      0.723524  \n",
       "39           0.889496      0.723538  \n",
       "17           0.998987      0.730562  \n",
       "15           0.998987      0.730562  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10-fold Cross Validation results:\n",
      "---------------------------------\n",
      "F1 scores: [0.72268245 0.72870043 0.72569854 0.73416732 0.7216739  0.71660721\n",
      " 0.72670075 0.73565014 0.70944599 0.7454475 ]\n",
      "\n",
      "Precision scores [0.56578135 0.57319333 0.56948734 0.57998765 0.56454602 0.55836936\n",
      " 0.57072267 0.58184064 0.54972205 0.59419395]\n",
      "\n",
      "Recall scores [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "Average F1:  0.7266774237036513\n",
      "Min F1:  0.7094459944200877\n",
      "Max F1:  0.7454475009686168\n",
      "\n",
      "Average Precision:  0.5707844348363187\n",
      "Min Precision:  0.5497220506485485\n",
      "Max Precision:  0.5941939468807906\n",
      "\n",
      "Average Recall:  1.0\n",
      "Min Recall:  1.0\n",
      "Max Recall:  1.0\n",
      "\n",
      "Single Run results:\n",
      "---------------------------------\n",
      "Accuracy: 0.574922791846819\n",
      "Precision: 0.5746166313427253\n",
      "Recall: 0.99374730487279\n",
      "F1: 0.7281775811675488\n",
      "\n",
      "Fit time:  0.9061228799982928\n",
      "CV time:  1.5183906280435622\n",
      "Total time:  2.5528147339937277\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Dustin's Pipe/Grid:  Currently takes about 30s.  Testing params\"\"\"\n",
    "\n",
    "LogPipe = make_pipeline(LogisticRegression())\n",
    "\n",
    "LogParams = {'logisticregression__penalty':['l1','l2','None','elastic-net']\n",
    "              ,'logisticregression__C': [.001, .01, .1, 1, 10, 100, 1000]\n",
    "              ,'logisticregression__class_weight': ['balanced','None']\n",
    "              ,'logisticregression__random_state': [86]\n",
    "              ,'logisticregression__solver': ['sag','liblinear','lbfgs']\n",
    "              ,'logisticregression__max_iter':[500]\n",
    "              ,'logisticregression__n_jobs':[-1]\n",
    "             }\n",
    "\n",
    "LogGrid = testPerformance(LogPipe, LogParams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy', 'adjusted_mutual_info_score', 'adjusted_rand_score', 'average_precision', 'balanced_accuracy', 'completeness_score', 'explained_variance', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'fowlkes_mallows_score', 'homogeneity_score', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted', 'max_error', 'mutual_info_score', 'neg_brier_score', 'neg_log_loss', 'neg_mean_absolute_error', 'neg_mean_gamma_deviance', 'neg_mean_poisson_deviance', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_median_absolute_error', 'neg_root_mean_squared_error', 'normalized_mutual_info_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'r2', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'roc_auc', 'roc_auc_ovo', 'roc_auc_ovo_weighted', 'roc_auc_ovr', 'roc_auc_ovr_weighted', 'v_measure_score']\n"
     ]
    }
   ],
   "source": [
    "# view available metrics:\n",
    "print(sorted(metrics.SCORERS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure model & results come back as expected\n",
    "print(LogGrid.best_estimator_)\n",
    "display(LogGrid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our best tuning from the grid search, let's test performance of logistic regression on a new dataset to test generalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>OtherPhysicianPresent</td>\n",
       "      <td>[-0.19267174238171256]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6100</th>\n",
       "      <td>State_39</td>\n",
       "      <td>[-0.11622124066356589]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6089</th>\n",
       "      <td>State_28</td>\n",
       "      <td>[-0.0866071282906229]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6072</th>\n",
       "      <td>State_11</td>\n",
       "      <td>[-0.08212221985902712]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>State_1</td>\n",
       "      <td>[-0.08170743659812331]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>State_49</td>\n",
       "      <td>[0.08241429051644562]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6068</th>\n",
       "      <td>State_7</td>\n",
       "      <td>[0.08484900940272519]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6094</th>\n",
       "      <td>State_33</td>\n",
       "      <td>[0.10470001917179776]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6141</th>\n",
       "      <td>County_160</td>\n",
       "      <td>[0.111454329173663]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6097</th>\n",
       "      <td>State_36</td>\n",
       "      <td>[0.1430207898553494]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9077 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Feature                  Weight\n",
       "17    OtherPhysicianPresent  [-0.19267174238171256]\n",
       "6100               State_39  [-0.11622124066356589]\n",
       "6089               State_28   [-0.0866071282906229]\n",
       "6072               State_11  [-0.08212221985902712]\n",
       "6062                State_1  [-0.08170743659812331]\n",
       "...                     ...                     ...\n",
       "6108               State_49   [0.08241429051644562]\n",
       "6068                State_7   [0.08484900940272519]\n",
       "6094               State_33   [0.10470001917179776]\n",
       "6141             County_160     [0.111454329173663]\n",
       "6097               State_36    [0.1430207898553494]\n",
       "\n",
       "[9077 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize feature importance\n",
    "zip_vars = zip(ipdata.columns,LogGrid.best_estimator_[0].coef_.T) # combine attributes\n",
    "FeatureWeights = pd.DataFrame(list(zip_vars), columns=['Feature', 'Weight'])\n",
    "\n",
    "FeatureWeights.sort_values(by='Weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "#pipe = Pipeline([('classifier' , RandomForestClassifier())])\n",
    "pipe = Pipeline([('classifier' , LogisticRegression())])\n",
    "scoring = {'AUC': 'roc_auc', 'Recall': make_scorer(accuracy_score),'Precision': make_scorer(accuracy_score)}\n",
    "scores = ['precision', 'recall']\n",
    "param_grid = [\n",
    "    {'classifier' : [LogisticRegression()],\n",
    "     'classifier__penalty' : ['l1', 'l2'],\n",
    "    #'classifier__C' : np.logspace(-4, 4, 20),\n",
    "    'classifier__C' : np.logspace(-4, 4),\n",
    "    'classifier__solver' : ['liblinear']},\n",
    "     {'classifier' : [RandomForestClassifier()],\n",
    "    'classifier__n_estimators' : list(range(10,101,10)),\n",
    "     'classifier__n_estimators' : list(range(10,101)),\n",
    "    #'classifier__max_features' : list(range(6,32,5))}\n",
    "     'classifier__max_features' : list(range(6,32))}\n",
    "]\n",
    "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 3, verbose=True, n_jobs=-1,scoring=scoring,refit='AUC')\n",
    "\n",
    "best_clf = clf.fit(X_train, y_train)\n",
    "\n",
    "#best_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "grid time:  140.70304446603404\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'randomforestclassifier__max_depth': 5, 'rand...</td>\n",
       "      <td>1.765320</td>\n",
       "      <td>0.641991</td>\n",
       "      <td>0.575417</td>\n",
       "      <td>0.575417</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'randomforestclassifier__max_depth': 5, 'rand...</td>\n",
       "      <td>3.441620</td>\n",
       "      <td>0.649502</td>\n",
       "      <td>0.575417</td>\n",
       "      <td>0.575417</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'randomforestclassifier__max_depth': 5, 'rand...</td>\n",
       "      <td>8.597043</td>\n",
       "      <td>0.655021</td>\n",
       "      <td>0.575417</td>\n",
       "      <td>0.575417</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'randomforestclassifier__max_depth': 10, 'ran...</td>\n",
       "      <td>5.673204</td>\n",
       "      <td>0.661141</td>\n",
       "      <td>0.575417</td>\n",
       "      <td>0.575417</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'randomforestclassifier__max_depth': 10, 'ran...</td>\n",
       "      <td>13.926310</td>\n",
       "      <td>0.664981</td>\n",
       "      <td>0.575417</td>\n",
       "      <td>0.575417</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'randomforestclassifier__max_depth': 10, 'ran...</td>\n",
       "      <td>3.348129</td>\n",
       "      <td>0.653884</td>\n",
       "      <td>0.575448</td>\n",
       "      <td>0.575435</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'randomforestclassifier__max_depth': 15, 'ran...</td>\n",
       "      <td>19.765389</td>\n",
       "      <td>0.672251</td>\n",
       "      <td>0.576143</td>\n",
       "      <td>0.575846</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.730781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'randomforestclassifier__max_depth': 15, 'ran...</td>\n",
       "      <td>7.590671</td>\n",
       "      <td>0.668713</td>\n",
       "      <td>0.576467</td>\n",
       "      <td>0.576043</td>\n",
       "      <td>0.999757</td>\n",
       "      <td>0.730905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'randomforestclassifier__max_depth': 15, 'ran...</td>\n",
       "      <td>4.780892</td>\n",
       "      <td>0.662997</td>\n",
       "      <td>0.577085</td>\n",
       "      <td>0.576429</td>\n",
       "      <td>0.999435</td>\n",
       "      <td>0.731129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'randomforestclassifier__max_depth': 20, 'ran...</td>\n",
       "      <td>28.481627</td>\n",
       "      <td>0.678854</td>\n",
       "      <td>0.579447</td>\n",
       "      <td>0.577924</td>\n",
       "      <td>0.998102</td>\n",
       "      <td>0.731968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'randomforestclassifier__max_depth': 20, 'ran...</td>\n",
       "      <td>9.832014</td>\n",
       "      <td>0.674461</td>\n",
       "      <td>0.580019</td>\n",
       "      <td>0.578339</td>\n",
       "      <td>0.997213</td>\n",
       "      <td>0.732061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'randomforestclassifier__max_depth': 20, 'ran...</td>\n",
       "      <td>7.159049</td>\n",
       "      <td>0.667749</td>\n",
       "      <td>0.581007</td>\n",
       "      <td>0.579043</td>\n",
       "      <td>0.995822</td>\n",
       "      <td>0.732249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'randomforestclassifier__max_depth': 30, 'ran...</td>\n",
       "      <td>10.286332</td>\n",
       "      <td>0.676758</td>\n",
       "      <td>0.592264</td>\n",
       "      <td>0.586867</td>\n",
       "      <td>0.984763</td>\n",
       "      <td>0.735394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'randomforestclassifier__max_depth': 30, 'ran...</td>\n",
       "      <td>34.757668</td>\n",
       "      <td>0.687294</td>\n",
       "      <td>0.591584</td>\n",
       "      <td>0.586093</td>\n",
       "      <td>0.988154</td>\n",
       "      <td>0.735736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'randomforestclassifier__max_depth': 30, 'ran...</td>\n",
       "      <td>17.254301</td>\n",
       "      <td>0.683975</td>\n",
       "      <td>0.592295</td>\n",
       "      <td>0.586682</td>\n",
       "      <td>0.986632</td>\n",
       "      <td>0.735775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  mean_fit_time  \\\n",
       "0   {'randomforestclassifier__max_depth': 5, 'rand...       1.765320   \n",
       "1   {'randomforestclassifier__max_depth': 5, 'rand...       3.441620   \n",
       "2   {'randomforestclassifier__max_depth': 5, 'rand...       8.597043   \n",
       "4   {'randomforestclassifier__max_depth': 10, 'ran...       5.673204   \n",
       "5   {'randomforestclassifier__max_depth': 10, 'ran...      13.926310   \n",
       "3   {'randomforestclassifier__max_depth': 10, 'ran...       3.348129   \n",
       "8   {'randomforestclassifier__max_depth': 15, 'ran...      19.765389   \n",
       "7   {'randomforestclassifier__max_depth': 15, 'ran...       7.590671   \n",
       "6   {'randomforestclassifier__max_depth': 15, 'ran...       4.780892   \n",
       "11  {'randomforestclassifier__max_depth': 20, 'ran...      28.481627   \n",
       "10  {'randomforestclassifier__max_depth': 20, 'ran...       9.832014   \n",
       "9   {'randomforestclassifier__max_depth': 20, 'ran...       7.159049   \n",
       "12  {'randomforestclassifier__max_depth': 30, 'ran...      10.286332   \n",
       "14  {'randomforestclassifier__max_depth': 30, 'ran...      34.757668   \n",
       "13  {'randomforestclassifier__max_depth': 30, 'ran...      17.254301   \n",
       "\n",
       "    mean_test_roc_auc  mean_test_accuracy  mean_test_precision  \\\n",
       "0            0.641991            0.575417             0.575417   \n",
       "1            0.649502            0.575417             0.575417   \n",
       "2            0.655021            0.575417             0.575417   \n",
       "4            0.661141            0.575417             0.575417   \n",
       "5            0.664981            0.575417             0.575417   \n",
       "3            0.653884            0.575448             0.575435   \n",
       "8            0.672251            0.576143             0.575846   \n",
       "7            0.668713            0.576467             0.576043   \n",
       "6            0.662997            0.577085             0.576429   \n",
       "11           0.678854            0.579447             0.577924   \n",
       "10           0.674461            0.580019             0.578339   \n",
       "9            0.667749            0.581007             0.579043   \n",
       "12           0.676758            0.592264             0.586867   \n",
       "14           0.687294            0.591584             0.586093   \n",
       "13           0.683975            0.592295             0.586682   \n",
       "\n",
       "    mean_test_recall  mean_test_f1  \n",
       "0           1.000000      0.730466  \n",
       "1           1.000000      0.730466  \n",
       "2           1.000000      0.730466  \n",
       "4           1.000000      0.730466  \n",
       "5           1.000000      0.730466  \n",
       "3           1.000000      0.730480  \n",
       "8           0.999892      0.730781  \n",
       "7           0.999757      0.730905  \n",
       "6           0.999435      0.731129  \n",
       "11          0.998102      0.731968  \n",
       "10          0.997213      0.732061  \n",
       "9           0.995822      0.732249  \n",
       "12          0.984763      0.735394  \n",
       "14          0.988154      0.735736  \n",
       "13          0.986632      0.735775  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10-fold Cross Validation results:\n",
      "---------------------------------\n",
      "F1 scores: [0.72559261 0.7285086  0.72990354 0.73612774 0.72064128 0.7184857\n",
      " 0.73075389 0.74088748 0.71225071 0.74990028]\n",
      "\n",
      "Precision scores [0.5740623  0.57914812 0.5798212  0.58876117 0.56862745 0.5649145\n",
      " 0.57864814 0.59102402 0.55839183 0.60841424]\n",
      "\n",
      "Recall scores [0.98580786 0.98168103 0.98481562 0.98189563 0.98358862 0.98672566\n",
      " 0.99134199 0.992569   0.98314607 0.97713098]\n",
      "\n",
      "Average F1:  0.729305183163632\n",
      "Min F1:  0.7122507122507122\n",
      "Max F1:  0.7499002792181891\n",
      "\n",
      "Average Precision:  0.579181298293167\n",
      "Min Precision:  0.5583918315252074\n",
      "Max Precision:  0.6084142394822006\n",
      "\n",
      "Average Recall:  0.9848702469791704\n",
      "Min Recall:  0.9771309771309772\n",
      "Max Recall:  0.9925690021231423\n",
      "\n",
      "Single Run results:\n",
      "---------------------------------\n",
      "Accuracy: 0.5913526868437307\n",
      "Precision: 0.5846702317290553\n",
      "Recall: 0.9900819318671842\n",
      "F1: 0.7351905219340379\n",
      "\n",
      "Fit time:  1.9043550619971938\n",
      "CV time:  9.889451301947702\n",
      "Total time:  11.972912582976278\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#random Forest Classification 10-fold cross-validation\n",
    "\n",
    "RfPipe = make_pipeline(RandomForestClassifier())\n",
    "RfParams = [\n",
    "    {\n",
    "         'randomforestclassifier__n_estimators': [100, 200, 500],\n",
    "         'randomforestclassifier__max_depth': [5,10,15,20,30],\n",
    "         'randomforestclassifier__random_state':[101],\n",
    "         'randomforestclassifier__n_jobs':[-1]\n",
    "     }\n",
    "]\n",
    "\n",
    "RfGrid = testPerformance(RfPipe, RfParams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dustin/anaconda3/envs/DS7331/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "grid time:  1902.4362271429854\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.043084</td>\n",
       "      <td>0.530786</td>\n",
       "      <td>0.540380</td>\n",
       "      <td>0.592964</td>\n",
       "      <td>0.641634</td>\n",
       "      <td>0.616248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 30, 'kneig...</td>\n",
       "      <td>0.055543</td>\n",
       "      <td>0.530786</td>\n",
       "      <td>0.540380</td>\n",
       "      <td>0.592964</td>\n",
       "      <td>0.641634</td>\n",
       "      <td>0.616248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 30, 'kneig...</td>\n",
       "      <td>0.115044</td>\n",
       "      <td>0.530786</td>\n",
       "      <td>0.540380</td>\n",
       "      <td>0.592964</td>\n",
       "      <td>0.641634</td>\n",
       "      <td>0.616248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.113429</td>\n",
       "      <td>0.530786</td>\n",
       "      <td>0.540380</td>\n",
       "      <td>0.592964</td>\n",
       "      <td>0.641634</td>\n",
       "      <td>0.616248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.092954</td>\n",
       "      <td>0.533643</td>\n",
       "      <td>0.540457</td>\n",
       "      <td>0.593016</td>\n",
       "      <td>0.641770</td>\n",
       "      <td>0.616339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 30, 'kneig...</td>\n",
       "      <td>0.095304</td>\n",
       "      <td>0.533643</td>\n",
       "      <td>0.540457</td>\n",
       "      <td>0.593016</td>\n",
       "      <td>0.641770</td>\n",
       "      <td>0.616339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 30, 'kneig...</td>\n",
       "      <td>0.165504</td>\n",
       "      <td>0.533643</td>\n",
       "      <td>0.540457</td>\n",
       "      <td>0.593016</td>\n",
       "      <td>0.641770</td>\n",
       "      <td>0.616339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.070018</td>\n",
       "      <td>0.533643</td>\n",
       "      <td>0.540457</td>\n",
       "      <td>0.593016</td>\n",
       "      <td>0.641770</td>\n",
       "      <td>0.616339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.099214</td>\n",
       "      <td>0.536753</td>\n",
       "      <td>0.547807</td>\n",
       "      <td>0.594659</td>\n",
       "      <td>0.672258</td>\n",
       "      <td>0.631018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 30, 'kneig...</td>\n",
       "      <td>0.063379</td>\n",
       "      <td>0.536753</td>\n",
       "      <td>0.547807</td>\n",
       "      <td>0.594659</td>\n",
       "      <td>0.672258</td>\n",
       "      <td>0.631018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 30, 'kneig...</td>\n",
       "      <td>0.122858</td>\n",
       "      <td>0.536753</td>\n",
       "      <td>0.547807</td>\n",
       "      <td>0.594659</td>\n",
       "      <td>0.672258</td>\n",
       "      <td>0.631018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.165063</td>\n",
       "      <td>0.536753</td>\n",
       "      <td>0.547807</td>\n",
       "      <td>0.594659</td>\n",
       "      <td>0.672258</td>\n",
       "      <td>0.631018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 30, 'kneig...</td>\n",
       "      <td>0.132646</td>\n",
       "      <td>0.539443</td>\n",
       "      <td>0.547931</td>\n",
       "      <td>0.594736</td>\n",
       "      <td>0.672473</td>\n",
       "      <td>0.631157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.113597</td>\n",
       "      <td>0.539443</td>\n",
       "      <td>0.547931</td>\n",
       "      <td>0.594736</td>\n",
       "      <td>0.672473</td>\n",
       "      <td>0.631157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 30, 'kneig...</td>\n",
       "      <td>0.161365</td>\n",
       "      <td>0.539443</td>\n",
       "      <td>0.547931</td>\n",
       "      <td>0.594736</td>\n",
       "      <td>0.672473</td>\n",
       "      <td>0.631157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.188263</td>\n",
       "      <td>0.539443</td>\n",
       "      <td>0.547931</td>\n",
       "      <td>0.594736</td>\n",
       "      <td>0.672473</td>\n",
       "      <td>0.631157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.101470</td>\n",
       "      <td>0.548634</td>\n",
       "      <td>0.563203</td>\n",
       "      <td>0.595586</td>\n",
       "      <td>0.750999</td>\n",
       "      <td>0.664190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.152566</td>\n",
       "      <td>0.548634</td>\n",
       "      <td>0.563203</td>\n",
       "      <td>0.595586</td>\n",
       "      <td>0.750999</td>\n",
       "      <td>0.664190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 30, 'kneig...</td>\n",
       "      <td>0.084599</td>\n",
       "      <td>0.548634</td>\n",
       "      <td>0.563203</td>\n",
       "      <td>0.595586</td>\n",
       "      <td>0.750999</td>\n",
       "      <td>0.664190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 30, 'kneig...</td>\n",
       "      <td>0.087758</td>\n",
       "      <td>0.548634</td>\n",
       "      <td>0.563203</td>\n",
       "      <td>0.595586</td>\n",
       "      <td>0.750999</td>\n",
       "      <td>0.664190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.077378</td>\n",
       "      <td>0.551084</td>\n",
       "      <td>0.563218</td>\n",
       "      <td>0.595595</td>\n",
       "      <td>0.751027</td>\n",
       "      <td>0.664206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.116217</td>\n",
       "      <td>0.551084</td>\n",
       "      <td>0.563218</td>\n",
       "      <td>0.595595</td>\n",
       "      <td>0.751027</td>\n",
       "      <td>0.664206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 30, 'kneig...</td>\n",
       "      <td>0.075925</td>\n",
       "      <td>0.551084</td>\n",
       "      <td>0.563218</td>\n",
       "      <td>0.595595</td>\n",
       "      <td>0.751027</td>\n",
       "      <td>0.664206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 30, 'kneig...</td>\n",
       "      <td>0.108861</td>\n",
       "      <td>0.551084</td>\n",
       "      <td>0.563218</td>\n",
       "      <td>0.595595</td>\n",
       "      <td>0.751027</td>\n",
       "      <td>0.664206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>0.550186</td>\n",
       "      <td>0.564731</td>\n",
       "      <td>0.594784</td>\n",
       "      <td>0.764520</td>\n",
       "      <td>0.668909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 30, 'kneig...</td>\n",
       "      <td>0.113612</td>\n",
       "      <td>0.550186</td>\n",
       "      <td>0.564731</td>\n",
       "      <td>0.594784</td>\n",
       "      <td>0.764520</td>\n",
       "      <td>0.668909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 30, 'kneig...</td>\n",
       "      <td>0.120045</td>\n",
       "      <td>0.550186</td>\n",
       "      <td>0.564731</td>\n",
       "      <td>0.594784</td>\n",
       "      <td>0.764520</td>\n",
       "      <td>0.668909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.092432</td>\n",
       "      <td>0.550186</td>\n",
       "      <td>0.564731</td>\n",
       "      <td>0.594784</td>\n",
       "      <td>0.764520</td>\n",
       "      <td>0.668909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 30, 'kneig...</td>\n",
       "      <td>0.105215</td>\n",
       "      <td>0.552706</td>\n",
       "      <td>0.564793</td>\n",
       "      <td>0.594818</td>\n",
       "      <td>0.764629</td>\n",
       "      <td>0.668973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.098632</td>\n",
       "      <td>0.552706</td>\n",
       "      <td>0.564793</td>\n",
       "      <td>0.594818</td>\n",
       "      <td>0.764629</td>\n",
       "      <td>0.668973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.084790</td>\n",
       "      <td>0.552706</td>\n",
       "      <td>0.564793</td>\n",
       "      <td>0.594818</td>\n",
       "      <td>0.764629</td>\n",
       "      <td>0.668973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 30, 'kneig...</td>\n",
       "      <td>0.133397</td>\n",
       "      <td>0.552706</td>\n",
       "      <td>0.564793</td>\n",
       "      <td>0.594818</td>\n",
       "      <td>0.764629</td>\n",
       "      <td>0.668973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.075920</td>\n",
       "      <td>0.566242</td>\n",
       "      <td>0.576791</td>\n",
       "      <td>0.577362</td>\n",
       "      <td>0.987240</td>\n",
       "      <td>0.728569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 30, 'kneig...</td>\n",
       "      <td>0.100082</td>\n",
       "      <td>0.566242</td>\n",
       "      <td>0.576791</td>\n",
       "      <td>0.577362</td>\n",
       "      <td>0.987240</td>\n",
       "      <td>0.728569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.100956</td>\n",
       "      <td>0.566242</td>\n",
       "      <td>0.576791</td>\n",
       "      <td>0.577362</td>\n",
       "      <td>0.987240</td>\n",
       "      <td>0.728569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 30, 'kneig...</td>\n",
       "      <td>0.093497</td>\n",
       "      <td>0.566242</td>\n",
       "      <td>0.576791</td>\n",
       "      <td>0.577362</td>\n",
       "      <td>0.987240</td>\n",
       "      <td>0.728569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 30, 'kneig...</td>\n",
       "      <td>0.091964</td>\n",
       "      <td>0.568194</td>\n",
       "      <td>0.576760</td>\n",
       "      <td>0.577189</td>\n",
       "      <td>0.988988</td>\n",
       "      <td>0.728907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.074392</td>\n",
       "      <td>0.568194</td>\n",
       "      <td>0.576760</td>\n",
       "      <td>0.577189</td>\n",
       "      <td>0.988988</td>\n",
       "      <td>0.728907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.089453</td>\n",
       "      <td>0.568194</td>\n",
       "      <td>0.576760</td>\n",
       "      <td>0.577189</td>\n",
       "      <td>0.988988</td>\n",
       "      <td>0.728907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 30, 'kneig...</td>\n",
       "      <td>0.115611</td>\n",
       "      <td>0.568194</td>\n",
       "      <td>0.576760</td>\n",
       "      <td>0.577189</td>\n",
       "      <td>0.988988</td>\n",
       "      <td>0.728907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.122269</td>\n",
       "      <td>0.569838</td>\n",
       "      <td>0.576560</td>\n",
       "      <td>0.576750</td>\n",
       "      <td>0.992467</td>\n",
       "      <td>0.729507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.108293</td>\n",
       "      <td>0.569838</td>\n",
       "      <td>0.576560</td>\n",
       "      <td>0.576750</td>\n",
       "      <td>0.992467</td>\n",
       "      <td>0.729507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 30, 'kneig...</td>\n",
       "      <td>0.115156</td>\n",
       "      <td>0.569838</td>\n",
       "      <td>0.576560</td>\n",
       "      <td>0.576750</td>\n",
       "      <td>0.992467</td>\n",
       "      <td>0.729507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 30, 'kneig...</td>\n",
       "      <td>0.171642</td>\n",
       "      <td>0.569838</td>\n",
       "      <td>0.576560</td>\n",
       "      <td>0.576750</td>\n",
       "      <td>0.992467</td>\n",
       "      <td>0.729507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 30, 'kneig...</td>\n",
       "      <td>0.083476</td>\n",
       "      <td>0.568008</td>\n",
       "      <td>0.576606</td>\n",
       "      <td>0.576773</td>\n",
       "      <td>0.992520</td>\n",
       "      <td>0.729539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 30, 'kneig...</td>\n",
       "      <td>0.139680</td>\n",
       "      <td>0.568008</td>\n",
       "      <td>0.576606</td>\n",
       "      <td>0.576773</td>\n",
       "      <td>0.992520</td>\n",
       "      <td>0.729539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.071766</td>\n",
       "      <td>0.568008</td>\n",
       "      <td>0.576606</td>\n",
       "      <td>0.576773</td>\n",
       "      <td>0.992520</td>\n",
       "      <td>0.729539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.126669</td>\n",
       "      <td>0.568008</td>\n",
       "      <td>0.576606</td>\n",
       "      <td>0.576773</td>\n",
       "      <td>0.992520</td>\n",
       "      <td>0.729539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  mean_fit_time  \\\n",
       "0   {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.043084   \n",
       "36  {'kneighborsclassifier__leaf_size': 30, 'kneig...       0.055543   \n",
       "24  {'kneighborsclassifier__leaf_size': 30, 'kneig...       0.115044   \n",
       "12  {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.113429   \n",
       "1   {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.092954   \n",
       "37  {'kneighborsclassifier__leaf_size': 30, 'kneig...       0.095304   \n",
       "25  {'kneighborsclassifier__leaf_size': 30, 'kneig...       0.165504   \n",
       "13  {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.070018   \n",
       "2   {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.099214   \n",
       "26  {'kneighborsclassifier__leaf_size': 30, 'kneig...       0.063379   \n",
       "38  {'kneighborsclassifier__leaf_size': 30, 'kneig...       0.122858   \n",
       "14  {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.165063   \n",
       "27  {'kneighborsclassifier__leaf_size': 30, 'kneig...       0.132646   \n",
       "15  {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.113597   \n",
       "39  {'kneighborsclassifier__leaf_size': 30, 'kneig...       0.161365   \n",
       "3   {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.188263   \n",
       "16  {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.101470   \n",
       "4   {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.152566   \n",
       "40  {'kneighborsclassifier__leaf_size': 30, 'kneig...       0.084599   \n",
       "28  {'kneighborsclassifier__leaf_size': 30, 'kneig...       0.087758   \n",
       "5   {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.077378   \n",
       "17  {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.116217   \n",
       "41  {'kneighborsclassifier__leaf_size': 30, 'kneig...       0.075925   \n",
       "29  {'kneighborsclassifier__leaf_size': 30, 'kneig...       0.108861   \n",
       "18  {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.135365   \n",
       "42  {'kneighborsclassifier__leaf_size': 30, 'kneig...       0.113612   \n",
       "30  {'kneighborsclassifier__leaf_size': 30, 'kneig...       0.120045   \n",
       "6   {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.092432   \n",
       "31  {'kneighborsclassifier__leaf_size': 30, 'kneig...       0.105215   \n",
       "19  {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.098632   \n",
       "7   {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.084790   \n",
       "43  {'kneighborsclassifier__leaf_size': 30, 'kneig...       0.133397   \n",
       "8   {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.075920   \n",
       "32  {'kneighborsclassifier__leaf_size': 30, 'kneig...       0.100082   \n",
       "20  {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.100956   \n",
       "44  {'kneighborsclassifier__leaf_size': 30, 'kneig...       0.093497   \n",
       "33  {'kneighborsclassifier__leaf_size': 30, 'kneig...       0.091964   \n",
       "21  {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.074392   \n",
       "9   {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.089453   \n",
       "45  {'kneighborsclassifier__leaf_size': 30, 'kneig...       0.115611   \n",
       "23  {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.122269   \n",
       "11  {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.108293   \n",
       "35  {'kneighborsclassifier__leaf_size': 30, 'kneig...       0.115156   \n",
       "47  {'kneighborsclassifier__leaf_size': 30, 'kneig...       0.171642   \n",
       "34  {'kneighborsclassifier__leaf_size': 30, 'kneig...       0.083476   \n",
       "46  {'kneighborsclassifier__leaf_size': 30, 'kneig...       0.139680   \n",
       "22  {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.071766   \n",
       "10  {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.126669   \n",
       "\n",
       "    mean_test_roc_auc  mean_test_accuracy  mean_test_precision  \\\n",
       "0            0.530786            0.540380             0.592964   \n",
       "36           0.530786            0.540380             0.592964   \n",
       "24           0.530786            0.540380             0.592964   \n",
       "12           0.530786            0.540380             0.592964   \n",
       "1            0.533643            0.540457             0.593016   \n",
       "37           0.533643            0.540457             0.593016   \n",
       "25           0.533643            0.540457             0.593016   \n",
       "13           0.533643            0.540457             0.593016   \n",
       "2            0.536753            0.547807             0.594659   \n",
       "26           0.536753            0.547807             0.594659   \n",
       "38           0.536753            0.547807             0.594659   \n",
       "14           0.536753            0.547807             0.594659   \n",
       "27           0.539443            0.547931             0.594736   \n",
       "15           0.539443            0.547931             0.594736   \n",
       "39           0.539443            0.547931             0.594736   \n",
       "3            0.539443            0.547931             0.594736   \n",
       "16           0.548634            0.563203             0.595586   \n",
       "4            0.548634            0.563203             0.595586   \n",
       "40           0.548634            0.563203             0.595586   \n",
       "28           0.548634            0.563203             0.595586   \n",
       "5            0.551084            0.563218             0.595595   \n",
       "17           0.551084            0.563218             0.595595   \n",
       "41           0.551084            0.563218             0.595595   \n",
       "29           0.551084            0.563218             0.595595   \n",
       "18           0.550186            0.564731             0.594784   \n",
       "42           0.550186            0.564731             0.594784   \n",
       "30           0.550186            0.564731             0.594784   \n",
       "6            0.550186            0.564731             0.594784   \n",
       "31           0.552706            0.564793             0.594818   \n",
       "19           0.552706            0.564793             0.594818   \n",
       "7            0.552706            0.564793             0.594818   \n",
       "43           0.552706            0.564793             0.594818   \n",
       "8            0.566242            0.576791             0.577362   \n",
       "32           0.566242            0.576791             0.577362   \n",
       "20           0.566242            0.576791             0.577362   \n",
       "44           0.566242            0.576791             0.577362   \n",
       "33           0.568194            0.576760             0.577189   \n",
       "21           0.568194            0.576760             0.577189   \n",
       "9            0.568194            0.576760             0.577189   \n",
       "45           0.568194            0.576760             0.577189   \n",
       "23           0.569838            0.576560             0.576750   \n",
       "11           0.569838            0.576560             0.576750   \n",
       "35           0.569838            0.576560             0.576750   \n",
       "47           0.569838            0.576560             0.576750   \n",
       "34           0.568008            0.576606             0.576773   \n",
       "46           0.568008            0.576606             0.576773   \n",
       "22           0.568008            0.576606             0.576773   \n",
       "10           0.568008            0.576606             0.576773   \n",
       "\n",
       "    mean_test_recall  mean_test_f1  \n",
       "0           0.641634      0.616248  \n",
       "36          0.641634      0.616248  \n",
       "24          0.641634      0.616248  \n",
       "12          0.641634      0.616248  \n",
       "1           0.641770      0.616339  \n",
       "37          0.641770      0.616339  \n",
       "25          0.641770      0.616339  \n",
       "13          0.641770      0.616339  \n",
       "2           0.672258      0.631018  \n",
       "26          0.672258      0.631018  \n",
       "38          0.672258      0.631018  \n",
       "14          0.672258      0.631018  \n",
       "27          0.672473      0.631157  \n",
       "15          0.672473      0.631157  \n",
       "39          0.672473      0.631157  \n",
       "3           0.672473      0.631157  \n",
       "16          0.750999      0.664190  \n",
       "4           0.750999      0.664190  \n",
       "40          0.750999      0.664190  \n",
       "28          0.750999      0.664190  \n",
       "5           0.751027      0.664206  \n",
       "17          0.751027      0.664206  \n",
       "41          0.751027      0.664206  \n",
       "29          0.751027      0.664206  \n",
       "18          0.764520      0.668909  \n",
       "42          0.764520      0.668909  \n",
       "30          0.764520      0.668909  \n",
       "6           0.764520      0.668909  \n",
       "31          0.764629      0.668973  \n",
       "19          0.764629      0.668973  \n",
       "7           0.764629      0.668973  \n",
       "43          0.764629      0.668973  \n",
       "8           0.987240      0.728569  \n",
       "32          0.987240      0.728569  \n",
       "20          0.987240      0.728569  \n",
       "44          0.987240      0.728569  \n",
       "33          0.988988      0.728907  \n",
       "21          0.988988      0.728907  \n",
       "9           0.988988      0.728907  \n",
       "45          0.988988      0.728907  \n",
       "23          0.992467      0.729507  \n",
       "11          0.992467      0.729507  \n",
       "35          0.992467      0.729507  \n",
       "47          0.992467      0.729507  \n",
       "34          0.992520      0.729539  \n",
       "46          0.992520      0.729539  \n",
       "22          0.992520      0.729539  \n",
       "10          0.992520      0.729539  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10-fold Cross Validation results:\n",
      "---------------------------------\n",
      "F1 scores: [0.71971212 0.7223114  0.71681416 0.71504715 0.71388102 0.71526379\n",
      " 0.7131655  0.72953451 0.70446321 0.74235808]\n",
      "\n",
      "Precision scores [0.56782334 0.57544757 0.56969309 0.58133333 0.56647399 0.56238125\n",
      " 0.57638426 0.58645161 0.54852849 0.60051381]\n",
      "\n",
      "Recall scores [0.98253275 0.96982759 0.96637744 0.9286475  0.96498906 0.98230088\n",
      " 0.93506494 0.96496815 0.98426966 0.97193347]\n",
      "\n",
      "Average F1:  0.7192550930052576\n",
      "Min F1:  0.7044632086851628\n",
      "Max F1:  0.74235807860262\n",
      "\n",
      "Average Precision:  0.5735030753141834\n",
      "Min Precision:  0.5485284909204758\n",
      "Max Precision:  0.6005138086062941\n",
      "\n",
      "Average Recall:  0.9650911441805977\n",
      "Min Recall:  0.9286474973375932\n",
      "Max Recall:  0.9842696629213483\n",
      "\n",
      "Single Run results:\n",
      "---------------------------------\n",
      "Accuracy: 0.5743051266213712\n",
      "Precision: 0.5743142144638403\n",
      "Recall: 0.9931004743423889\n",
      "F1: 0.7277610996997945\n",
      "\n",
      "Fit time:  0.00567118899198249\n",
      "CV time:  3.8818543720408343\n",
      "Total time:  11.071164189022966\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#KNN Classification 10-fold cross-validation\n",
    "\n",
    "KnnPipe = make_pipeline(KNeighborsClassifier())\n",
    "KnnParams = [\n",
    "    {\n",
    "         'kneighborsclassifier__weights': ['uniform','distance'],\n",
    "         'kneighborsclassifier__leaf_size': [10,30],\n",
    "         'kneighborsclassifier__metric': ['minkowski','euclidean'],\n",
    "         'kneighborsclassifier__n_neighbors':[3,5,13,15,round(sqrt(X_train.shape[0])),round(sqrt(len(ipdata)))],\n",
    "         'kneighborsclassifier__n_jobs':[-1]\n",
    "    }\n",
    "]\n",
    "\n",
    "KnnGrid = testPerformance(KnnPipe, KnnParams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "grid time:  43.40527008497156\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'kneighborsclassifier__leaf_size': 10, 'kneig...</td>\n",
       "      <td>0.030559</td>\n",
       "      <td>0.536753</td>\n",
       "      <td>0.547807</td>\n",
       "      <td>0.594659</td>\n",
       "      <td>0.672258</td>\n",
       "      <td>0.631018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  mean_fit_time  \\\n",
       "0  {'kneighborsclassifier__leaf_size': 10, 'kneig...       0.030559   \n",
       "\n",
       "   mean_test_roc_auc  mean_test_accuracy  mean_test_precision  \\\n",
       "0           0.536753            0.547807             0.594659   \n",
       "\n",
       "   mean_test_recall  mean_test_f1  \n",
       "0          0.672258      0.631018  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10-fold Cross Validation results:\n",
      "---------------------------------\n",
      "F1 scores: [0.60242233 0.58404255 0.61466459 0.57770632 0.58937198 0.61644562\n",
      " 0.57911733 0.6078329  0.59662091 0.60681115]\n",
      "\n",
      "Precision scores [0.58189217 0.57668067 0.59040959 0.58144552 0.57850369 0.5922528\n",
      " 0.57601713 0.59815005 0.562749   0.60245902]\n",
      "\n",
      "Recall scores [0.62445415 0.59159483 0.64099783 0.57401491 0.60065646 0.64269912\n",
      " 0.58225108 0.61783439 0.63483146 0.61122661]\n",
      "\n",
      "Average F1:  0.5975035677298262\n",
      "Min F1:  0.5777063236870311\n",
      "Max F1:  0.6164456233421751\n",
      "\n",
      "Average Precision:  0.584055964644847\n",
      "Min Precision:  0.5627490039840638\n",
      "Max Precision:  0.6024590163934426\n",
      "\n",
      "Average Recall:  0.6120560835581383\n",
      "Min Recall:  0.5740149094781682\n",
      "Max Recall:  0.6426991150442478\n",
      "\n",
      "Single Run results:\n",
      "---------------------------------\n",
      "Accuracy: 0.5560222359481162\n",
      "Precision: 0.597752808988764\n",
      "Recall: 0.6882276843467011\n",
      "F1: 0.639807576668671\n",
      "\n",
      "Fit time:  0.006670586997643113\n",
      "CV time:  4.0582847250043415\n",
      "Total time:  10.729753850027919\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#KNN Classification 10-fold cross-validation\n",
    "\n",
    "KnnPipe = make_pipeline(KNeighborsClassifier())\n",
    "KnnParams = [\n",
    "    {\n",
    "         'kneighborsclassifier__weights': ['uniform'],\n",
    "         'kneighborsclassifier__leaf_size': [10],\n",
    "         'kneighborsclassifier__metric': ['minkowski'],\n",
    "         'kneighborsclassifier__n_neighbors':[5],\n",
    "         'kneighborsclassifier__n_jobs':[-1]\n",
    "    }\n",
    "]\n",
    "\n",
    "KnnGrid = testPerformance(KnnPipe, KnnParams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('kneighborsclassifier',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=10,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=-1, n_neighbors=5, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KnnGrid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sorted(metrics.SCORERS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "grid time:  23.31968172098277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('kneighborsregressor',\n",
       "                 KNeighborsRegressor(algorithm='auto', leaf_size=10,\n",
       "                                     metric='minkowski', metric_params=None,\n",
       "                                     n_jobs=-1, n_neighbors=5, p=2,\n",
       "                                     weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"KNN Regression code\"\"\"\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "RegKnnPipe = make_pipeline(KNeighborsRegressor())\n",
    "RegKnnParams = [\n",
    "    {\n",
    "         'kneighborsregressor__weights': ['uniform'],\n",
    "         'kneighborsregressor__leaf_size': [10],\n",
    "         'kneighborsregressor__metric': ['minkowski'],\n",
    "         'kneighborsregressor__n_neighbors':[5],\n",
    "         'kneighborsregressor__n_jobs':[-1]\n",
    "    }\n",
    "]\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=.2, random_state=86)\n",
    "\n",
    "#Perform the grid search using accuracy as a metric during cross validation.\n",
    "grid = GridSearchCV(RegKnnPipe, RegKnnParams, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "#Use the best features from recursive feature elimination during the grid search\n",
    "start_time = timeit.default_timer()\n",
    "grid.fit(reg_X_train, reg_y_train)\n",
    "grid_time = timeit.default_timer() - start_time\n",
    "#display the best pipeline model identified during the grid search\n",
    "print(\"\\ngrid time: \", grid_time)\n",
    "\n",
    "gridResults = pd.DataFrame.from_dict(grid.cv_results_)\n",
    "\n",
    "grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "grid time:  62.7144524770556\n"
     ]
    }
   ],
   "source": [
    "\"\"\"OLS Regression code\"\"\"\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "OLSPipe = make_pipeline(LinearRegression())\n",
    "OLSParams = [\n",
    "    {\n",
    "         'linearregression__n_jobs':[-1]\n",
    "    }\n",
    "]\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=.2, random_state=86)\n",
    "\n",
    "#Perform the grid search using accuracy as a metric during cross validation.\n",
    "grid = GridSearchCV(OLSPipe, OLSParams, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "#Use the best features from recursive feature elimination during the grid search\n",
    "start_time = timeit.default_timer()\n",
    "grid.fit(reg_X_train, reg_y_train)\n",
    "grid_time = timeit.default_timer() - start_time\n",
    "#display the best pipeline model identified during the grid search\n",
    "print(\"\\ngrid time: \", grid_time)\n",
    "\n",
    "gridResults = pd.DataFrame.from_dict(grid.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29642    0.0560\n",
       "12132    0.2320\n",
       "37347    0.2960\n",
       "23817    0.0560\n",
       "23549    0.0056\n",
       "          ...  \n",
       "7737     0.0560\n",
       "4117     0.0800\n",
       "36685    0.0800\n",
       "19725    0.0320\n",
       "10011    0.2160\n",
       "Name: InscClaimAmtReimbursed, Length: 8095, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypreds = grid.best_estimator_[0].predict(reg_X_test)\n",
    "ypreds\n",
    "reg_y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluations 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO:__ Visualize results \n",
    "\n",
    "People don't explain 'why' which will deduct points \n",
    "\n",
    "Analyze how the model is performing \n",
    "\n",
    "Explaination is bolstered by analysis \n",
    "\n",
    "TIP: YellowBrick (it's a pkg) for visualizing estimators "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluations 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO:__\n",
    "Discuss advantages of models for a classification task \n",
    "\n",
    "Give table, how many models you built \n",
    "\n",
    "CV results object from grid search will give all of that information \n",
    "\n",
    "TIP Put in a dataframe in ME5 and then talk about \n",
    "\n",
    "Here's all the models we did, here is the best one (or top 3) \n",
    "\n",
    "Is there one that runs 10x as long and a slightly inferior runs fast \n",
    "\n",
    "Is the difference between models significant? \n",
    "\n",
    "Long method 1: Notebook #6 and use student's paired t test (at bottom), correct t value and folds \n",
    "\n",
    "Long method 2: generate ROC curves for each model \n",
    "\n",
    "If you use ROC as your eval metric, it is statistically sound measure, so if one has a larger area under curve, it is a better model statistically speaking. \n",
    "\n",
    "Can use micro average ROC curve with multiclass problem \n",
    "\n",
    "If you already did both, ask for exceptional points \n",
    "\n",
    "TIP: mlxtend has an 'evaluate' library for significant test \n",
    "\n",
    "Can get comprehensive with paired_ttest5x2cv \n",
    "\n",
    "Calling library and function will spit out exactly what you need "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluations 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO:__\n",
    "    Two options: \n",
    "\n",
    "Both tasks are on same dataset.  do two feature importance and opine difference between two \n",
    "\n",
    "Make sure you do feature importance on scaled data if you're using coefficients \n",
    "\n",
    "Use some other type of feature eval technique (mlextend library has multiple options) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO:__\n",
    "    Address each question (in a subsection) \n",
    "\n",
    "2 ways to go about it \n",
    "\n",
    "Just because you can't predict something in the real world, doesn't necessarily mean you aren't interested in model's ability to predict \n",
    "\n",
    "Predict graduation rate for public schools (schools know their rates.. But they would be interested in what is correlated with grad rates) \n",
    "\n",
    "Maybe it's not useful for prediction, but could be used for EDA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exceptional Work\n",
    "### Preprocessing:\n",
    "We would like credit for the large amount of preprocessing that went into our data.  We have a large variety of features in the dataset, many of which required clever feature engineering tricks to improve performance.  Conversion to the sparse matrix took a good bit of research, and continues to be an effort for implementation, since not every model or library will accept a sparse matrix.  The conversion of procedure codes and diagnosis codes from multiple columns into a one hot encoded dataframe took a significant amount of time/effort, most of the out of the box libraries we tried would not parse a list object and it took a lot of experimentation and research.  The performance improved as it reduced our total featureset footprint from > 40,000 to around 9,000.   \n",
    "\n",
    "### Pipelines and Grid Search:\n",
    "We decided to implement Pipelines and Grid Search in order to reduce the copy/paste and number of variables we need to work with.  This is a new concept barely touched on in class, and it required significant amounts of research time to implement before we could move on to model evaluation, visualization and discussion.  We determined the best approach i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <a href=\"https://machinelearningmastery.com/k-fold-cross-validation/\"> https://machinelearningmastery.com/k-fold-cross-validation/ </a> K-Fold Cross Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": false,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": true,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "285px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 365,
   "position": {
    "height": "40px",
    "left": "789px",
    "right": "20px",
    "top": "120px",
    "width": "630px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
