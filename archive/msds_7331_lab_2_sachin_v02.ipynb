{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6> <b> SMU Lab Two - MSDS7331 - Machine Learning-1 </b> </font>\n",
    "\n",
    "<font size=5> <b> Summer 2020 Group - Sachin, Ikenna, Edgar, Dustin </b></font> \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/sachinac/ML7331/blob/master/data/data_mining.jpg?raw=true\"> \n",
    "\n",
    "<p align=\"center\"><font size=5> <b> Health Care Fraud Detection  </b></font> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import Libraries</a></span></li><li><span><a href=\"#Data-Preparation-Part-1\" data-toc-modified-id=\"Data-Preparation-Part-1-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Preparation Part 1</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Set-Categorical-Variables\" data-toc-modified-id=\"Set-Categorical-Variables-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Set Categorical Variables</a></span></li><li><span><a href=\"#Set-Float-Variables\" data-toc-modified-id=\"Set-Float-Variables-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Set Float Variables</a></span></li><li><span><a href=\"#Set-Integer-Variables\" data-toc-modified-id=\"Set-Integer-Variables-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Set Integer Variables</a></span></li><li><span><a href=\"#Set-Date-Variables\" data-toc-modified-id=\"Set-Date-Variables-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Set Date Variables</a></span></li><li><span><a href=\"#Recoding-Binary-and-Categorical-Features\" data-toc-modified-id=\"Recoding-Binary-and-Categorical-Features-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Recoding Binary and Categorical Features</a></span></li><li><span><a href=\"#Final-Dataframe---All-Features\" data-toc-modified-id=\"Final-Dataframe---All-Features-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Final Dataframe - All Features</a></span></li><li><span><a href=\"#Set-Target-Variable\" data-toc-modified-id=\"Set-Target-Variable-2.8\"><span class=\"toc-item-num\">2.8&nbsp;&nbsp;</span>Set Target Variable</a></span></li><li><span><a href=\"#One-Hot-Encoding-using-SciKit-Learn-Multi-Label-Binarizer\" data-toc-modified-id=\"One-Hot-Encoding-using-SciKit-Learn-Multi-Label-Binarizer-2.9\"><span class=\"toc-item-num\">2.9&nbsp;&nbsp;</span>One Hot Encoding using SciKit Learn Multi Label Binarizer</a></span></li><li><span><a href=\"#One-Hot-Encoding-using-Pandas\" data-toc-modified-id=\"One-Hot-Encoding-using-Pandas-2.10\"><span class=\"toc-item-num\">2.10&nbsp;&nbsp;</span>One Hot Encoding using Pandas</a></span></li><li><span><a href=\"#Post-processing-Encoded-Features\" data-toc-modified-id=\"Post-processing-Encoded-Features-2.11\"><span class=\"toc-item-num\">2.11&nbsp;&nbsp;</span>Post-processing Encoded Features</a></span></li><li><span><a href=\"#Remove-'None'-columns\" data-toc-modified-id=\"Remove-'None'-columns-2.12\"><span class=\"toc-item-num\">2.12&nbsp;&nbsp;</span>Remove 'None' columns</a></span></li><li><span><a href=\"#MinMaxScaler\" data-toc-modified-id=\"MinMaxScaler-2.13\"><span class=\"toc-item-num\">2.13&nbsp;&nbsp;</span>MinMaxScaler</a></span></li></ul></li><li><span><a href=\"#Data-Preparation-Part-2\" data-toc-modified-id=\"Data-Preparation-Part-2-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Preparation Part 2</a></span><ul class=\"toc-item\"><li><span><a href=\"#Final-DataSet\" data-toc-modified-id=\"Final-DataSet-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Final DataSet</a></span></li></ul></li><li><span><a href=\"#Modeling-and-Evaluation-1\" data-toc-modified-id=\"Modeling-and-Evaluation-1-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Modeling and Evaluation 1</a></span><ul class=\"toc-item\"><li><span><a href=\"#Task-1:-Classification---Provider-Fraud\" data-toc-modified-id=\"Task-1:-Classification---Provider-Fraud-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Task 1: Classification - Provider Fraud</a></span></li><li><span><a href=\"#Task-2:-Regression\" data-toc-modified-id=\"Task-2:-Regression-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Task 2: Regression</a></span></li></ul></li><li><span><a href=\"#Modeling-and-Evaluation-2\" data-toc-modified-id=\"Modeling-and-Evaluation-2-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Modeling and Evaluation 2</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sparse-Matrix-Conversion-and-Test/Train-Split\" data-toc-modified-id=\"Sparse-Matrix-Conversion-and-Test/Train-Split-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Sparse Matrix Conversion and Test/Train Split</a></span></li><li><span><a href=\"#Cross-Validation-Method\" data-toc-modified-id=\"Cross-Validation-Method-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Cross Validation Method</a></span></li></ul></li><li><span><a href=\"#Modeling-and-Evaluations-3\" data-toc-modified-id=\"Modeling-and-Evaluations-3-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Modeling and Evaluations 3</a></span><ul class=\"toc-item\"><li><span><a href=\"#function-Defnitions\" data-toc-modified-id=\"function-Defnitions-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>function Defnitions</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.0-testPerformance\" data-toc-modified-id=\"1.0-testPerformance-6.1.1\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;</span>1.0 testPerformance</a></span></li><li><span><a href=\"#2.0-Display-Weights\" data-toc-modified-id=\"2.0-Display-Weights-6.1.2\"><span class=\"toc-item-num\">6.1.2&nbsp;&nbsp;</span>2.0 Display Weights</a></span></li><li><span><a href=\"#3.0-lab2_grid_search\" data-toc-modified-id=\"3.0-lab2_grid_search-6.1.3\"><span class=\"toc-item-num\">6.1.3&nbsp;&nbsp;</span>3.0 lab2_grid_search</a></span></li></ul></li><li><span><a href=\"#Classification-Models\" data-toc-modified-id=\"Classification-Models-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Classification Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-6.2.1\"><span class=\"toc-item-num\">6.2.1&nbsp;&nbsp;</span>Logistic Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Parameters\" data-toc-modified-id=\"Logistic-Parameters-6.2.1.1\"><span class=\"toc-item-num\">6.2.1.1&nbsp;&nbsp;</span>Logistic Parameters</a></span></li><li><span><a href=\"#Parameter-Grid\" data-toc-modified-id=\"Parameter-Grid-6.2.1.2\"><span class=\"toc-item-num\">6.2.1.2&nbsp;&nbsp;</span>Parameter Grid</a></span></li><li><span><a href=\"#GridSearch\" data-toc-modified-id=\"GridSearch-6.2.1.3\"><span class=\"toc-item-num\">6.2.1.3&nbsp;&nbsp;</span>GridSearch</a></span></li><li><span><a href=\"#Logistic-weights\" data-toc-modified-id=\"Logistic-weights-6.2.1.4\"><span class=\"toc-item-num\">6.2.1.4&nbsp;&nbsp;</span>Logistic weights</a></span></li></ul></li><li><span><a href=\"#Random-forest\" data-toc-modified-id=\"Random-forest-6.2.2\"><span class=\"toc-item-num\">6.2.2&nbsp;&nbsp;</span>Random forest</a></span><ul class=\"toc-item\"><li><span><a href=\"#Random-Forest-Parameters\" data-toc-modified-id=\"Random-Forest-Parameters-6.2.2.1\"><span class=\"toc-item-num\">6.2.2.1&nbsp;&nbsp;</span>Random Forest Parameters</a></span></li><li><span><a href=\"#Parameter-Grid\" data-toc-modified-id=\"Parameter-Grid-6.2.2.2\"><span class=\"toc-item-num\">6.2.2.2&nbsp;&nbsp;</span>Parameter Grid</a></span></li><li><span><a href=\"#GridSearch\" data-toc-modified-id=\"GridSearch-6.2.2.3\"><span class=\"toc-item-num\">6.2.2.3&nbsp;&nbsp;</span>GridSearch</a></span></li><li><span><a href=\"#Random-Forest-Weights\" data-toc-modified-id=\"Random-Forest-Weights-6.2.2.4\"><span class=\"toc-item-num\">6.2.2.4&nbsp;&nbsp;</span>Random Forest Weights</a></span></li></ul></li><li><span><a href=\"#Naive-Bayes\" data-toc-modified-id=\"Naive-Bayes-6.2.3\"><span class=\"toc-item-num\">6.2.3&nbsp;&nbsp;</span>Naive Bayes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Naive-Bayes-Parameters\" data-toc-modified-id=\"Naive-Bayes-Parameters-6.2.3.1\"><span class=\"toc-item-num\">6.2.3.1&nbsp;&nbsp;</span>Naive Bayes Parameters</a></span></li><li><span><a href=\"#Parameter-Grid\" data-toc-modified-id=\"Parameter-Grid-6.2.3.2\"><span class=\"toc-item-num\">6.2.3.2&nbsp;&nbsp;</span>Parameter Grid</a></span></li><li><span><a href=\"#Grid-Search\" data-toc-modified-id=\"Grid-Search-6.2.3.3\"><span class=\"toc-item-num\">6.2.3.3&nbsp;&nbsp;</span>Grid Search</a></span></li><li><span><a href=\"#Naive-Bayes-Weights\" data-toc-modified-id=\"Naive-Bayes-Weights-6.2.3.4\"><span class=\"toc-item-num\">6.2.3.4&nbsp;&nbsp;</span>Naive Bayes Weights</a></span></li></ul></li></ul></li><li><span><a href=\"#Regression-Models\" data-toc-modified-id=\"Regression-Models-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Regression Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Multiple-Linear-Regression\" data-toc-modified-id=\"Multiple-Linear-Regression-6.3.1\"><span class=\"toc-item-num\">6.3.1&nbsp;&nbsp;</span>Multiple Linear Regression</a></span></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-6.3.2\"><span class=\"toc-item-num\">6.3.2&nbsp;&nbsp;</span>Random Forest</a></span></li><li><span><a href=\"#kNN\" data-toc-modified-id=\"kNN-6.3.3\"><span class=\"toc-item-num\">6.3.3&nbsp;&nbsp;</span>kNN</a></span></li></ul></li></ul></li><li><span><a href=\"#Modeling-and-Evaluations-4\" data-toc-modified-id=\"Modeling-and-Evaluations-4-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Modeling and Evaluations 4</a></span></li><li><span><a href=\"#Modeling-and-Evaluations-5\" data-toc-modified-id=\"Modeling-and-Evaluations-5-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Modeling and Evaluations 5</a></span></li><li><span><a href=\"#Modeling-and-Evaluations-6\" data-toc-modified-id=\"Modeling-and-Evaluations-6-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Modeling and Evaluations 6</a></span></li><li><span><a href=\"#Deployment\" data-toc-modified-id=\"Deployment-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Deployment</a></span></li><li><span><a href=\"#Exceptional-Work\" data-toc-modified-id=\"Exceptional-Work-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Exceptional Work</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Preprocessing:\" data-toc-modified-id=\"Preprocessing:-11.0.1\"><span class=\"toc-item-num\">11.0.1&nbsp;&nbsp;</span>Preprocessing:</a></span></li><li><span><a href=\"#Pipelines-and-Grid-Search:\" data-toc-modified-id=\"Pipelines-and-Grid-Search:-11.0.2\"><span class=\"toc-item-num\">11.0.2&nbsp;&nbsp;</span>Pipelines and Grid Search:</a></span></li></ul></li></ul></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:51:14.762534Z",
     "start_time": "2020-07-05T03:51:13.648304Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import timeit\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, MultiLabelBinarizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.sparse import csc_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "lab2_random_state  = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data into memory. EDA was already performed on this data. We had originally received Beneficiary, Encounters and target variable datasets in three different spreadsheets and EDA combined that into single spreadsheet using keys of the tables. We still need to perform some additional operations before we actually start with modeling. So in first we prepare our data for modeling as follows :\n",
    "* Prepare variables. Setup data type correctly.\n",
    "* Remove unnecessary variables\n",
    "* Transform categorical features into dummy variables \n",
    "* Feature selection.\n",
    "\n",
    "Lets first print the information of this dataframe. As we can see from below dataframe info this data has total of 79 features. We definately dont need all features. This step will process some of the features before we actually use this data for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:51:17.095282Z",
     "start_time": "2020-07-05T03:51:16.624947Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lab2_df = pd.read_csv('data/final_fraud_dataset.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T08:51:44.322459Z",
     "start_time": "2020-06-30T08:51:44.318865Z"
    }
   },
   "source": [
    "Following are nominal categorical attributes. Pandas requires these to be datatype of 'object' or 'category'. We are setting nominal categorical variables as 'object'. Here is the list of categorical variables :\n",
    "\n",
    "* Race\n",
    "* Gender\n",
    "* RenalDiseaseIndicator\n",
    "* State\n",
    "* County\n",
    "* AttendingPhysicianPresent\n",
    "* OtherPhysicianPresent\n",
    "* OperatingPhysicianPresent\n",
    "* 11 Chronic Conditions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:51:18.521831Z",
     "start_time": "2020-07-05T03:51:18.441457Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_preds = ['Gender','Race','RenalDiseaseIndicator','State','County',\n",
    "                     'NoOfMonths_PartACov','NoOfMonths_PartBCov',\n",
    "                     'ChronicCond_Alzheimer','ChronicCond_Heartfailure',\n",
    "                     'ChronicCond_KidneyDisease','ChronicCond_Cancer','ChronicCond_ObstrPulmonary',\n",
    "                     'ChronicCond_Depression','ChronicCond_Diabetes','ChronicCond_IschemicHeart',\n",
    "                     'ChronicCond_Osteoporasis','ChronicCond_rheumatoidarthritis','ChronicCond_stroke',\n",
    "                     'Alive','ClmAdmitDiagnosisCode','DiagnosisGroupCode',\n",
    "                     'ClmDiagnosisCode_1','ClmDiagnosisCode_2','ClmDiagnosisCode_3',\n",
    "                     'ClmDiagnosisCode_4','ClmDiagnosisCode_5','ClmDiagnosisCode_6',\n",
    "                     'ClmDiagnosisCode_7','ClmDiagnosisCode_8','ClmDiagnosisCode_9',\n",
    "                     'ClmDiagnosisCode_10','ClmProcedureCode_1','ClmProcedureCode_2',\n",
    "                     'ClmProcedureCode_3','ClmProcedureCode_4','ClmProcedureCode_5',\n",
    "                     'AttendingPhysicianPresent','OtherPhysicianPresent','OperatingPhysicianPresent']\n",
    "\n",
    "lab2_df[cat_preds]   = lab2_df[cat_preds].astype('object')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Float Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following varibles are required to be datatype of floating point. These are amounts and hence it makes sense to changt it's type to float\n",
    "\n",
    "* InscClaimAmtReimbursed\n",
    "* IPAnnualReimbursementAmt\n",
    "* IPAnnualDeductibleAmt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:51:20.302494Z",
     "start_time": "2020-07-05T03:51:20.250187Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "float_preds = ['InscClaimAmtReimbursed','IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt']\n",
    "\n",
    "lab2_df[float_preds]   = lab2_df[float_preds].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Integer Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These variables contains all numbers but they are actually nominal categorical attributes. They are all binary in nature. So we can keep them as integer as we will be converting this dataset into sparse matrix for model building exercise. \n",
    "\n",
    "Following variables will be set as integer data type :\n",
    "* NoOfMonths_PartACov - Number of months of Medicare part A coverage\n",
    "* NoOfMonths_PartBCov - Number of months of Medicare part B coverage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:51:21.923465Z",
     "start_time": "2020-07-05T03:51:21.882349Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "int_preds = ['NoOfMonths_PartACov', \n",
    "             'NoOfMonths_PartBCov']\n",
    "\n",
    "lab2_df[int_preds] = lab2_df[int_preds].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Date Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are new attributes are derived from existing attritbutes of type dates. All date attributes are converted to the proleptic Gregorian ordinal of a date.In simple terms datetime.toordinal() returns the day count from the date 01/01/01\n",
    "\n",
    "\n",
    "* ORD_DOD - Set ORD_DOD to open end date where date is not available to indicate that Beneficiary is alive\n",
    "* ORD_DOB \n",
    "* ORD_ClaimStartDt\n",
    "* ORD_ClaimEndDt\n",
    "* ORD_AdmissionDt\n",
    "* ORD_DischargeDt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:51:24.612870Z",
     "start_time": "2020-07-05T03:51:23.514769Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dte_preds = ['ClaimStartDt', 'ClaimEndDt','AdmissionDt', 'DischargeDt', 'DOB','DOD']\n",
    "\n",
    "# Regex to normalize integer DOB/DOD as ISO dates\n",
    "lab2_df['DOB'] = lab2_df['DOB'].astype(str).str.replace('(\\d{4})(\\d\\d)(\\d\\d)', '\\\\1-\\\\2-\\\\3', regex=True) \n",
    "lab2_df['DOD'] = lab2_df['DOD'].astype(str).str.replace('(\\d{4})(\\d\\d)(\\d\\d)', '\\\\1-\\\\2-\\\\3', regex=True) \n",
    "\n",
    "lab2_df['ORD_DOD'] = lab2_df['DOD']\n",
    "lab2_df['ORD_DOD'] = lab2_df['ORD_DOD'].replace('0','2199-12-31')\n",
    "\n",
    "lab2_df['ORD_DOD'] = pd.to_datetime(lab2_df['ORD_DOD'],format='%Y-%m-%d').apply(dt.datetime.toordinal)\n",
    "lab2_df['ORD_DOB'] = pd.to_datetime(lab2_df['DOB'],format='%Y-%m-%d').apply(dt.datetime.toordinal)\n",
    "lab2_df['ORD_ClaimStartDt'] = pd.to_datetime(lab2_df['ClaimStartDt'],format='%Y-%m-%d').apply(dt.datetime.toordinal)\n",
    "lab2_df['ORD_ClaimEndDt']   = pd.to_datetime(lab2_df['ClaimEndDt'],format='%Y-%m-%d').apply(dt.datetime.toordinal)\n",
    "lab2_df['ORD_AdmissionDt']  = pd.to_datetime(lab2_df['AdmissionDt'],format='%Y-%m-%d').apply(dt.datetime.toordinal)\n",
    "lab2_df['ORD_DischargeDt']  = pd.to_datetime(lab2_df['DischargeDt'],format='%Y-%m-%d').apply(dt.datetime.toordinal)\n",
    "\n",
    "ord_dte_preds = ['ORD_DOD', 'ORD_DOB','ORD_ClaimStartDt', 'ORD_ClaimEndDt', 'ORD_AdmissionDt','ORD_DischargeDt']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recoding Binary and Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All chronic conditions, Gender, RenalDiseaseIndicator are binary variables i.e. they all have just two values but values are not 0 and 1. e.g. Gender has values 1 or 2, RenalDiseaseIndicator has Y or 1 and all Chronic Conditions has values 1 or 2. \n",
    "\n",
    "We will recode these values to 0 or 1 instead of 1 and 2 for modeling purpose. Leaving two columns for a binary feature can introduce bias, giving one feature artificially more weight in prediction if the model treats the single feature as two.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:51:26.060348Z",
     "start_time": "2020-07-05T03:51:25.225365Z"
    }
   },
   "outputs": [],
   "source": [
    "# Recode below categorical variables \n",
    "\n",
    "lab2_df['Gender']  = lab2_df['Gender'].replace([1,2],[0,1])\n",
    "lab2_df['RenalDiseaseIndicator']  = lab2_df['RenalDiseaseIndicator'].replace('Y',1)\n",
    "\n",
    "\n",
    "lab2_df = lab2_df.replace({'ChronicCond_Alzheimer': 2,      'ChronicCond_Heartfailure': 2, \n",
    "                           'ChronicCond_KidneyDisease': 2,  'ChronicCond_Cancer': 2, \n",
    "                           'ChronicCond_ObstrPulmonary': 2, 'ChronicCond_Depression': 2, \n",
    "                           'ChronicCond_Diabetes': 2,       'ChronicCond_IschemicHeart': 2, \n",
    "                           'ChronicCond_Osteoporasis': 2,   'ChronicCond_rheumatoidarthritis': 2, \n",
    "                           'ChronicCond_stroke': 2 }, '0')\n",
    "\n",
    "lab2_df['Gender'] = lab2_df['Gender'].astype('object')\n",
    "lab2_df['Race'] = lab2_df['Race'].astype('object')\n",
    "lab2_df['State'] = lab2_df['State'].astype('object')\n",
    "lab2_df['County'] = lab2_df['County'].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Dataframe - All Features\n",
    "All features are GROUPED as follows:\n",
    "* Numeric Predictors\n",
    "* Categorical Predictors\n",
    "* Non-Predictors (Will not be used for modeling)\n",
    "\n",
    "We chose to remove all ID columns from the data, as they aren't useful in prediction (unique IDs = N observations).  We replaced the original date features with their ordinal conversions.  We removed all providerIDs from the dataset, because these are correlated 1:1 with the response.  Unfortunately, our data lists only the provider ID as the response variable (potentially fraudulent), so the prediction algorithm gets 'the answer' if the provider ID shows up in attending, operating, or other physician columns.  Removing these from the dataset limits the prediction ability of our algorithms, but more closely represents reality, where a provider's fraudulent behavior is unknown at the time of claim review.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:51:26.267874Z",
     "start_time": "2020-07-05T03:51:26.192579Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_preds     = ['Age','NoPhysician','NoOfDiag','NoOfProc',\n",
    "                     'ORD_DOD','ORD_DOB','ORD_ClaimStartDt','ORD_ClaimEndDt',\n",
    "                     'ORD_AdmissionDt','ORD_DischargeDt','DaysAdmitted',\n",
    "                     'IPAnnualReimbursementAmt','IPAnnualDeductibleAmt',   \n",
    "                     'InscClaimAmtReimbursed'  \n",
    "                    ]\n",
    "\n",
    "cat_preds_nominal = ['Gender','Race','RenalDiseaseIndicator','State','County',\n",
    "                     'NoOfMonths_PartACov','NoOfMonths_PartBCov',\n",
    "                     'ChronicCond_Alzheimer','ChronicCond_Heartfailure',\n",
    "                     'ChronicCond_KidneyDisease','ChronicCond_Cancer','ChronicCond_ObstrPulmonary',\n",
    "                     'ChronicCond_Depression','ChronicCond_Diabetes','ChronicCond_IschemicHeart',\n",
    "                     'ChronicCond_Osteoporasis','ChronicCond_rheumatoidarthritis','ChronicCond_stroke',\n",
    "                     'Alive','ClmAdmitDiagnosisCode','DiagnosisGroupCode',\n",
    "                     'ClmDiagnosisCode_1','ClmDiagnosisCode_2','ClmDiagnosisCode_3',\n",
    "                     'ClmDiagnosisCode_4','ClmDiagnosisCode_5','ClmDiagnosisCode_6',\n",
    "                     'ClmDiagnosisCode_7','ClmDiagnosisCode_8','ClmDiagnosisCode_9',\n",
    "                     'ClmDiagnosisCode_10','ClmProcedureCode_1','ClmProcedureCode_2',\n",
    "                     'ClmProcedureCode_3','ClmProcedureCode_4','ClmProcedureCode_5',\n",
    "                     'AttendingPhysicianPresent','OtherPhysicianPresent','OperatingPhysicianPresent'\n",
    "                     ]\n",
    "\n",
    "non_preds = ['BeneID','DOB','DOD','state_usps','ClaimID',\n",
    "             'ClaimStartDt','ClaimEndDt','Provider',\n",
    "             'AttendingPhysician','OperatingPhysician','OtherPhysician',\n",
    "             'AdmissionDt','DischargeDt','DRGDesc',\n",
    "             'ProcedureShortDesc_1','ProcedureShortDesc_2','ProcedureShortDesc_3',\n",
    "             'ProcedureShortDesc_4','ProcedureShortDesc_5','DiagnosticDesc_1',\n",
    "             'DiagnosticDesc_2','DiagnosticDesc_3','DiagnosticDesc_4',\n",
    "             'DiagnosticDesc_5','DiagnosticDesc_6','DiagnosticDesc_7',\n",
    "             'DiagnosticDesc_8','DiagnosticDesc_9','DiagnosticDesc_10',\n",
    "             'NoOfChronicCondition'\n",
    "             ]\n",
    "\n",
    "preds_in_model = numeric_preds + cat_preds_nominal\n",
    "\n",
    "Xlab2_df = lab2_df[preds_in_model]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:51:27.303568Z",
     "start_time": "2020-07-05T03:51:27.289074Z"
    }
   },
   "outputs": [],
   "source": [
    "target_df = lab2_df['PotentialFraud'].replace(['Yes','No'],[1,0]).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding using SciKit Learn Multi Label Binarizer\n",
    "\n",
    "Because the claim data can have up to 10 different diagnosis codes and 5 different procedure codes, we created a new array column that combines all used diagnosis codes and another like type column with procedures.  This will reduce our feature counts from >40,000 to around 9,000 and will help maximize feature importance because each code will no longer be split across up to 10 different columns (i.e. diagnosis code columns 1 - 10).  This way if code A gets used in column_1, and in column_2, the usage of code A will be consolidated to the DiagnosisCode_A column.\n",
    "\n",
    "Pandas get_dummies function will not parse lists, we'll need to utilize the multiLabelBinarizer from scikit learn to one-hot encode the list values before calling get_dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:51:40.200093Z",
     "start_time": "2020-07-05T03:51:28.105870Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Xlab2_df['DiagnosisCode'] = Xlab2_df[['ClmDiagnosisCode_1', 'ClmDiagnosisCode_2', 'ClmDiagnosisCode_3', 'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5', 'ClmDiagnosisCode_6', 'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8', 'ClmDiagnosisCode_9', 'ClmDiagnosisCode_10']].values.tolist()\n",
    "\n",
    "Xlab2_df['ProcedureCode'] = Xlab2_df[['ClmProcedureCode_1', 'ClmProcedureCode_2', 'ClmProcedureCode_3', 'ClmProcedureCode_4', 'ClmProcedureCode_5']].values.tolist()\n",
    "\n",
    "ipdata = Xlab2_df.copy()\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "ipdata = ipdata.join(pd.DataFrame(mlb.fit_transform(ipdata['ProcedureCode']),columns='ProcedureCode_'+mlb.classes_))\n",
    "ipdata = ipdata.join(pd.DataFrame(mlb.fit_transform(ipdata['DiagnosisCode']),columns='DiagnosisCode_'+mlb.classes_))\n",
    "\n",
    "ipdata = ipdata.drop(columns=['ClmProcedureCode_1', 'ClmProcedureCode_2', 'ClmProcedureCode_3', 'ClmProcedureCode_4', 'ClmProcedureCode_5','ClmDiagnosisCode_1', 'ClmDiagnosisCode_2', 'ClmDiagnosisCode_3', 'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5', 'ClmDiagnosisCode_6', 'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8', 'ClmDiagnosisCode_9', 'ClmDiagnosisCode_10','ProcedureCode','DiagnosisCode'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding using Pandas\n",
    "\n",
    "Now that we've dropped our multi-columns and lists, we can onehot encode the rest of the features and transform into a sparse matrix using Pandas Get Dummies function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:51:43.841957Z",
     "start_time": "2020-07-05T03:51:40.202754Z"
    }
   },
   "outputs": [],
   "source": [
    "ipdata = pd.get_dummies(ipdata, sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:51:46.914624Z",
     "start_time": "2020-07-05T03:51:44.576609Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ipdata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing Encoded Features\n",
    "\n",
    "Because we are using objects, Pandas converts all classes into new columns.  However, for binary features, we want to remove one of the values, in order to prevent the model from introducing bias by weighting each binary feature twice (via separate true/false columns).\n",
    "\n",
    "To correct this, we must search for and remove duplicate columns (indicated by the _0 suffix).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:51:49.531293Z",
     "start_time": "2020-07-05T03:51:47.795843Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "StopWords = ['Diagnosis','Procedure','County','State']\n",
    "bins = []\n",
    "print('Removed Following Columns:')\n",
    "for col in ipdata.columns:\n",
    "    if not any(word in col for word in StopWords) and '_0' in col:    \n",
    "        print(col)\n",
    "        bins.append(col)\n",
    "ipdata = ipdata.drop(bins, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove 'None' columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our encoded dataset contains None for Diagnosis and Procedure codes features wherever information is not available on the claim. All claims allows max 5 procedure codes and 10 diagnosis codes and at least one procedure code or diagnosis code is applied on the claim. When claim has only one procedure and one diagnosis all other procedure codes contains NAs or None and one hot encoding treats these as another category which is not correct. therefore we need to remove column Nones created by one hot encoding by pandas.\n",
    "\n",
    "Essentially by creating a 'none' column it creates a column (new feature) for missing data, which would erroneously assign more weight to a value that doesn't exist.  Because it would get a '1' for missing a value, but would also have 0's for the other values.  Also it may mess up our counts because 'None' would count as a valid procedure code if we're summing unique values for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:51:51.786234Z",
     "start_time": "2020-07-05T03:51:50.272976Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nones = []\n",
    "print('Removed Following Columns:')\n",
    "for col in ipdata.columns:\n",
    "    if 'None' in col:    \n",
    "        nones.append(col)\n",
    "        print(col)\n",
    "ipdata = ipdata.drop(nones, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:51:52.164147Z",
     "start_time": "2020-07-05T03:51:51.788298Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ipdata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to use the MinMaxScaler here instead of the standard scaler because we're using a sparse matrix of mostly binary features.  Because we do have some true numeric features, such as: deductible amount, age, the converted ordinal dates, claim dollar amounts etc, these may end up having values outside the bounds of 0 and 1.  A zero mean scaler doesn't make sense with this data because it would cause the numeric features to have inflated importance if observations end up being several standard deviations away from 0, while the binary features are capped at 1.  The minMax scaler allows us to force all values in the dataset to live within the bounds of 0 and 1, allowing our logistic regression algorithms to weight features appropriately using similar measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:52:38.479956Z",
     "start_time": "2020-07-05T03:51:53.054305Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(ipdata)\n",
    "X1 = scaler.transform(ipdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Part 2\n",
    "\n",
    "We ended up with two variants of our final dataset: the sparse matrix (ipdata) containing all one-hot encoded features, and the original dataframe (Xlab2_df) so that if we need to retrieve any of the original data, we can share indices to highlight our findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:53:59.453451Z",
     "start_time": "2020-07-05T03:53:59.389135Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xlab2_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:52:39.015060Z",
     "start_time": "2020-07-05T03:52:38.970059Z"
    }
   },
   "outputs": [],
   "source": [
    "Xlab2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:52:39.913640Z",
     "start_time": "2020-07-05T03:52:39.840958Z"
    }
   },
   "outputs": [],
   "source": [
    "Xlab2_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Classification - Provider Fraud\n",
    "We will predict possible fraudulent claims and measure effectiveness using 10-fold cross validation and focus on attaining high metrics in F-1, recall and precision, in that order. Precision measures the percentage of fraudulent predictions which are truly fraudulent, and recall measures the total percentage of fraudulent claims correctly identified. These two metrics have been identified as most appropriate, due to our objective of correctly identifying fraudulent claims.  We want a high recall score, but not at the expense of precision (we can get 100% recall by classifying everyone as fraudulent).  F-1 should give us a good balance between the two, as they have an inverse relationship, where increasing one often decreases the other. \n",
    "\n",
    "## Task 2: Regression \n",
    "__TODO:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Matrix Conversion and Test/Train Split\n",
    "The minMax Scaler returns a dense numpy array.  Because we have so many features, we need to transform the data back into a sparse matrix for efficient . **CSC(Compressed Sparse Column)** is more efficient at accessing column-vectors or column operations, generally, as it is stored as arrays of columns and their value at each row.\n",
    "\n",
    "We chose to scale, convert to sparse and do test/train splits all before our pipeline in order to save processing time in the pipeline and grid search model execution steps.  The scaler takes a few minutes, and we don't want to introduce this lag to the repetitive pipeline.  This also gives us the advantage of using the exact same test/train splits for all models for a fair evaluation.  \n",
    "\n",
    "## Cross Validation Method\n",
    "\n",
    "We're using 10 fold cross validation because it will utilize it's own splits of the training data and help to ensures we don't overfit to the training data, in addition to witholding test data entirely from the models so we can more effectively evaluate generalization ability on a dataset that hasn't been seen by our models.  It has another benefit of using 10 different test/train splits of the training data, so if we happen by chance to get the best possible prediction outcome the first time we run it, we have 9 more chances to even out our prediction metrics using an average of the 10 runs.  This greatly increases our confidence that we are correctly reporting model performance metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T22:50:46.473458Z",
     "start_time": "2020-07-04T22:50:27.708823Z"
    }
   },
   "outputs": [],
   "source": [
    "X = csc_matrix(X1)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,target_df,test_size=0.2,random_state=lab2_random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluations 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function Defnitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 testPerformance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a helper function designed to help test our models after hypertuning.  It takes a pipeline object and a parameter array and executes the grid search, as well as running a new cross validation and confusion matrix on the test data that we withheld from the training set.\n",
    "\n",
    "First it creates a cross validation object, with 10-fold cross validation and an 80/20 test split.  Next it fits our training data to the model(s) listed in the grid, then it executes each model once for each combination of parameters given in the parameter array.  After obtaining the results, it displays the metrics data we defined (ROC, Accuracy, Precision, Recall and F1), with the best model being chosen with the highest F1 score.  After displaying these results, it performs 10 fold cross validation on the test data (witheld from the training data) to see how well the model performs on new data outside of the training set.  We then create a confusion matrix which can highlight models that look good on paper (high scores), but are actually poor performers.  We see this in cases where recall gets really great scores, but the vast majority of claims get classified as fraudulent, which is not realistic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T04:02:44.026125Z",
     "start_time": "2020-07-05T04:02:44.007705Z"
    }
   },
   "outputs": [],
   "source": [
    "def testPerformance(pipeline, params,n1_jobs=-1):\n",
    "    \n",
    "    cv = ShuffleSplit(n_splits=10, test_size=.2, random_state=lab2_random_state)\n",
    "    \n",
    "    #Perform the grid search using accuracy as a metric during cross validation.\n",
    "    grid = GridSearchCV(pipeline, params, cv=cv, \n",
    "                        scoring=['roc_auc','accuracy','f1','recall','precision'], \n",
    "                        n_jobs=n1_jobs, refit='f1')\n",
    "    \n",
    "    #Use the best features from recursive feature elimination during the grid search\n",
    "    start_time = timeit.default_timer()\n",
    "    grid.fit(X_train, y_train)\n",
    "    grid_time = timeit.default_timer() - start_time\n",
    "    #display the best pipeline model identified during the grid search\n",
    "    print(\"\\ngrid time: \", grid_time)\n",
    "\n",
    "    gridResults = pd.DataFrame.from_dict(grid.cv_results_)\n",
    "    \n",
    "    \n",
    "    fileName = str(grid.best_estimator_[0]).split('(')[0]+'_CV_Results.xlsx'\n",
    "    gridResults.to_excel(fileName)\n",
    "    \n",
    "    \n",
    "    fewResults = pd.DataFrame(grid.cv_results_)[['params','mean_fit_time','mean_test_roc_auc',\"mean_test_accuracy\",\"mean_test_precision\",\"mean_test_recall\",\"mean_test_f1\"]].dropna()\n",
    "    display(fewResults.sort_values(by='mean_test_f1'))\n",
    "    \n",
    "    print('Best Estimator   : ',grid.best_estimator_[0])\n",
    "    print('Best Parameters  : ',grid.best_params_)\n",
    "    print('Best Scores      : ',grid.best_score_)    \n",
    "\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    clf = grid.best_estimator_[0]\n",
    "    # fit the model\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    fit_time = timeit.default_timer() - start_time\n",
    "\n",
    "    # do 10-fold cross validation:\n",
    "    f1scores  = cross_val_score(clf, X_test, y_test, cv=cv, scoring='f1'       , n_jobs=n1_jobs)\n",
    "    PreScores = cross_val_score(clf, X_test, y_test, cv=cv, scoring='precision', n_jobs=n1_jobs)\n",
    "    RecScores = cross_val_score(clf, X_test, y_test, cv=cv, scoring='recall'   , n_jobs=n1_jobs)\n",
    "    \n",
    "    print('\\n10-fold Cross Validation results:')\n",
    "    print('---------------------------------')\n",
    "    print('F1 scores:', f1scores)\n",
    "    print('\\nPrecision scores', PreScores)\n",
    "    print('\\nRecall scores', RecScores)\n",
    "\n",
    "    print('\\nAverage F1: ',np.average(f1scores))\n",
    "    print('Min F1: ',np.min(f1scores))\n",
    "    print('Max F1: ',np.max(f1scores))\n",
    "    print('\\nAverage Precision: ',np.average(PreScores))\n",
    "    print('Min Precision: ',np.min(PreScores))\n",
    "    print('Max Precision: ',np.max(PreScores))\n",
    "    print('\\nAverage Recall: ',np.average(RecScores))\n",
    "    print('Min Recall: ',np.min(RecScores))\n",
    "    print('Max Recall: ',np.max(RecScores))\n",
    "\n",
    "    cv_time = timeit.default_timer() - start_time - fit_time\n",
    "\n",
    "    # Build Confusion Matrix to test generality:\n",
    "    y_pred=clf.predict(X_test)\n",
    "    cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    class_names=[0,1] # name  of classes\n",
    "    fig, ax = plt.subplots()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    # create heatmap\n",
    "    sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    plt.tight_layout()\n",
    "    plt.title('Potential Fraud Confusion matrix', y=1.1)\n",
    "    plt.ylabel('Actual Fraud')\n",
    "    plt.xlabel('Predicted Fraud')\n",
    "    plt.show\n",
    "    print('\\nSingle Run results:')\n",
    "    print('---------------------------------')\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "    print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "    print(\"F1:\",metrics.f1_score(y_test, y_pred))\n",
    "    \n",
    "    print(\"\\nFit time: \", fit_time)\n",
    "    print(\"CV time: \", cv_time)\n",
    "    print(\"Total time: \", timeit.default_timer() - start_time)\n",
    "    return(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Display Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T22:50:53.148611Z",
     "start_time": "2020-07-04T22:50:53.140076Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_weights(grid_object,class_model=\"logistic\"):\n",
    "    # summarize feature importance\n",
    "    \n",
    "    if ( class_model == \"rf\" ):\n",
    "      zip_vars = zip(ipdata.columns,grid_object.best_estimator_[0].feature_importances_) # combine attributes    \n",
    "    else:\n",
    "      zip_vars = zip(ipdata.columns,grid_object.best_estimator_[0].coef_.T) # combine attributes\n",
    "    \n",
    "    FeatureWeights = pd.DataFrame(list(zip_vars), columns=['Feature', 'Weight'])\n",
    "    display(FeatureWeights.sort_values(by='Weight',ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 lab2_grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T22:50:55.891837Z",
     "start_time": "2020-07-04T22:50:55.881306Z"
    }
   },
   "outputs": [],
   "source": [
    "def lab2_grid_search(estimator,results_filename,\n",
    "                     parm_grid,splits,X,y):\n",
    "\n",
    "    cr_v = ShuffleSplit(n_splits=splits, test_size=.2, random_state=86)\n",
    "    \n",
    "    lab2_scoring = {'AUC'      : 'roc_auc', \n",
    "                    'Accuracy'  : make_scorer(accuracy_score),\n",
    "                    'Recall'    : make_scorer(recall_score),\n",
    "                    'Precision' : make_scorer(precision_score),\n",
    "                    'F1'        : make_scorer(f1_score)\n",
    "                  }\n",
    "\n",
    "    clf = GridSearchCV(estimator,\n",
    "                       param_grid = parm_grid, cv = cr_v, \n",
    "                       verbose=True, n_jobs=1,\n",
    "                       scoring=lab2_scoring,\n",
    "                       refit='AUC', return_train_score=True )\n",
    "        \n",
    "    clf_fit = clf.fit(X, y)\n",
    "    \n",
    "    results= pd.DataFrame.from_dict(clf_fit.cv_results_)\n",
    "    results.to_csv('data/'+results_filename)\n",
    "    \n",
    "    return clf_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T04:05:12.479081Z",
     "start_time": "2020-07-05T04:05:12.471475Z"
    }
   },
   "outputs": [],
   "source": [
    "log_reg  = LogisticRegression(random_state=lab2_random_state)\n",
    "log_pipe = make_pipeline(log_reg)\n",
    "log_reg.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T04:05:51.112258Z",
     "start_time": "2020-07-05T04:05:51.106802Z"
    }
   },
   "outputs": [],
   "source": [
    "log_param_grid = [\n",
    "      {'logisticregression__penalty'      : ['l1'],\n",
    "       'logisticregression__C'            : [0.1],#//np.logspace(-4, 4, 20),\n",
    "       'logisticregression__solver'       : ['liblinear'],\n",
    "       'logisticregression__random_state' : [lab2_random_state]},\n",
    "      {'logisticregression__penalty'      : ['l2'],\n",
    "       'logisticregression__C'            : [0.1],##np.logspace(-4, 4, 20),\n",
    "       'logisticregression__solver'       : ['sag'],\n",
    "       'logisticregression__max_iter'     : [800],\n",
    "       'logisticregression__random_state' : [lab2_random_state]}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T04:10:09.294868Z",
     "start_time": "2020-07-05T04:05:52.800466Z"
    }
   },
   "outputs": [],
   "source": [
    "best_log_clf = testPerformance(log_pipe,log_param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a dataframe of features sorted by coefficient weight. It shows the top 5 negative an top 5 positive features for importance by how correlated they are with the response variable.  We calculated these weights by transposing the coefficient output from the logistic regression model, and using the Python Zip method to combine the coefficients with their corresponding feature (column) name. This gives us the feature names with their coefficient weight and preserves the index position as the label in a pandas dataframe, which we can then sort as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T21:15:13.947959Z",
     "start_time": "2020-07-04T21:15:13.702993Z"
    }
   },
   "outputs": [],
   "source": [
    "display_weights(best_log_clf)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T02:52:34.212488Z",
     "start_time": "2020-07-05T02:52:34.207176Z"
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=lab2_random_state)\n",
    "rf_pipe = make_pipeline(rf)\n",
    "rf.get_params()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T02:52:37.529661Z",
     "start_time": "2020-07-05T02:52:37.525625Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_param_grid = [\n",
    "      {'randomforestclassifier__max_features' :  np.arange(1,6,1),\n",
    "       'randomforestclassifier__n_estimators' :  np.arange(10,210,10),\n",
    "       'randomforestclassifier__random_state' :  [lab2_random_state],\n",
    "       'randomforestclassifier__n_jobs'       :  [-1]\n",
    "      }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T21:24:41.894347Z",
     "start_time": "2020-07-04T21:23:46.791237Z"
    }
   },
   "outputs": [],
   "source": [
    "best_rf_clf = testPerformance(rf_pipe,rf_param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T21:25:05.318896Z",
     "start_time": "2020-07-04T21:25:05.283577Z"
    }
   },
   "outputs": [],
   "source": [
    "display_weights(best_rf_clf,\"rf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T04:12:31.655363Z",
     "start_time": "2020-07-05T04:12:31.649536Z"
    }
   },
   "outputs": [],
   "source": [
    "mult_nb = MultinomialNB()\n",
    "mult_pipe = make_pipeline(mult_nb)\n",
    "print(\"Pipeline : \")\n",
    "print(mult_pipe)\n",
    "print(\"\\nHyperparameters : \")\n",
    "print(mult_nb.get_params())\n",
    "mult_nb.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T16:41:27.251017Z",
     "start_time": "2020-07-04T16:41:27.248793Z"
    }
   },
   "source": [
    "\n",
    "#### Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T04:20:11.365148Z",
     "start_time": "2020-07-05T04:20:11.361926Z"
    }
   },
   "outputs": [],
   "source": [
    "nb_param_grid = [\n",
    "      {'multinomialnb__alpha' :  np.logspace(-4, 4, 20),#[np.arange(1,3,10)],\n",
    "       'multinomialnb__fit_prior'       :  [True]\n",
    "      }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T04:20:20.226911Z",
     "start_time": "2020-07-05T04:20:13.652968Z"
    }
   },
   "outputs": [],
   "source": [
    "best_nb_clf = testPerformance(mult_pipe,nb_param_grid,n1_jobs=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T23:01:31.076513Z",
     "start_time": "2020-07-04T23:01:30.891726Z"
    }
   },
   "outputs": [],
   "source": [
    "display_weights(best_nb_clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:54:11.800703Z",
     "start_time": "2020-07-05T03:54:11.795078Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_preds = ['Gender','Race','RenalDiseaseIndicator','State',\n",
    "             'County','ChronicCond_Alzheimer','ChronicCond_Heartfailure',\n",
    "             'ChronicCond_KidneyDisease','ChronicCond_Cancer','ChronicCond_ObstrPulmonary',\n",
    "             'ChronicCond_Depression','ChronicCond_Diabetes','ChronicCond_IschemicHeart',\n",
    "             'ChronicCond_Osteoporasis','ChronicCond_rheumatoidarthritis','ChronicCond_stroke',\n",
    "             'Alive','ClmAdmitDiagnosisCode','DiagnosisGroupCode','ClmDiagnosisCode_1',\n",
    "             'ClmDiagnosisCode_2','ClmDiagnosisCode_3','ClmDiagnosisCode_4',\n",
    "             'ClmDiagnosisCode_5','ClmDiagnosisCode_6','ClmDiagnosisCode_7',\n",
    "             'ClmDiagnosisCode_8','ClmDiagnosisCode_9','ClmDiagnosisCode_10',\n",
    "             'ClmProcedureCode_1','ClmProcedureCode_2','ClmProcedureCode_3',\n",
    "             'ClmProcedureCode_4','ClmProcedureCode_5','AttendingPhysicianPresent',\n",
    "             'OtherPhysicianPresent','OperatingPhysicianPresent']\n",
    "             \n",
    "\n",
    "cat_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:54:12.750536Z",
     "start_time": "2020-07-05T03:54:12.639593Z"
    }
   },
   "outputs": [],
   "source": [
    "from feature_engine.categorical_encoders import MeanCategoricalEncoder\n",
    "\n",
    "X_reg = Xlab2_df.copy()\n",
    "\n",
    "prov_ids = ['AttendingPhysicianPresent','OtherPhysicianPresent','OperatingPhysicianPresent']\n",
    "\n",
    "X_reg[prov_ids]   = X_reg[prov_ids].astype('object')\n",
    "X_reg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:54:14.135951Z",
     "start_time": "2020-07-05T03:54:14.090641Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_enc = MeanCategoricalEncoder(variables=cat_preds)\n",
    "X_reg.loc[:,cat_preds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:05:02.315467Z",
     "start_time": "2020-07-05T05:05:02.305496Z"
    }
   },
   "outputs": [],
   "source": [
    "for key in mean_enc.encoder_dict_.keys():\n",
    "    ns_key = mean_enc.encoder_dict_[key]\n",
    "    print(mean_enc.encoder_dict_[key]['0'])\n",
    "#mean_enc.encoder_dict_   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:55:53.352586Z",
     "start_time": "2020-07-05T03:55:52.728597Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_enc.fit(X_reg.loc[:,cat_preds], lab2_df['PotentialFraud'].replace(['Yes','No'],[1,0]))\n",
    "\n",
    "X1_train = mean_enc.transform(X_reg.loc[:,cat_preds])\n",
    "X1_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:58:10.945967Z",
     "start_time": "2020-07-05T03:58:10.882068Z"
    }
   },
   "outputs": [],
   "source": [
    "reg_target=lab2_df['PotentialFraud'].replace(['Yes','No'],[1,0]).copy()\n",
    "X_final = pd.concat([pd.DataFrame(data=Xreg_final_scaled, columns=X_reg.iloc[:,0:14].columns),X1_train],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:58:21.186511Z",
     "start_time": "2020-07-05T03:58:21.159376Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:58:37.749252Z",
     "start_time": "2020-07-05T03:58:35.802399Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"Age\", y=\"IPAnnualReimbursementAmt\", hue=reg_target, data=X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:55:25.167125Z",
     "start_time": "2020-07-05T03:55:25.148183Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_reg.iloc[:,0:14])\n",
    "Xreg_final_scaled = scaler.transform(X_reg.iloc[:,0:14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T04:01:45.560888Z",
     "start_time": "2020-07-05T04:01:45.537157Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X_final,target_df,test_size=0.2,random_state=lab2_random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T03:57:57.644557Z",
     "start_time": "2020-07-05T03:57:57.623255Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluations 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO:__ Visualize results \n",
    "\n",
    "People don't explain 'why' which will deduct points \n",
    "\n",
    "Analyze how the model is performing \n",
    "\n",
    "Explaination is bolstered by analysis \n",
    "\n",
    "TIP: YellowBrick (it's a pkg) for visualizing estimators "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluations 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO:__\n",
    "Discuss advantages of models for a classification task \n",
    "\n",
    "Give table, how many models you built \n",
    "\n",
    "CV results object from grid search will give all of that information \n",
    "\n",
    "TIP Put in a dataframe in ME5 and then talk about \n",
    "\n",
    "Here's all the models we did, here is the best one (or top 3) \n",
    "\n",
    "Is there one that runs 10x as long and a slightly inferior runs fast \n",
    "\n",
    "Is the difference between models significant? \n",
    "\n",
    "Long method 1: Notebook #6 and use student's paired t test (at bottom), correct t value and folds \n",
    "\n",
    "Long method 2: generate ROC curves for each model \n",
    "\n",
    "If you use ROC as your eval metric, it is statistically sound measure, so if one has a larger area under curve, it is a better model statistically speaking. \n",
    "\n",
    "Can use micro average ROC curve with multiclass problem \n",
    "\n",
    "If you already did both, ask for exceptional points \n",
    "\n",
    "TIP: mlxtend has an 'evaluate' library for significant test \n",
    "\n",
    "Can get comprehensive with paired_ttest5x2cv \n",
    "\n",
    "Calling library and function will spit out exactly what you need "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluations 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO:__\n",
    "    Two options: \n",
    "\n",
    "Both tasks are on same dataset.  do two feature importance and opine difference between two \n",
    "\n",
    "Make sure you do feature importance on scaled data if you're using coefficients \n",
    "\n",
    "Use some other type of feature eval technique (mlextend library has multiple options) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO:__\n",
    "    Address each question (in a subsection) \n",
    "\n",
    "2 ways to go about it \n",
    "\n",
    "Just because you can't predict something in the real world, doesn't necessarily mean you aren't interested in model's ability to predict \n",
    "\n",
    "Predict graduation rate for public schools (schools know their rates.. But they would be interested in what is correlated with grad rates) \n",
    "\n",
    "Maybe it's not useful for prediction, but could be used for EDA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exceptional Work\n",
    "### Preprocessing:\n",
    "We would like credit for the large amount of preprocessing that went into our data.  We have a large variety of features in the dataset, many of which required clever feature engineering tricks to improve performance.  Conversion to the sparse matrix took a good bit of research, and continues to be an effort for implementation, since not every model or library will accept a sparse matrix.  The conversion of procedure codes and diagnosis codes from multiple columns into a one hot encoded dataframe took a significant amount of time/effort, most of the out of the box libraries we tried would not parse a list object and it took a lot of experimentation and research.  The performance improved as it reduced our total featureset footprint from > 40,000 to around 9,000.   \n",
    "\n",
    "### Pipelines and Grid Search:\n",
    "We decided to implement Pipelines and Grid Search in order to reduce the copy/paste and number of variables we need to work with.  This is a new concept barely touched on in class, and it required significant amounts of research time to implement before we could move on to model evaluation, visualization and discussion.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <a href=\"https://machinelearningmastery.com/k-fold-cross-validation/\"> https://machinelearningmastery.com/k-fold-cross-validation/ </a> K-Fold Cross Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": false,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": true,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "285px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 365,
   "position": {
    "height": "40px",
    "left": "789px",
    "right": "20px",
    "top": "119px",
    "width": "630px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
