{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the CRISP-DM framework in your analysis (you are not\n",
    "performing all of the CRISP-DM outline, only the portions relevant to the grading rubric outlined\n",
    "below).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a logistic regression model and a support vector machine model for the\n",
    "classification task involved with your dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess how well each model performs (use 80/20 training/testing split for your data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust parameters of the models to make them more\n",
    "accurate. If your dataset size requires the use of stochastic gradient descent, then linear kernel\n",
    "only is fine to use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust parameters of the models to make them more\n",
    "accurate. If your dataset size requires the use of stochastic gradient descent, then linear kernel\n",
    "only is fine to use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Use the weights from logistic regression to interpret the importance of different\n",
    "features for each classification task. Explain your interpretation in detail. Why do you think\n",
    "some variables are more important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the chosen support vectors for the classification task. Do these provide\n",
    "any insight into the data? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 40474 entries, 0 to 40473\nData columns (total 53 columns):\n #   Column                           Non-Null Count  Dtype   \n---  ------                           --------------  -----   \n 0   BeneID                           40474 non-null  object  \n 1   ClaimID                          40474 non-null  object  \n 2   ClaimStartDt                     40474 non-null  int64   \n 3   ClaimEndDt                       40474 non-null  int64   \n 4   Provider                         40474 non-null  object  \n 5   InscClaimAmtReimbursed           40474 non-null  float64 \n 6   AttendingPhysician               40474 non-null  object  \n 7   OperatingPhysician               40474 non-null  object  \n 8   OtherPhysician                   40474 non-null  object  \n 9   AdmissionDt                      40474 non-null  int64   \n 10  ClmAdmitDiagnosisCode            40474 non-null  object  \n 11  DeductibleAmtPaid                40474 non-null  float64 \n 12  DischargeDt                      40474 non-null  int64   \n 13  DiagnosisGroupCode               40474 non-null  object  \n 14  ClmDiagnosisCode_1               40474 non-null  object  \n 15  ClmDiagnosisCode_2               40474 non-null  object  \n 16  ClmDiagnosisCode_3               40474 non-null  object  \n 17  ClmDiagnosisCode_4               40474 non-null  object  \n 18  ClmDiagnosisCode_5               40474 non-null  object  \n 19  ClmDiagnosisCode_6               40474 non-null  object  \n 20  ClmDiagnosisCode_7               40474 non-null  object  \n 21  ClmDiagnosisCode_8               40474 non-null  object  \n 22  ClmDiagnosisCode_9               40474 non-null  object  \n 23  ClmDiagnosisCode_10              40474 non-null  object  \n 24  ClmProcedureCode_1               40474 non-null  object  \n 25  ClmProcedureCode_2               40474 non-null  object  \n 26  ClmProcedureCode_3               40474 non-null  object  \n 27  ClmProcedureCode_4               40474 non-null  object  \n 28  ClmProcedureCode_5               40474 non-null  object  \n 29  ClmProcedureCode_6               40474 non-null  object  \n 30  DOB                              40474 non-null  int64   \n 31  DOD                              40474 non-null  int64   \n 32  Gender                           40474 non-null  object  \n 33  Race                             40474 non-null  object  \n 34  RenalDiseaseIndicator            40474 non-null  object  \n 35  State                            40474 non-null  object  \n 36  County                           40474 non-null  object  \n 37  NoOfMonths_PartACov              40474 non-null  int64   \n 38  NoOfMonths_PartBCov              40474 non-null  int64   \n 39  ChronicCond_Alzheimer            40474 non-null  int64   \n 40  ChronicCond_Heartfailure         40474 non-null  int64   \n 41  ChronicCond_KidneyDisease        40474 non-null  int64   \n 42  ChronicCond_Cancer               40474 non-null  int64   \n 43  ChronicCond_ObstrPulmonary       40474 non-null  int64   \n 44  ChronicCond_Depression           40474 non-null  int64   \n 45  ChronicCond_Diabetes             40474 non-null  int64   \n 46  ChronicCond_IschemicHeart        40474 non-null  int64   \n 47  ChronicCond_Osteoporasis         40474 non-null  int64   \n 48  ChronicCond_rheumatoidarthritis  40474 non-null  int64   \n 49  ChronicCond_stroke               40474 non-null  int64   \n 50  IPAnnualReimbursementAmt         40474 non-null  float64 \n 51  IPAnnualDeductibleAmt            40474 non-null  float64 \n 52  PotentialFraud                   40474 non-null  category\ndtypes: category(1), float64(4), int64(19), object(29)\nmemory usage: 16.4+ MB\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#Read in data:\n",
    "ipdata = pd.read_csv(\"./data/Train_Inpatientdata-1542865627584.csv\")\n",
    "bendata = pd.read_csv(\"./data/Train_Beneficiarydata-1542865627584.csv\")\n",
    "prodata = pd.read_csv(\"./data/Train-1542865627584.csv\")\n",
    "\n",
    "\n",
    "#proc_codes = pd.read_csv(\"./data/CMS27_DESC_LONG_SHORT_SG_092709.csv\")\n",
    "# v27 ICD-9 Procedure Code Data comes from https://www.cms.gov/Medicare/Coding/ICD9ProviderDiagnosticCodes/Downloads/FY2010Diagnosis-ProcedureCodesFullTitles.zip\n",
    "\n",
    "#diag_codes = pd.read_fwf(\"./data/V26 I-9 Diagnosis.txt\")\n",
    "# v26 Diag Code Data comes from https://www.cms.gov/Medicare/Coding/ICD9ProviderDiagnosticCodes/Downloads/v27_icd9.zip\n",
    "# and missing code 7889 comes from https://www.cms.gov/Medicare/Coding/ICD9ProviderDiagnosticCodes/Downloads/v26_icd9.zip\n",
    "\n",
    "\n",
    "\n",
    "# Merge beneficiary data with inpatient data:\n",
    "ipdata = ipdata.merge(bendata, left_on='BeneID', right_on='BeneID')\n",
    "\n",
    "# Merge Provider Data:\n",
    "ipdata = ipdata.merge(prodata, on='Provider', how='inner')\n",
    "\n",
    "# Fill NAs\n",
    "ipdata['DOD'] = ipdata['DOD'].fillna('2199-12-31')\n",
    "missing_vcols = ['OperatingPhysician', 'OtherPhysician','ClmAdmitDiagnosisCode','DiagnosisGroupCode', \n",
    "                 'ClmDiagnosisCode_3', 'ClmDiagnosisCode_3', 'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5', \n",
    "                 'ClmDiagnosisCode_6', 'ClmDiagnosisCode_7','ClmDiagnosisCode_8', 'ClmDiagnosisCode_9', \n",
    "                 'ClmDiagnosisCode_10','ClmProcedureCode_1', 'ClmProcedureCode_2', 'ClmProcedureCode_3', \n",
    "                 'ClmProcedureCode_4', 'ClmProcedureCode_5', 'ClmProcedureCode_6'] \n",
    "\n",
    "ipdata[missing_vcols] = ipdata[missing_vcols].fillna('None')\n",
    "ipdata['DeductibleAmtPaid'] = ipdata['DeductibleAmtPaid'].fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "# Convert everythign to string\n",
    "ipdata = ipdata.applymap(str)\n",
    "\n",
    "# Convert to usable formats:\n",
    "timecols = ['ClaimStartDt', 'ClaimEndDt','AdmissionDt', 'DischargeDt', 'DOB','DOD']\n",
    "numcols = ['InscClaimAmtReimbursed', 'DeductibleAmtPaid','IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt']\n",
    "catcols = ['PotentialFraud']\n",
    "intcols = ['ChronicCond_Alzheimer','ChronicCond_Heartfailure','ChronicCond_KidneyDisease','ChronicCond_Cancer','ChronicCond_ObstrPulmonary','ChronicCond_Depression','ChronicCond_Diabetes','ChronicCond_IschemicHeart','ChronicCond_Osteoporasis','ChronicCond_rheumatoidarthritis','ChronicCond_stroke', 'NoOfMonths_PartACov', 'NoOfMonths_PartBCov']\n",
    "\n",
    "ipdata[timecols] = ipdata[timecols].apply(pd.to_datetime)\n",
    "\n",
    "ipdata['DOD'] = ipdata['DOD'].apply(dt.datetime.toordinal)\n",
    "ipdata['DOB'] = ipdata['DOB'].apply(dt.datetime.toordinal)\n",
    "ipdata['ClaimStartDt'] = ipdata['ClaimStartDt'].apply(dt.datetime.toordinal)\n",
    "ipdata['ClaimEndDt'] = ipdata['ClaimEndDt'].apply(dt.datetime.toordinal)\n",
    "ipdata['AdmissionDt'] = ipdata['AdmissionDt'].apply(dt.datetime.toordinal)\n",
    "ipdata['DischargeDt'] = ipdata['DischargeDt'].apply(dt.datetime.toordinal)\n",
    "\n",
    "ipdata[intcols] = ipdata[intcols].astype(int)\n",
    "\n",
    "ipdata = ipdata.replace({'ChronicCond_Alzheimer': 2, 'ChronicCond_Heartfailure': 2, 'ChronicCond_KidneyDisease': 2,\n",
    "                           'ChronicCond_Cancer': 2, 'ChronicCond_ObstrPulmonary': 2, 'ChronicCond_Depression': 2, \n",
    "                           'ChronicCond_Diabetes': 2, 'ChronicCond_IschemicHeart': 2, 'ChronicCond_Osteoporasis': 2, \n",
    "                           'ChronicCond_rheumatoidarthritis': 2, 'ChronicCond_stroke': 2 }, 0)\n",
    "\n",
    "ipdata = ipdata.replace({'RenalDiseaseIndicator': 'Y'}, 1)\n",
    "\n",
    "\n",
    "ipdata[numcols] = ipdata[numcols].astype(float)\n",
    "ipdata[catcols] = ipdata[catcols].astype('category')\n",
    "\n",
    "\n",
    "ipdata = ipdata.drop(columns=['OPAnnualReimbursementAmt','OPAnnualDeductibleAmt'])\n",
    "\n",
    "ipdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total time:  158.396421968\n"
    }
   ],
   "source": [
    "# One hot encode \n",
    "#df = ipdata.sample(frac=0.5, replace=False, random_state=1)\n",
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "# Drop ID columns\n",
    "ipdata = ipdata.drop(columns=['Provider', 'BeneID', 'ClaimID'])\n",
    "\n",
    "# Onehot encode & convert to sparse matrix\n",
    "ipdata = pd.get_dummies(ipdata, sparse=True)\n",
    "\n",
    "# Drop extra response column\n",
    "ipdata = ipdata.drop(columns='PotentialFraud_No')\n",
    "\n",
    "X = ipdata.drop(columns='PotentialFraud_Yes')\n",
    "Y = ipdata[\"PotentialFraud_Yes\"]\n",
    "\n",
    "# Scale training data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=86)\n",
    "\n",
    "\n",
    "total_time = timeit.default_timer() - start_time\n",
    "print(\"Total time: \", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model takes awhile, let's time it:\n",
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# This line works, takes about 15 minutes to train\n",
    "#logreg = LogisticRegression(penalty='l2', random_state=86, solver='sag', n_jobs=-1)\n",
    "\n",
    "# This is what I'm working on, still trying to get this to train w/o crashing.\n",
    "logreg = LogisticRegression(penalty='l2', random_state=86, solver='lbfgs', n_jobs=-1)\n",
    "\n",
    "# fit the model\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "fit_time = timeit.default_timer() - start_time\n",
    "print(\"Fit time: \", fit_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After fitting, you can play around with predictions to really see the effect of the probability threshold\n",
    "\n",
    "# Build predictions:\n",
    "y_pred=logreg.predict_proba(X_test)[:,1] > .51\n",
    "\n",
    "# import the metrics class\n",
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "class_names=[0,1] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Potential Fraud Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual Fraud')\n",
    "plt.xlabel('Predicted Fraud')\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}